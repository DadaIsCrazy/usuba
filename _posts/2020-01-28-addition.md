---
layout: post
title: Bitslice adder
date: "2020-01-28 00:00:00"
description: Comparaison of native addition and a bitslice adder
lang: en
locale: en_US
author: Darius Mercadier
excerpt: Bitslicing is supposedly slow when it comes to arithmetic operations, since bitsliced program need to manually reimplement arithmetic using logical gates. In this post, we will show how much of a slowdown this would incur on an Intel Skylake CPU.
comments: false
hidden: true
---

<!--
Introduction
 - bitslicing cannot do arithmetic
   -> must re-implement arithmetic
 - example: adder
   + 5n instructions
   + 5n/m instr/add
   + cost not obvious: superscalar, register pressure...
-->

As explained in post [2 - Bitslicing]({{ site.baseurl }}{% post_url
2020-01-14-bitslicing %}), bitsliced codes cannot use arithmetic
instructions. Instead, arithmetic must be reimplemented using bitwise
logical gates. While this certainly increases code size compared to a
non-bitsliced code, it's not obvious how it affects performances: on
one hand, a simple arithmetic operation becomes a large circuit, but
on the other hand, thanks to bitslicing, this circuit computes _m_
times the operation on _m_-bit registers.

In this post, we will re-use the example of the adder (cf. post
[Bitslicing - Arithmetic operations]({{ site.baseurl }}{% post_url
2020-01-14-bitslicing %}#arithmetic-operations)) to evaluate what
performances we might expect from bitsliced arithmetic. Recall that a
_n_-bit ripple-carry adder is a chain of _n_ full adders, each
composed of 5 instructions, for a total of _n*5_ instructions. Running
this bitsliced adder on _m_-bit registers computes _m_ additions in
parallel, thus reducing its cost to _n*5/m_ instructions per addition.

However, this adder is unlikely to execute in exactly _n*5_ cycles on
modern high-end CPUs, whose microarchitectures are complex: number of
registers, superscalarity, and cache latency will all impact
performances. In this post, we will benchmark such an adder against
native `add` instructions, and show that in most cases, bitsliced
additions are less efficient that native ones.

## Sylake CPU background

<!--
Skylake CPU background
 - not presenting everything
 - schema?
 - pipelined
 - superscalar
 - ignoring hyperthreading
 - frontend (in order)
   + decoding (example: inc/jmp)
   + DSB
   + LSD
   + macro-fusion
 - backend (out of order; retiring in order)
   + execution ports:
     * schema?
     * p0156 int ALU (p06 branch) (p015 vect ALU)
     * p23 load
     * p4 store
   + scheduling -> black box
 - memory
   + cache: line size, latency
-->


The Skylake CPU is a deeply pipelined microarchitecture (_i.e._ it can
contain many instructions at the same time, all going through
different phases), illustrated by the following schema:

<p align="center">
<img src="{{ site.baseurl }}/assets/images/blog/Skylake-simplified-small.png">
</p>

Note that this is a simplified view of the Skylake microarchitecure,
whose purpose is only to explain what matters to us, and to show which
parts we will be focusing on when analyzing the performances of our
programs.

We can see the pipelines consists of 2 main phases: the front end
retrieves and decodes instructions in-order from the L1 instruction
cache, while the out-of-order execution engine actually executes the
instructions. The instructions are finally removed in-order from the
pipeline by the retiring unit.


### Front end

The L1 instruction cache contains x86 instructions represented as a
sequence of bytes. Those instructions are decoded by the Legacy Decode
Pipeline (MITE). The MITE operates in the following way:

 - up to 16 bytes of instructions are fetched from the L1 instruction
   cache, and pre-decoded into macro-ops.
   
 - up to 6 macro-ops per cycle are delivered to the instruction queue
   (IQ), which performs macro-fusion: some common patterns are
   identified and optimized by fusing their macro-ops together. For
   instance, an increment followed by a conditional jump, often found
   at the end of a loop, can fuse together in a single macro-op.
   
 - the IQ delivers up to 5 macro-ops per cycle to the decoders. The
   decoders convert each macro-ops into one or several μops, which are
   then sent to the Instruction Decode Queue (IDQ).

The MITE is limited by the fetcher to 16 bytes of instructions per
cycle. This translates to 4 or 5 μops per cycle on programs
manipulating integer registers, which is enough to maximize the
bandwidth of the pre-decoder and decoders. However, SSE, AVX and
AVX-512 instructions are often larger. For instance, an addition
between two registers is encoded on 2 bytes for integer registers, 4
bytes on SSE and AVX, and 6 bytes on AVX-512. Therefore, on programs
using SIMD extensions, the MITE tend to be limited by the fetcher. In
order to overcome this, the Decoded Stream Buffer (DSB), a μop cache,
can be used to bypass the whole MITE when dealing with sequences of
instructions that have already been decoded. The DSB delives up to 6
μops per cycles, directly to the IDQ.


Originally, the whole front end could be entirely bypassed even
further by the Loop Stream Detector (LSD), which was able to detect
loop are would continue emit the loop's µops until a branch
mis-prediction would occur. However, due to a bug with
hyper-threading, this feature is now disabled (erratum SKL150).



### Execution engine

The execution engine can be divided in 3 phases. The Allocate/Rename
phase retrieves µops from the IDQ and sends them to the Scheduler,
which dispatchs µops to the execution core. Once µops are executed,
they are retired: all ressources allocated for them are freed, and the
µops are effectively removed from the pipeline.


The renamer fetchers up to 6 µops per cycle from the IDQ. It renames
architectural registers (_e.g._ `rax`, `rdx`) into micro-architectural
registers (also known as physical registers). It determines the
possible execution ports for each instruction, and allocates any
additional ressources they may need (_e.g._ load or store buffers).

Additionally, the renamer recognizes some patterns and executes some
instructions without going through the execution core. In particular,
it performs:

 - move elimination: some inter-register `mov` can be removed by
   carefully mapping architectural registers to physical registers.
   
 - zeroing idiom elimination: some commonly used idioms to set a
   register to zero are recognized and removed by the renamer. For
   instance, a `xor` or a subtraction when both operands are the same
   register.


The scheduler then dispatches µops out-of-order to the execution units
of the execution core. When an instruction could be executed on
several execution units, the scheduler chooses one using an unknown
algorithm.

The execution core consists of several execution units, each able to
execute some specific type of µops, and accessed through 8 ports:

 - Arithmetic and bitwise instructions can execute ports 0, 1 and 5
   (and 6 for general purpose registers).
   
 - Branches can execute on port 0 and 6.
 
 - Memory loads can execute on port 2 and 3.
 
 - Memory reads can execute on port 4.
 

Up to 4 general purpose arithmetic instructions can therefore be
executed each cycle. In a loop however, this would not leave any free
port for the branch to execute.

The instructions are then remove from the pipeline in-order by the
retiring unit. All ressources allocated for them are freed, and
fault and exceptions are handled at that stage.



## Setup

<!-- Setup
  - loop X time over 1 addition
  - bitslice add
    + 8, 16, 32 bits: register pressure will matter at > 16
  - native add:
    + sse: 4x32, 8x16, 16x8
    + GP: 1x32, 1x16, 1x8
  - native add "parallel":
    + because superscalar: saturate p0156
  - Skylake i5-6500
-->

We consider 3 different additions for our evaluation:

 - a bitslice ripple-carry adder (presented above). Three variants are
   used: 8-bit, 16-bit and 32-bit. Since their number of instructions
   are _5*n_, we could expect the 32-bit adder to be twice slower than
   the 16-bit, which itself would be twice slower than the 8-bit
   adder. However, larger adders put more pressure on registers, which
   could reduce performances, hence the need for benchmarking all
   three versions.
   
 - an addition done using a single CPU instruction. For completness,
   we consider the 8, 16 and 32-bit variants of the addition; all of
   which should have the same throughput and latency. On general
   purpose (GP) registers, only one addition can be done with a single
   instruction. However, SSE instructions allow to do 4 32-bit, or 8
   16-bit or 16 8-bit additions with a single instruction. This does
   not reduce latency, but increases throughput.
 
 - 3 independent additions done with 3 CPU instructions. Doing only a
   single addition per cycle under-utilizes the superscalar
   capabilities of modern CPUs: up to 3 SSE additions (and 4 on GP)
   can be done each cycles. Once again, we consider the 8, 16 and
   32-bit variants, on both SSE and GP.

We implemented those additions in C, and put each of them in a loop
doing 2 billion iterations. This takes less than a second for the
second and third additions, which might be considered too short for
some benchmarks, but since we are merely micro-benchmarking a handful
of CPU instructions, this is enough. We repeat this process 10 times,
and report the average of the 10 runs in the next section. The
standard deviation being less than 5 percents, we omit it in order to
avoid needlessly obsucating the result table.

We compiled our C codes using Clang 7.0.0, but given the simplicity of
the generated assembly codes, the choice of compiler should not
matter. Finally, we ran the benchmarks on a Intel Skylake i5-6500.


## Results

<!--
 - native_single: 
   + expected: 1 add + 1 increment + 1 jump => 1 cycle
   + got: 1 cycle
 - native_parallel:
   + expected: 3 add + 1 increment + 1 jump => 1 cycle
     * macro-fusion
   + got: 1 cycle
 - bitslice:
   + total ops: 5*n. 
   + expected: assuming 3 ops/cycle -> 5n/3
     * 8-bit: exp 8*5/3=13.3, got: 14.77, close enough!
     * 16-bit: exp 16*5/3=26.5, got: 33.28
       & 32-bit: exp 32*5/3=53.3, got: 74.55
       - spilling: half the instructions are `move`
 - bitslice vs others?
-->

We report in the following table the cycles per iteration and cycles
per addition. `bitslice` is the bitsliced addition using a
ripple-carry adder. `native_single` is a single native additions using
a single instruction. `native_parallel` is the three independent
native additions.

<center>

<table style="border-collapse: collapse; text-align:center">
<tr style="border-top:1px solid #c6cbd1;border-right:1px solid #c6cbd1;border-left:1px solid #c6cbd1;background-color:#ffffff">
<th rowspan="2" style="min-width:250px">addition type</th><th style="min-width:200px">cycles/iteration</th><th style="min-width:200px">cycles/add</th></tr>
<tr style="border-bottom:1px solid #c6cbd1;border-right:1px solid #c6cbd1;border-left:1px solid #c6cbd1;background-color:#ffffff"><th>(SSE / GP)</th><th>(SSE / GP)</th></tr>


<tr style="border:1px solid #c6cbd1;background-color:#e6f7ff"><td style="border:1px solid #c6cbd1">  8-bit        bitslice </td><td style="border:1px solid #c6cbd1">     14.77    /    16.28     </td><td style="border:1px solid #c6cbd1">      0.12    /     0.51     </td></tr> 
<tr style="border:1px solid #c6cbd1;background-color:#ffffff"><td style="border:1px solid #c6cbd1">  8-bit   native_single </td><td style="border:1px solid #c6cbd1">      1.00    /     1.00     </td><td style="border:1px solid #c6cbd1">      0.06    /     1.00     </td></tr> 
<tr style="border:1px solid #c6cbd1;background-color:#e6f7ff"><td style="border:1px solid #c6cbd1">  8-bit native_parallel </td><td style="border:1px solid #c6cbd1">      1.00    /     1.00     </td><td style="border:1px solid #c6cbd1">      0.02    /     0.33     </td></tr> 
<tr style="border:1px solid #c6cbd1;height:15px;background-color:#ffffff"><td></td><td></td><td></td></tr>


<tr style="border:1px solid #c6cbd1;background-color:#e6f7ff"><td style="border:1px solid #c6cbd1"> 16-bit        bitslice </td><td style="border:1px solid #c6cbd1">     33.28    /    34.52     </td><td style="border:1px solid #c6cbd1">      0.26    /     1.08     </td></tr> 
<tr style="border:1px solid #c6cbd1;background-color:#ffffff"><td style="border:1px solid #c6cbd1"> 16-bit   native_single </td><td style="border:1px solid #c6cbd1">      1.00    /     1.00     </td><td style="border:1px solid #c6cbd1">      0.13    /     1.00     </td></tr> 
<tr style="border:1px solid #c6cbd1;background-color:#e6f7ff"><td style="border:1px solid #c6cbd1"> 16-bit native_parallel </td><td style="border:1px solid #c6cbd1">      1.00    /     1.00     </td><td style="border:1px solid #c6cbd1">      0.04    /     0.33     </td></tr> 
<tr style="border:1px solid #c6cbd1;height:15px;background-color:#ffffff"><td></td><td></td><td></td></tr>


<tr style="border:1px solid #c6cbd1;background-color:#e6f7ff"><td style="border:1px solid #c6cbd1"> 32-bit        bitslice </td><td style="border:1px solid #c6cbd1">     74.55    /    73.33     </td><td style="border:1px solid #c6cbd1">      0.58    /     2.29     </td></tr> 
<tr style="border:1px solid #c6cbd1;background-color:#ffffff"><td style="border:1px solid #c6cbd1"> 32-bit   native_single </td><td style="border:1px solid #c6cbd1">      1.00    /     1.00     </td><td style="border:1px solid #c6cbd1">      0.25    /     1.00     </td></tr> 
<tr style="border:1px solid #c6cbd1;background-color:#e6f7ff"><td style="border:1px solid #c6cbd1"> 32-bit native_parallel </td><td style="border:1px solid #c6cbd1">      1.00    /     1.00     </td><td style="border:1px solid #c6cbd1">      0.08    /     0.33     </td></tr>

</table>

</center>
<br>

### Single native addition (`native_single`)

According to Intel's manual, additions (both SSE and GP ones) should
execute in one cycle. There should be no overhead from the loop:
looping requires incrementing a counter and doing a conditional
jump. Those two instructions get macro-fused together and execute on
port 0 or 6. The SSE addition can execute on either port 0, 1 or 5,
and can thus be done at the same time as the loop increment/jump.

Experimentally, we get a 1 cycle/iteration throughput, regardless of
the size of the addition (8-bit, 16-bit or 32-bit). On GP registers,
this means 1 cycle per addition. On SSE registers however, a single
`padd` instruction performs multiple additions, thus reducing the cost
per addition: 0.25 cyles for 32-bit, 0.13 cycles for 16-bit and 0.06
cycles for 8-bit.


### Parallel native additions (`native_parallel`)

Since SSE addition can execute on either port 0, 1 or 5, three of them
could be done in a single cycle, provided that they don't have
dependencies (_i.e._ none uses the output of another one). The
increment and jump of the loop would fuse and be executed on port 6,
thus not perturbing the additions.

Once again, this corresponds to the numbers we observe experimentally:
1 cycle/iteration regarderless of the size of the additions. Since 3
`padd` instructions are executed each cycle, the cost par addition is
a third of `native_single`'s: 0.08 for 32-bit, 0.04 for 16-bit and
0.02 for 8-bit.


### Bitslice addition (`bitslice`)

Recall that the _n_-bit ripple-carry adder contains _n*5_
instructions. It relies solely on bitwise instructions, which can be
executed on ports 0, 1 and 5 on SSE registers (and on port 6 as well
on GP registers). The least amount of cycles this adder can execute in
is therefore _n*5/3_.

In isolation, a full adder contains inner dependencies, preventing
them from execute in less than 3 cycles. However, in an _n_-bit adder,
out-of-order execution can allow multiple full adders to execute
simultaneously, thus allowing a saturation of CPU ports 0, 1 and 5
despite the dependencies within each full adder.

The 8-bit SSE adder runs in 14.77 cycles, slightly slower than the
13.3 theoretical minimum (_n_*5/3 = 8*5/3 = 13.3). The 16 and 32-bit
variants are even slower compared to their theoretical minimum, at
33.28 (expected 26.5) and 74.55 (expected 53.3) cycles. The 8-bit GP
adder is slighly slower than the SSE equivalent (16.28 cycles), while
its 16-bit and 32-bit versions have similar performances as their SSE
counterparts.


The lower performances than expected can be explained by 2 factors:

 - Spilling: a bitsliced _n_-bit adder has _n*2_ inputs, _n_ outputs,
   and _n*5_ temporary variables. Even though most of the temporary
   variables are short lived, the pressure on the registers remains
   high: there are only 16 SSE registers available and 15 GP registers
   (since one register is always kept for the stack pointer). The
   8-bit SSE adder doesn't suffer from spilling, but all other adders
   are affected.
 
 - Desctructive 2-operand instructions. x86 bitwise instructions take
   two registers, and override one of them with the result (_i.e._
   they have the form `x ^= y` rather than `x = y ^ z`). Some
   variables must therefore be saved (using a `mov`) before being
   overwritten with a new result. Combined with spilling, this means
   that about half the instructions of the bitslice adders are
   moves. Even though they execute on different ports than bitswise
   instructions (ports 2, 3, 4), this introduces dependencies, and is
   enough to slightly slow down the bitslice adders.
   
   
Since the CPU can do 4 GP bitwise instructions per cycle, and only 3
SSE (port 6 has only a general purpose ALU, not a vectorized one), the
GP adders should be faster than the SSE ones. However, the SSE adders
use 16 registers, while the GP ones use only 14 registers: one
registers is reserved to store the stack pointer, and another one
keeps the loop counter. This cause the GP adders to do more spilling
than the SSE ones. Overall, this two phenomenon balances each other,
which causes SSE and GP adders to have similar performances.



## Conclusion
