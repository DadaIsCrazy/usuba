---
layout: post
title: Usuba
date: "2020-02-24 00:00:00"
description: The Usuba language
lang: en
locale: en_US
author: Darius Mercadier
excerpt: 
comments: false
hidden: true
--- 

The Usuba language design is driven by a combination of algorithmic
and hardware-specific constraints. Algorithmically, implementing a
block cipher requires some discipline to achieve high throughput and
avoid timing attacks.  To get high throughput, we focus exclusively on
parallel modes of operation such as counter mode (CTR). This excludes
feedback modes, such as output feedback (OFB) and cipher block
chaining (CBC), delivering much lower throughput in software. We
translate this constraint by forbidding feedback loops in our
designs. An Usuba program can therefore be understood as a stateless
combinational circuit, parallelizable by design.

Processing independent blocks in parallel forbids us from using any
form of conditional execution. As is standard in GPU programming, we
resort to masking for conditionals, effectively wiring the two results
to a multiplexer. Usuba programs are thus immune to timing attacks
based on branch prediction, by construction. We are further able to
guarantee the absence of cache effects by forbidding data-dependent
access to memory. For example, we support lookup tables but compile
them to Boolean circuits.

Finally, Usuba must be expressive enough to describe hardware-oriented
ciphers (such as DES or Trivium, which are specified in terms of
Boolean operations) as well as software-oriented ciphers specified in
terms of affine transformations (such as AES and, more generally,
ciphers exploiting maximum distance separable matrices [1]). To
account for the former, Usuba provides abstractions to manipulate
vectors, such as extracting a single bit as well as splitting or
combining vectors. To account for the latter, Usuba handles the
matricial structure of each block of data, allowing bitlevel
operations to carry over such structured types while driving the
compiler into generating efficient SIMD code.  Altogether, Usuba
provides a vector-based programming model, similar in spirit to APL
[2], allowing us to work at the granularity of a single bit while
providing static type-checking and compilation to efficient code.

Usuba programs are also subject to architecture-specific
constraints. For instance, a cipher relying on 32-bit multiplication
is a poor candidate for bitslicing: this multiplication turns into a
genuine multiplier circuit simulated in software. Similarly, a cipher
relying on 6-bit arithmetic would be impossible to execute in vertical
slicing: the SIMD instruction sets manipulate quantities ranging from
bytes to zwords, leaving aside such an exotic word-size. We are
therefore in a rather peculiar situation where, on the one hand, we
would like to implement a cipher once, while, on the other hand, the
validity of our program depends on a combination of slicing mode and
target architecture.

How can we, at compile time, provide meaningful feedback to the Usuba
programmer so as to (always) generate high-throughput code? We address
this issue by introducing a type for structured blocks (Section 2.1)
upon which we develop a language (Section 2.2) supporting parametric
polymorphism (for genericity) and ad-hoc polymorphism (for
architecture-specific code generation) as well as a type system
(Section 2.3) ensuring that "well-typed programs do always vectorize".

### Data Layout

Our basic unit of computation is the block, i.e. a bitvector of
statically-known length. To account for its matricial struc- ture and
its intended parallelization, we introduce the type u<D>m×n to denote
n ∈ ℕ* registers of unsigned m-bit words (m ∈ N* and “u” stands for
“unsigned”) that we intend to parallelize using vertical (D = V) or
horizontal (D = H) SIMD instructions. A single m-bit value is thus
typed u<D>m×1, abbreviated u<D>m. This notation allows us to
unambiguously specify the data layout of the blocks processed by the
cipher. Consider the 64-bit input block b₀, b₁, ..., b₆₃ of the
Rectangle cipher, targeting 128-bit SSE registers. Bitsliced Rectangle
manipulates blocks of type u<V>1×64, i.e. each bit is dispatched to an
individual register (Figure 2a). A 16-bit vertical slicing of
Rectangle manipulates blocks of type u<V>16×4, i.e. each one of the 4
sub-blocks is dispatched to the first 16-bit element of 4 registers
(Figure 2b). Horizontal slicing has type u<H>16×4, i.e. each 16-bit
word is horizontally spread across each of the 16 packed elements of 4
SIMD registers (Figure 2c). Note that directions collapse in the case
of bitslicing, i.e. u<V>1×64 =~ u<H>1×64. Both cases amount to the
same layout, or put otherwise: vertical and horizontal slicing are two
(orthogonal!) generalizations of bitslicing.  For a given data layout,
throughput is maximized by filling the remaining bits of the registers
with subsequent blocks of the input stream, following the same
pattern. Thus, a vertical, 16-bit SIMD addition (`vpaddw`) in vertical
slicing will amount to performing an addition on 8 blocks in
parallel. We only need to specify the treatment of a single slice,
Usubac then automatically generates code that maximizes register
usage.  Transposing a sequence of input blocks in a form suitable for
parallel processing is fully determined by its type. Usubac
automatically synthesizes this function and we evaluate
its throughput in Section 4.3.  

### Syntax & Semantics 

In and of
itself, Usuba is an unsurprising dataflow language [1, 25]. We
introduce its syntax and semantics by way of an ex- ample: our
implementation of the Rectangle cipher (Figure 1), whose reference
implementation consists in 115 lines of C++.  In the following, we
shall leave types and typing aside, com- ing back to this point in
Section 2.3.  An Usuba program is composed of a totally ordered set of
nodes (here, SubColumn , ShiftRows and Rectangle ). The last node
plays the role of the main entry point: it will be compiled to a C
function. A node typically consists of an unordered system of
equations involving logic and arith- metic operators. The semantics is
defined extensionally as a solution to the system of equations,
i.e. an assignment of variables to values such that all the equations
hold.  Usuba also provides syntactic sugar for declaring lookup tables
(here, SubColumn ), useful for specifying S-boxes. Con- ceptually, a
lookup table is an array: the n-bit input indexes into an array of 2 n
possible output values. However, to max- imize throughput and avoid
cache timing attacks, the com- piler expands lookup tables to Boolean
circuits. For prototyp- ing purposes, Usuba uses an elementary logic
synthesis al- gorithm based on binary decision diagrams (BDD)
–inspired by [67]– to perform this expansion. The circuits generated
by this tool are hardly optimal: finding optimal representa- tions of
S-boxes is a full time occupation for cryptographers, often involving
months of exhaustive search [23, 44, 61, 70].  Usuba integrates these
hard-won results into a database of known circuits, which is searched
before trying to convert any lookup table to a circuit. For instance,
Rectangle’s S-box ( SubColumn ) is replaced with the following node:
node SubColumn (a:v4) returns (b:v4) vars t1:v1, t2:v1, t3:v1, t4:v1,
t5:v1, t6:v1, t7:v1, t8:v1, t9:v1, t10:v1, t11:v1, t12:v1 let t1 =
~a[1]; t2 = a[0]&t1; t3 = a[2]^a[3]; b[0] = t2^t3; t5 = a[3]|t1; t6 =
a[0]^t5; b[1] = a[2]^t6; t8 = a[1]^a[2]; t9 = t3&t6; b[3] = t8^t9; t11
= b[0]|t8; b[2] = t6^t11 telUsuba: High-Throughput and Constant-Time
Ciphers, by Construction Syntactically, our treatment of vectors stems
from the work on hardware synthesis of synchronous dataflow pro- grams
[69]. In effect, we are merely describing “software circuits”. Many
programming idioms found in hardware syn- thesis, which would be
extremely inefficient in general, can be efficiently implemented in
our setting. In bitsliced mode, we can for example permute the 4 th
and 13 th bit of a 16-bit word at no run-time cost: this amounts to
statically swap- ping the names of the registers holding the 4 th and
13 th bits throughout the rest of the program.  Given a vector x of
size n (thus, of type τ [n]), we can obtain the element x[k] at
position 0 ≤ k < n and the consecutive elements x[k..l] in the range 0
≤ k < l < n. This syntax is instrumental for writing concise
bit-twiddling code. Indices must be known at compile-time, since
variable indices could compromise the constant-time property of the
code. The type-checker can therefore prevent out-of-bounds accesses.
Noticeably, vectors are maintained in a flattened form.  Given two
vectors x and y of size, respectively, m and n, the variable z = (x,
y) is itself a vector of size m +n (not a pair of
vectors). Conversely, for a vector u of size m +n, the equation (x, y)
= u stands for x = u[0..n] and y = u[n..m + n].  To account for
repetitive definitions (such as the wiring of the 25 rounds of
Rectangle), the forall construct lets us declare a group of equations
within static bounds. Its semantics is intuitively defined by
macro-expansion: we can always translate it into a chunk of
inter-dependent equations.  However, in practice, the Usubac compiler
preserves this structure in its pipeline and may generate imperative
loops performing destructive updates (Section 3.2).  Some ciphers
(e.g. Chacha20, Serpent) are defined in a very imperative manner,
repetitively updating a local state. Writ- ing those ciphers in a
synchronous dataflow language can be tedious: it amounts to writing
code in static single assign- ment form (SSA). To simplify such codes,
Usuba provides an “imperative assignment” operator x := e . It
desugars into a standard equation with a fresh variable on the
left-hand side that is substituted for the updated state in later
equations.  The constructs introduced so far deal with the wiring and
structure of the dataflow graph. To compute, one must in- troduce
operators. Usuba supports bitwise logical operators (conjunction & ,
disjunction | , exclusive-or ^ and negation ~ ), arithmetic operators
(addition + , multiplication * and subtrac- tion - ), shifts of
vectors (left << and right >> ) and rotations of vectors (left <<< and
right >>> ). Their availability and exact semantics (esp., run-time
cost) depend on the slicing mode and the target architecture, as shown
next.  

### Type System 

#### Base types

For the purpose of interacting with
its crypto- graphic runtime, the interface of a block cipher is
specified in terms of the matricial type u D m × n, which documents
the layout of blocks coming in and out of the cipher.  PLDI ’19, June
22–26, 2019, Phoenix, AZ, USA We also have general vectors whose types
are τ [n], for any type τ . Now, consider the key schedule of vsliced
Rec- tangle: it is presented as an object key of type u V 16 × 4[26],
which is 26 quadruples of 16-bit words. To obtain the key at round 23,
we thus write key[23] while obtaining the 3 rd word of that key one
must write key[23][3]. The notation u D m × 4[26] indicates that
accesses must be performed in column-major order, i.e. as if we were
accessing an object of type u D m[26][4] (following C convention). In
fact, because vectors are kept flat, the types u D m[26][4] and u D m
× 4[26] are actually equivalent from the typechecker’s standpoint, the
compiler collapsing both types to u D m[104]. This appar- ent
redundancy is explained by the fact that types serve two purposes. In
the surface language, matricial types (u D m × 4) document the data
layout and its SIMDization. In the target language, the matricial
structure is irrelevant: an object of type u D m × 4[26] supports
exactly the same operations as an object of type u D m[26][4]. Surface
types are thus normalized, after type-checking, into distilled types.


### Parametric polymorphism. 

A final addition to our lan- guage of types
is the notion of parametric word size and parametric direction. A
cipher like Rectangle can in fact be sliced horizontally or
vertically: both modes of operation are compatible with the various
SIMD architectures intro- duced after SSSE3. Similarly, the node
SubColumn amounts to a Boolean circuit whose operations (&, |, ^, and
~) are defined for any atomic word size (ranging from a single Boolean
to a 512-bit AVX512 register): SubColumn thus applies to u D 1, u D 8,
etc. This completes the grammar of distilled types, including type
parameters in word size and direction: n ⟨τ ⟩ ⟨m⟩ ::=
|
|
‘m
n
∈ N
(integers)
::=
(types)
| u ⟨D⟩ ⟨m⟩ (base type)
| τ [n]
(vectors)
| nat
(constants)
(size)
(parameter)
(fixed size)
⟨D⟩
::=
|
|
|
‘D
V
H
(direction)
(parameter)
(vertical)
(horizontal)
Nodes being first-order functions, a function type is (at
most) rank-1 polymorphic: the polymorphic parameters it
may depend on are universally quantified over the whole
type (and node body). We use the abbreviation bn and um
for the type u ‘D 1 × n and, respectively, u ‘D m where ‘D is the
direction parameter in the nearest scope. Similarly, we write
vn for u ‘D ‘m × n when ‘m is the nearest word size parameter.

### Ad-hoc polymorphism

In reality, very few programs are
defined for any word size or any direction. Only Boolean
circuits are direction polymorphic, bitwise logical operations
applying uniformly. Also, no program is absolutely paramet-
ric in the word size: we can only compute up to the register
size of the underlying architecture.PLDI ’19, June 22–26, 2019, Phoenix, AZ, USA
Darius Mercadier and Pierre-Évariste Dagand
Table 1. Operator instances.
Class
Logic(τ )
Arith(τ )
Shift(τ )
Instances
Logic(τ ) ⇒ Logic(τ [n])
for n ∈ N
Logic(u ‘D m) for m ∈ [1, 64]
Logic(u ‘D m) for m ∈ [65, 128]
Logic(u ‘D m) for m ∈ [129, 256]
Logic(u ‘D m) for m ∈ [257, 512]
Arith(τ ) ⇒ Arith(τ [n])
for n ∈ N
Arith(u V 8)
Arith(u V 16)
Arith(u V 32)
Arith(u V 64)
Shift(τ [n]) for n ∈ N
Shift(u V ‘m),
⇒ Shift(u ‘D ‘m)
Shift(u H ‘m)
Shift(u V 16)
Shift(u V 32)
Shift(u V 64)
Shift(u H 2)
Shift(u H 4)
Shift(u H 8)
Shift(u H 16)
Shift(u H 32)
Shift(u H 64)
Architecture Compiled with
all homomorphic application (n instr.)
≥ x86-64
≥ SSE
≥ AVX
≥ AVX512 and, or, etc. (1 instr.)
all homomorphic application (n instr.)
≥ SSE
vpadd, vpsub, etc. (1 instr.)
≥ AVX2
all variable renaming (0 instr.)
all depends of instance
≥ SSE
vpsrl/vpsll (≤ 3 instr.)
≥ AVX2
≥ SSE
vpshuf (1 instr.)
≥ AVX512
To capture these invariants, we introduce a form of bounded
polymorphism through type-classes [71]. Whether a given
cipher can be implemented over a collection of word size
and/or direction is determined by the availability of logical
and arithmetic operators. We therefore introduce three type-
classes for logical, arithmetic and shift/rotate operations:
Logic(τ ) :
Arith(τ ) :
Shift(τ ) :
& :τ → τ → τ
+ :τ → τ → τ
>> :τ → nat → τ
| :τ → τ → τ
* :τ → τ → τ
<< :τ → nat → τ
^ :τ → τ → τ
- :τ → τ → τ
>>> :τ → nat → τ
~ :τ → τ
<<< :τ → nat → τ
The implementations of these classes depend on the type
considered and the target architecture. For instance, arith-
metic on 13-bit words is impossible, even in vertical mode.
The generated code also depends on a combination of types
and target architecture. For instance, shifting a vector amounts
to renaming registers whereas shifting in horizontal mode
requires an actual shuffle instruction. We chose to provide
instances solely for operations that can be implemented stat-
ically or with a handful of instructions.
Our type-class mechanism is not user-extensible. The list
of all the possible type-classes instances is summarized in
Table 1. This set of instances is obviously non-overlapping so
our overloading mechanism is coherent: if the type-checker
succeeds in finding an instance for the target architecture,
then that instance is unique.


### Type-checking

Despite its unusual combination of features,
Usuba’s type system is rather unsurprising. First, it is applied
to a first-order and explicitly-typed language, thus requiring
no type inference. Second, vectors – while perhaps intimidat-
ing – can only take statically-known sizes: we are far away
from the realm of dependent types, merely touching upon
phantom types techniques. The combination of prenex poly-
morphism and type-classes is well understood. We therefore
refrain from further expounding our type system.
As a result of these features, our generic implementation of
Rectangle type-checks as-is when targeting any instruction
set beyond SSE, meaning that it can be sliced vertically or
horizontally. In Section 3.1, we shall describe the mechanisms
at our disposal to produce vertically or horizontally sliced C
code as well as for extracting a bitsliced implementation.


---

## References


[1] S. Duval, G. Leurent, [MDS Matrices with Lightweight Circuits](https://eprint.iacr.org/2018/260.pdf), IACR Trans. Symmetric Cryptol. 2018.

[2] K. E. Iverson, [Notation as a Tool of Thought](https://m-cacm.acm.org/magazines/1980/8/10988-notation-as-a-tool-of-thought/pdf), Commun. ACM 23, 1980.
