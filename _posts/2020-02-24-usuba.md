---
layout: post
title: Usuba
date: "2020-02-24 00:00:00"
description: The Usuba language
lang: en
locale: en_US
author: Darius Mercadier
excerpt: 
comments: false
hidden: true
--- 

The Usuba language design is driven by a combination of algorithmic
and hardware-specific constraints. Algorithmically, implementing a
block cipher requires some discipline to achieve high throughput and
avoid timing attacks.  To get high throughput, we focus exclusively on
parallel modes of operation such as counter mode (CTR). This excludes
feedback modes, such as output feedback (OFB) and cipher block
chaining (CBC). We translate this constraint by forbidding feedback
loops in our designs. An Usuba program can therefore be understood as
a stateless combinational circuit, parallelizable by design.

Processing independent blocks in parallel forbids us from using any
form of conditional execution. As is standard in GPU programming, we
resort to masking for conditionals, effectively wiring the two results
to a multiplexer, as shown in [Post 2: Bitslicing]({{ site.baseurl}}
{% post_url 2020-01-14-bitslicing %}). Usuba programs are thus immune 
to timing attacks based on branch prediction, by construction. We are
further able to guarantee the absence of cache effects by forbidding
data-dependent access to memory. For example, we support lookup tables
but compile them to Boolean circuits.

Finally, Usuba must be expressive enough to describe hardware-oriented
ciphers (such as DES or Trivium, which are specified in terms of
Boolean operations) as well as software-oriented ciphers specified in
terms of affine transformations (such as AES and, more generally,
ciphers exploiting maximum distance separable matrices [1]). To
account for the former, Usuba provides abstractions to manipulate
vectors, such as extracting a single bit as well as splitting or
combining vectors. To account for the latter, Usuba handles the
matricial structure of each block of data, allowing bit-level
operations to carry over such structured types while driving the
compiler into generating efficient SIMD code.  Altogether, Usuba
provides a vector-based programming model, similar in spirit to APL
[2], allowing us to work at the granularity of a single bit while
providing static type-checking and compilation to efficient code.

Usuba programs are also subject to architecture-specific
constraints. For instance, a cipher relying on 32-bit multiplication
is a poor candidate for bitslicing: this multiplication turns into a
genuine multiplier circuit simulated in software. Similarly, a cipher
relying on 6-bit arithmetic would be impossible to execute in vertical
slicing: the SIMD instruction sets manipulate bytes as well as 16-bit,
32-bit and 64-bit words, leaving aside such an exotic word-size. We
are therefore in a rather peculiar situation where, on the one hand,
we would like to implement a cipher once, while, on the other hand,
the validity of our program depends on a combination of slicing mode
and target architecture.

How can we, at compile time, provide meaningful feedback to the Usuba
programmer so as to (always) generate high-throughput code? We address
this issue by introducing a type for structured blocks (Section Data
Layout) upon which we develop a language (Section Syntax & Semantics)
supporting parametric polymorphism (for genericity) and ad-hoc
polymorphism (for architecture-specific code generation) as well as a
type system (Section Type System) ensuring that "well-typed programs
do always vectorize".

### Data Layout

Our basic unit of computation is the block, *i.e.* a bitvector of
statically-known length. To account for its matricial structure and
its intended parallelization, we introduce the type `u<D>m×n` to denote
_n_ ∈ ℕ* registers of unsigned _m_-bit words (_m_ ∈ ℕ* and "u" stands for
"unsigned") that we intend to parallelize using vertical (_D_ = _V_) or
horizontal (_D_ = _H_) SIMD instructions. A single m-bit value is thus
typed `u<D>m×1`, abbreviated `u<D>m`. This notation allows us to
unambiguously specify the data layout of the blocks processed by the
cipher. Consider the 64-bit input block of the Rectangle cipher:

<p align="center">
<img src="{{ site.baseurl }}/assets/images/blog/rect-data-init.png">
</p>

Bitsliced Rectangle manipulates blocks of type `u<D>1×64`, i.e. each bit
is dispatched to an individual register:

<p align="center">
<img src="{{ site.baseurl }}/assets/images/blog/rect-data-bs.png">
</p>

The gray parts of the registers contains bits from other inputs,
processed in parallel with the first one (in blue). A 16-bit vertical
slicing of Rectangle manipulates blocks of type `u<V>16×4`, _i.e._
each one of the 4 sub-blocks is dispatched to the first 16-bit element
of 4 registers:

<p align="center">
<img src="{{ site.baseurl }}/assets/images/blog/rect-data-vs.png">
</p>

The double vertical lines represent the end of each 16-bit packed
elements. Horizontal slicing has type `u<H>16×4`, i.e. each 16-bit
word is horizontally spread across each of the 16 packed elements of 4
SIMD registers:

<p align="center">
<img src="{{ site.baseurl }}/assets/images/blog/rect-data-hs.png">
</p>

Note that directions collapse in the case of bitslicing,
_i.e._ `u<V>1×64` ≅ `u<H>1×64`. Both cases amount to the same layout, or
put otherwise: vertical and horizontal slicing are two (orthogonal!)
generalizations of bitslicing.

For a given data layout, throughput is maximized by filling the
remaining bits of the registers with subsequent blocks of the input
stream, following the same pattern. Thus, a vertical, 16-bit SIMD
addition (_e.g._ `vpaddw` on AVX) in vertical slicing will amount to
performing an addition on 8 blocks in parallel. We empathize that the
types merely describe the structures of the blocks, and do not specify
the parallelization strategy, nor the architecture to be used. We only
need to specify the treatment of a single slice, Usubac then
automatically generates code that maximizes register usage.
Transposing a sequence of input blocks in a form suitable for parallel
processing is fully determined by its type.


### Syntax & Semantics 

In and of itself, Usuba is an unsurprising dataflow language [3,
4]. We introduce its syntax and semantics by way of an example: our
implementation of the Rectangle cipher:

```lustre
table SubColumn (in:v4) returns (out:v4) {
    6 , 5, 12, 10, 1, 14, 7, 9,
    11, 0, 3 , 13, 8, 15, 4, 2
}

node ShiftRows (input:u16[4]) returns (out:u16[4])
let
    out[0] = input[0];
    out[1] = input[1] <<< 1;
    out[2] = input[2] <<< 12;
    out[3] = input[3] <<< 13
tel

node Rectangle (plain:u16[4],key:u16[26][4])
       returns (cipher:u16[4])
vars round : u16[26][4]
let
    round[0] = plain;
    forall i in [0,24] {
        round[i+1] = ShiftRows(SubColumn(round[i] ^ key[i]))
    }
    cipher = round[25] ^ key[25]
tel
```

In the following, we shall leave types and typing aside, coming back
to this point in the next section. An Usuba program is composed of a
totally ordered set of nodes (here, `SubColumn` , `ShiftRows` and
`Rectangle`). The last node plays the role of the main entry point: it
will be compiled to a C function. A node typically consists of an
unordered system of equations involving logic and arithmetic
operators. The semantics is defined extensionally as a solution to the
system of equations, _i.e._ an assignment of variables to values such
that all the equations hold.

Usuba also provides syntactic sugar for declaring lookup tables (here,
`SubColumn`), useful for specifying S-boxes. Conceptually, a lookup
table is an array: a _n_-bit input indexes into an array of 2ⁿ
possible output values. However, to maximize throughput and avoid
cache timing attacks, the compiler expands lookup tables to Boolean
circuits. For prototyping purposes, Usuba uses an elementary logic
synthesis algorithm based on binary decision diagrams (BDD) –inspired
by [5]– to perform this expansion. The circuits generated by this tool
are hardly optimal: finding optimal representations of S-boxes is a
full time occupation for cryptographers, often involving months of
exhaustive search [6, 7, 8, 9].  Usuba integrates these hard-won
results into a database of known circuits, which is searched before
trying to convert any lookup table to a circuit. For instance,
Rectangle’s S-box (`SubColumn`) is replaced with the following node:

```lustre
node SubColumn (a:v4) returns (b:v4)
  vars t1,t2,t3,t4,t5,t6,t7,t8,t9,t10,t11,t12 : v1
  let 
    t1   = ~a[1]; 
    t2   = a[0] & t1; 
    t3   = a[2] ^ a[3];
    b[0] = t2 ^ t3; 
    t5   = a[3] | t1; 
    t6   = a[0] ^ t5; 
    b[1] = a[2] ^ t6; 
    t8   = a[1] ^ a[2]; 
    t9   = t3 & t6; 
    b[3] = t8 ^ t9; 
    t11  = b[0] | t8; 
    b[2] = t6 ^ t11
tel
```

Syntactically, our treatment of vectors stems from the work on
hardware synthesis of synchronous dataflow programs [10]. <!-- In effect,
we are merely describing "software circuits". Many programming idioms
found in hardware synthesis, which would be extremely inefficient in
general, can be efficiently implemented in our setting. For instance,
as shown in [Post 2: Bitslicing]({{ site.baseurl
}}{% post_url 2020-01-14-bitslicing %}), in bitsliced mode, 
permutations can be done at compile-time.-->  Given a vector `x` of size
_n_ (thus, of type `τ[n]`), we can obtain the element `x[k]` at
position 0 ≤ _k_ < _n_ and the consecutive elements `x[k..l]` in the
range 0 ≤ _k_ < _l_ < _n_. This syntax is instrumental for writing
concise bit-twiddling code. Indices must be known at compile-time,
since variable indices could compromise the constant-time property of
the code. The type-checker can therefore prevent out-of-bounds
accesses. Noticeably, vectors are maintained in a flattened
form. Given two vectors `x` and `y` of size, respectively, _m_ and
_n_, the variable `z = (x, y)` is itself a vector of size _m+n_ (not a
pair of vectors). Conversely, for a vector `u` of size _m+n_, the
equation `(x, y) = u` stands for `x = u[0..n]` and `y = u[n..m + n]`.

To account for repetitive definitions (such as the wiring of the 25
rounds of Rectangle), the `forall` construct lets us declare a group
of equations within static bounds. Its semantics is intuitively
defined by macro-expansion: we can always translate it into a chunk of
inter-dependent equations. However, in practice, the Usubac compiler
preserves this structure in its pipeline and may generate imperative
loops performing destructive updates (Section 3.2). 

Some ciphers (e.g. Chacha20, Serpent) are defined in a very imperative
manner, repetitively updating a local state. Writing those ciphers in
a synchronous dataflow language can be tedious: it amounts to writing
code in static single assignment form (SSA). To simplify such codes,
Usuba provides an "imperative assignment" operator `x := e`. It
desugars into a standard equation with a fresh variable on the
left-hand side that is substituted for the updated state in later
equations.  

The constructs introduced so far deal with the wiring and structure of
the dataflow graph. To compute, one must introduce operators. Usuba
supports bitwise logical operators (conjunction `&`, disjunction `|`,
exclusive-or `^` and negation `~`), arithmetic operators (addition
`+`, multiplication `*` and subtraction `-`), shifts of vectors (left
`<<` and right `>>`), rotations of vectors (left `<<<` and right
`>>>`), and intra-register bit shuffling (`Shuffle`). Their
availability and exact semantics (especially, run-time cost) depend on
the slicing mode and the target architecture, as shown next.  

### Type System 

#### Base types

For the purpose of interacting with its cryptoraphic runtime, the
interface of a block cipher is specified in terms of the matricial
type `u<D>m×n`, which documents the layout of blocks coming in and out
of the cipher. We also have general vectors whose types are `τ[n]`,
for any type `τ`. Now, consider the subkeys used by vsliced Rectangle:
they are presented as an object key of type `u<V>16×4[26]`, which is
26 quadruples of 16-bit words. To obtain the key at round 23, we thus
write `key[23]` while obtaining the 3rd word of that key one must
write `key[23][3]`. The notation `u<D>m×4[26]` indicates that accesses
must be performed in column-major order, _i.e._ as if we were
accessing an object of type `u<D>m[26][4]` (following C
convention). In fact, because vectors are kept flat, the types
`u<D>m[26][4]` and `u<D>m×4[26]` are actually equivalent from the
typechecker's standpoint. This apparent redundancy is explained by the
fact that types serve two purposes. In the surface language, matricial
types (`u<D>m×4`) document the data layout and its SIMDization. In the
target language, the matricial structure is irrelevant: an object of
type `u<D>m×4[26]` supports exactly the same operations as an object
of type `u<D>m[26][4]`. Surface types are thus normalized, after
type-checking, into distilled types.


### Parametric polymorphism. 

A final addition to our language of types is the notion of parametric
word size and parametric direction. A cipher like Rectangle can in
fact be sliced horizontally or vertically: both modes of operation are
compatible with the various SIMD architectures introduced after
SSSE3. Similarly, the node `SubColumn` amounts to a Boolean circuit
whose operations (`&`, `|`, `^`, and `~`) are defined for any atomic
word size (ranging from a single Boolean to a 512-bit AVX512
register): `SubColumn` thus applies to `u<D>1`, `u<D>8`, etc. This
completes the grammar of distilled types, including type parameters in
word size and direction: 

<p style="margin:20px;margin-left:80px">

<b>n</b> ∈ ℕ <span style="display:inline-block;width:95px"></span>(integers)<br/>
<br/>
⟨<b>τ</b>⟩ ::=    <span style="display:inline-block;width:85px"></span> (types)<br/>
&nbsp;&nbsp;| u&lt;<b>D</b>&gt;⟨<b>m</b>⟩ <span style="display:inline-block;width:58px"></span>(base type)<br/>
&nbsp;&nbsp;| <b>τ</b>[<b>n</b>]       <span style="display:inline-block;width:70px"></span> (vectors)<br/>
&nbsp;&nbsp;| nat        <span style="display:inline-block;width:80px"></span> (constants)<br/>
<br/>
⟨<b>m</b>⟩ ::=      <span style="display:inline-block;width:84px"></span> (size)<br/>
&nbsp;&nbsp;| <i style="color:red">‘m</i>         <span style="display:inline-block;width:85px"></span> (parameter)<br/>
&nbsp;&nbsp;| <b>n</b>          <span style="display:inline-block;width:95px"></span> (fixed size)<br/>
<br/>
⟨<b>D</b>⟩ ::=      <span style="display:inline-block;width:80px"></span> (direction)<br/>
&nbsp;&nbsp;| <i style="color:red">‘D</i>        <span style="display:inline-block;width:80px"></span> (parameter)<br/>
&nbsp;&nbsp;| V         <span style="display:inline-block;width:90px"></span> (vertical)<br/>
&nbsp;&nbsp;| B         <span style="display:inline-block;width:90px"></span> (horizontal)<br/>

</p>


Nodes being first-order functions, a function type is (at most) rank-1
polymorphic: the polymorphic parameters it may depend on are
universally quantified over the whole type (and node body). We use the
abbreviation `bn` and `um` for the type <code>u&lt;<i
style="color:red">‘D</i>&gt;1×n</code> and, respectively,
<code>u&lt;<i style="color:red">‘D</i>&gt;m×1</code> where <i
style="color:red">‘D</i> is the direction parameter in the nearest
scope. Similarly, we write `vn` for <code>u&lt;<i
style="color:red">‘D</i>&gt;<i style="color:red">‘m</i>×n</code> when
<i style="color:red">‘m</i> is the nearest word size parameter.

### Ad-hoc polymorphism

In reality, very few programs are defined for any word size or any
direction. Only Boolean circuits are direction polymorphic, bitwise
logical operations applying uniformly. Also, no program is absolutely
parametric in the word size: we can only compute up to the register
size of the underlying architecture.




To capture these invariants, we introduce a form of bounded
polymorphism through type-classes [11]. Whether a given cipher can be
implemented over a collection of word size and/or direction is
determined by the availability of logical and arithmetic operators. We
therefore introduce four type-classes for logical, arithmetic,
shift/rotate and shuffle operations:

```
Logic(τ) :          Arith(τ) :             Shift(τ) :
 & : τ → τ → τ        + : τ → τ → τ            >> : τ → nat → τ
 | : τ → τ → τ        * : τ → τ → τ            << : τ → nat → τ
 ^ : τ → τ → τ        - : τ → τ → τ           >>> : τ → nat → τ
 ~ : τ → τ                                    <<< : τ → nat → τ
 
Shuffle(τ) :
 Shuffle:  τ → nat list → τ
```

The implementations of these classes depend on the type considered and
the target architecture. For instance, arithmetic on 13-bit words is
impossible, even in vertical mode. The generated code also depends on
a combination of types and target architecture. For instance, shifting
a vector amounts to renaming registers whereas shifting in horizontal
mode requires an actual shuffle instruction. We chose to provide
instances solely for operations that can be implemented statically or
with a handful of instructions, with the exceptions of `Shuffle`,
which is made available in vertical mode despite its large cost. Our
type-class mechanism is not user-extensible. The list of all the
possible type-classes instances is summarized in the following
table. This set of instances is obviously non-overlapping so our
overloading mechanism is coherent: if the type-checker succeeds in
finding an instance for the target architecture, then that instance is
unique.


<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;margin-left:auto;margin-right:auto;margin-bottom:20px;margin-top:20px}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}
.tg .tg-cly1{text-align:center;vertical-align:middle}
.tg .tg-9wq8{border-color:inherit;text-align:center;vertical-align:middle}
.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
.tg .tg-73oq{border-color:#000000;text-align:center;vertical-align:middle}
.tg .tg-0a7q{border-color:#000000;text-align:center;vertical-align:middle}
.tg .tg-0lax{text-align:center;vertical-align:top}
.tg .tg-nrix{text-align:center;vertical-align:middle}
.tg .tg-lboi{border-color:inherit;text-align:center;vertical-align:middle}
.tg .tg-0pky{border-color:inherit;text-align:center;vertical-align:top}
</style>
<table class="tg">
  <tr>
    <th class="tg-c3ow">Class</th>
    <th class="tg-c3ow" colspan="2">Instances<br></th>
    <th class="tg-c3ow">Architecture<br></th>
    <th class="tg-c3ow">Compiled with</th>
  </tr>
  <tr>
    <td class="tg-9wq8" rowspan="2">Logic(<code>τ</code>)</td>
    <td class="tg-c3ow" colspan="2">Logic(<code>τ</code>) ⇒ Logic(<code>τ[<i>n</i>]</code>) <br>           for <i>n</i> ∈ ℕ</td>
    <td class="tg-9wq8">all</td>
    <td class="tg-73oq">homomorphic application (<i>n</i> instr.)</td>
  </tr>
  <tr>
    <td class="tg-c3ow" colspan="2">Logic(<code>u&lt;<i style="color:red">‘D</i>&gt;<i>m</i></code>) for <i>m</i> ∈ [1, 64]<br>Logic(<code>u&lt;<i style="color:red">‘D</i>&gt;<i>m</i></code>) for <i>m</i> ∈ [65, 128]<br>Logic(<code>u&lt;<i style="color:red">‘D</i>&gt;<i>m</i></code>) for <i>m</i> ∈ [129, 256]<br>Logic(<code>u&lt;<i style="color:red">‘D</i>&gt;<i>m</i></code>) for <i>m</i> ∈ [257, 512]</td>
    <td class="tg-c3ow">≥ x86-64<br>≥ SSE<br>≥ AVX<br>≥ AVX512<br></td>
    <td class="tg-0a7q"><code>and</code>, <code>or</code>, etc (1 instr.)</td>
  </tr>
  <tr>
    <td class="tg-9wq8" rowspan="2">Arith(<code>τ</code>)</td>
    <td class="tg-c3ow" colspan="2">Arith(<code>τ</code>) ⇒ Arith(<code>τ[<i>n</i>]</code>)<br>for <i>n</i> ∈ ℕ<br></td>
    <td class="tg-9wq8">all</td>
    <td class="tg-0a7q">homomorphic application (<i>n</i> instr.)</td>
  </tr>
  <tr>
    <td class="tg-c3ow" colspan="2">Arith(<code>u&lt;V&gt;8</code>)<br>Arith(<code>u&lt;V&gt;16</code>)<br>Arith(<code>u&lt;V&gt;32</code>)<br>Arith(<code>u&lt;V&gt;64</code>)</td>
    <td class="tg-9wq8">all</td>
    <td class="tg-0a7q"><code>add</code>, <code>vpadd</code>, <code>vpsub</code>, etc. (1 instr.)</td>
  </tr>
  <tr>
    <td class="tg-9wq8" rowspan="5">Shift(<code>τ</code>)</td>
    <td class="tg-c3ow" colspan="2">Shift(<code>τ[<i>n</i>]</code>) for <i>n</i> ∈ ℕ</td>
    <td class="tg-c3ow">all</td>
    <td class="tg-73oq">variable renaming (0 instr.)</td>
  </tr>
  <tr>
    <td class="tg-0lax" style="border-right:0">Shift(<code>u&lt;V&gt;<i style="color:red">‘m</i></code>),<br>Shift(<code>u&lt;H&gt;<i style="color:red">‘m</i></code>)<br></td>
    <td class="tg-cly1" style="border-left:0">⇒ Shift(<code>u&lt;‘<i>D</i>&gt;<i style="color:red">‘m</i></code>)</td>
    <td class="tg-nrix">all</td>
    <td class="tg-cly1">depends of instance</td>
  </tr>
  <tr>
    <td class="tg-0lax" colspan="2">Shift(<code>u&lt;V&gt;16</code>)<br>Shift(<code>u&lt;V&gt;32</code>)<br>Shift(<code>u&lt;V&gt;64</code>)</td>
    <td class="tg-cly1">all</td>
    <td class="tg-cly1"><code>vpsrl</code>/<code>vpsll</code> (≤ 3 instr.)</td>
  </tr>
  <tr>
    <td class="tg-0lax" colspan="2">Shift(<code>u&lt;H&gt;2</code>)<br>Shift(<code>u&lt;H&gt;4</code>)<br>Shift(<code>u&lt;H&gt;8</code>)<br>Shift(<code>u&lt;H&gt;16</code>)<br></td>
    <td class="tg-cly1">≥ SSE</td>
    <td class="tg-cly1" rowspan="2"><code>vpshuf</code> (1 instr.)</td>
  </tr>
  <tr>
    <td class="tg-0lax" colspan="2">Shift(<code>u&lt;H&gt;32</code>)<br>Shift(<code>u&lt;H&gt;64</code>)<br></td>
    <td class="tg-cly1">≥ AVX512</td>
  </tr>
  <tr>
    <td class="tg-lboi" rowspan="4">Shuffle(<code>τ</code>)</td>
    <td class="tg-0pky" colspan="2">Shuffle(<code>u&lt;H&gt;2</code>)<br>Shuffle(<code>u&lt;H&gt;4</code>)<br>Shuffle(<code>u&lt;H&gt;8</code>)<br>Shuffle(<code>u&lt;H&gt;16</code>)<br></td>
    <td class="tg-lboi">&gt;= SSE</td>
    <td class="tg-lboi" rowspan="2"><code>vpshuf</code> (1 instr.)</td>
  </tr>
  <tr>
    <td class="tg-0pky" colspan="2">Shuffle(<code>u&lt;H&gt;32</code>)<br>Shuffle(<code>u&lt;H&gt;64</code>)<br></td>
    <td class="tg-lboi">&gt;= AVX512</td>
  </tr>
  <tr>
    <td class="tg-0pky" colspan="2">Shuffle(<code>u&lt;V&gt;16</code>)<br>Shuffle(<code>u&lt;V&gt;32</code>)<br></td>
    <td class="tg-lboi">&gt;= SSE</td>
    <td class="tg-lboi" rowspan="2"><code>vpsrl</code>/<code>vpsll</code>/<code>vpand</code>/<code>vpxor</code><br> (<i>m * 4</i> instr.)</td>
  </tr>
  <tr>
    <td class="tg-0pky" colspan="2">Shuffle(<code>u&lt;V&gt;64</code>)</td>
    <td class="tg-0pky">&gt;= AVX512</td>
  </tr>
</table>

Both logical and arithmetic operators can be applied to an array of
size _n_, in which case they amount to _n_ element-wise applications
of the operator on each element of the array. Shifting an array on the
other hand is performed at the granularity of the element on arrays,
and amounts to statically renaming variables and shifting in
zeros. For instance, if we consider an array `x` of type `b1[4]`, `x
<< 2` is equivalent to `(x[0], x[1], x[2], x[3]) << 2`, which is
reduced at compile time to `(x[2], x[3], 0, 0)` (with the last two `0`
being of type `b1`).

Logic instructions can be applied on any non-array type for any
slicing, as long as the architecture offers large enough
registers. Arithmetic instructions on non-array types is only valid
for vslicing, and require some support from the underlying
architecture. In pratice, SSE, AVX, AVX2 and AVX512 all offer
instruction to do 8-bit, 16-bit, 32-bit and 64-bit arithmetics. Shifts
for vertical slicing can on 16-bit, 32-bit and 64-bit use CPU shift
instructions (`vpsrl` `vpsll` on AVX2, `shr` and `shl` on general
purpose x86). Shifts in horizontal slicing are compiled using shuffle
instructions (`vpshufd`, `vpshufb`, _etc._). For instance, consider a
variable `x` of type `u16`: hifting right this variable by 2 is done
using the shuffle pattern `[-1,-1,15,14,13,12,11,10,9,8,7,6,5,4,3,2]`
(`-1` in the pattern causes a `0` to be introduced). SIMD registers
older AVX512 only offer shuffles for up to 16 elements, while AVX512
goes also provide 32 and 64 elements shuffle, thus allowing us to
compile 64-bit shifts. Shuffle instruction in horizontal mode map
naturally to SIMD shuffle instructions. And finally, Shuffle
instructions in vertical mode are compiled to shifts moving each bit
in a register. For instance, shuffling a variable `x` of type `u8`
with the pattern `[5,2,0,1,7,6,4,3]` produces the following code:

```c
((x << 5) & 128) ^
((x << 1) & 64)  ^
((x >> 2) & 32)  ^
((x >> 2) & 16)  ^
((x >> 3) & 8)   ^
((x << 1) & 4)   ^
((x >> 2) & 2)   ^
((x >> 4) & 1)
```

<!--
<pre><code>
<b>nd</b>  ::=                                            (node declaration)
     |  node <i>id</i>(<b>tv</b><sup>+</sup>) returns (<b>tv</b><sup>+</sup>)                  (simple node)
         vars <b>tv</b><sup>+</sup> 
         let <b>eq</b><sup>+</sup> tel
     | table <i>id</i>(<b>tv</b><sup>+</sup>) returns (<b>tv</b><sup>+</sup>) { <i>n</i><sup>+</sup> }        (table)
     | perm <i>id</i>(<b>tv</b><sup>+</sup>) returns (<b>tv</b><sup>+</sup>) { <i>n</i><sup>+</sup> }         (permutation)
     | node[] <i>id</i>(<b>tv</b><sup>+</sup>) returns (<b>tv</b><sup>+</sup>) { <b>nd</b><sup>+</sup> }      (array of nodes)
               
<b>tv</b> ::= <i>id</i> : <b>typ</b>                (variable declaration)

<b>typ</b> ::=  <b>typ</b>[<i>n</i>]                (array type)
         | u&lt;<b>D</b>&gt;<i>m</i>×<i>n</i>             (<i>n</i> <i>m</i>-bit atoms with slicing direction <i>D</i>)
         | u<i>m</i>×<i>n</i>                (<i>n</i> <i>m</i>-bit atoms, direction polymorphic)
         | u&lt;<b>D</b>&gt;<i>m</i>               (1 <i>m</i>-bit atom with direction <i>D</i>)
         | b<i>n</i>                  (<i>n</i> 1-bit atoms (direction agnostic))
         | u<i>m</i>                  (1 <i>m</i>-bit atom, polymorphic direction)
         | v<i>n</i>                  (<i>n</i> atoms of polymorphic size and direction)

<b>D</b> ::= V          (vslicing)
     | H         (hslicing)
         
<b>eqs</b> ::=            (list of equations)
    <b>eq</b> | <b>eq</b> ; <b>eqs</b>

<b>eq</b> ::=             (equation)
    | forall <i>i</i> in [<b>aexpr</b>,<b>aexpr</b>] { <b>eqs</b> }       (universally quantified equation)
    | <b>lhs</b> = <b>expr</b>                               (equation)

<b>lhs</b> ::=                    (left hand-side of an equation)
   <b>var</b> | (<b>var</b><sup>+</sup>)

<b>var</b> ::=                      (variable)
    | <i>x</i>                      (variable)
    | <i>x</i>[<b>aexpr</b>]               (array index)
    | <i>x</i>[<b>aexpr</b><sup>+</sup>]      (array slice)
    | <i>x</i>[<b>aexpr</b> ... <b>aexpr</b>]     (array range)
    
<b>expr</b> ::=                       (expression)
    | <b>var</b>                      (variable)
    | <i>n</i>                        (integer)
    | (<b>expr</b><sup>+</sup>)            (tuple)
    | <b>unop</b> <b>expr</b>                (unary operation)
    | <b>expr</b> <b>binop</b> <b>expr</b>          (binary operation)
    | <b>expr</b> <b>shiftop</b> <b>aexpr</b>        (shift)
    | Shuffle(<b>var</b>, [<i>n</i><sup>+</sup>])   (shuffle)
    | <i>f</i>(<b>expr</b><sup>+</sup>)          (function call)
    | <i>f</i>&lt;<i>n</i>&gt;(<b>expr</b><sup>+</sup>)       (function call in an array of function)

</code>
</pre>

-->



### Type-checking

Despite its unusual combination of features, Usuba's type system is
rather unsurprising. First, it is applied to a first-order and
explicitly-typed language, thus requiring no type inference. Second,
vectors –while perhaps intimidating– can only take statically-known
sizes: we are far away from the realm of dependent types, merely
touching upon phantom types techniques. The combination of prenex
polymorphism and type-classes is well understood. We therefore refrain
from further expounding our type system.  As a result of these
features, our generic implementation of Rectangle type-checks as-is
when targeting any instruction set beyond SSE, meaning that it can be
sliced vertically or horizontally. In Section 3.1, we shall describe
the mechanisms at our disposal to produce vertically or horizontally
sliced C code as well as for extracting a bitsliced implementation.


---

## References


[1] S. Duval, G. Leurent, [MDS Matrices with Lightweight Circuits](https://eprint.iacr.org/2018/260.pdf), IACR Trans. Symmetric Cryptol. 2018.

[2] K. E. Iverson, [Notation as a Tool of Thought](https://m-cacm.acm.org/magazines/1980/8/10988-notation-as-a-tool-of-thought/pdf), Commun. ACM 23, 1980.

[3]  [IEEE Standard VHDL Language Reference Manual](https://edg.uchicago.edu/~tang/VHDLref.pdf), 2000.

[4] P. Caspi _et al._, [LUSTRE: A declarative language for programming synchronous systems](https://www.cse.unsw.edu.au/~plaice/archive/JAP/P-ACM_POPL87-lustre.pdf), POPL, 1987.

[5] T. Pornin, [Constant-time mul](https://www.bearssl.org/ctmul.html), accessed 12/2019.

[6] D. Canright, [A Very Compact S-Box for AES](https://www.iacr.org/archive/ches2005/032.pdf), CHES, 2005.

[7] M. Kwan, [Reducing the Gate Count of Bitslice DES](http://eprint.iacr.org/2000/), 2000.

[8] D. A. Osvik, [Speeding up Serpent](https://www.ii.uib.no/~osvik/pub/aes3.pdf), AES Candidate Conference, 2000.

[9] M. Ullrich _et al._, [Finding optimal bitsliced implementations of 4×4-bit S-boxes](http://skew2011.mat.dtu.dk/proceedings/Finding%20Optimal%20Bitsliced%20Implementations%20of%204%20to%204-bit%20S-boxes.pdf), SKEW, 2011.

[10] F. Rocheteau, [Extension du langage LUSTRE et application à la conception de circuits : le langage LUSTRE-V4 et le système POLLUX](https://tel.archives-ouvertes.fr/tel-00342092) (Extension of the lustre language and application to hardware design: the lustre-v4 language and the pollux system), 1992.

[11] P. Wadler, S. Blott, [How to Make ad-hoc Polymorphism Less ad-hoc](https://people.csail.mit.edu/dnj/teaching/6898/papers/wadler88.pdf), POPL, 1988.
