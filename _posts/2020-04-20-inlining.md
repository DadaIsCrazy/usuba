---
layout: post
title: Inlining
date: "2020-04-20 00:00:00"
description: Usubac's inlining optimization
lang: en
locale: en_US
author: Darius Mercadier
excerpt: 
comments: false
hidden: true
---


Inlining consists in replacing function calls with the body of the
function called. The benefits of inlining are twofold. First, it can
improve performance by removing the overhead of a function call
(pushing arguments into registers or onto the stack, calling the
function, saving the return values, returning from the
function...). Second, and most important, it enables other
optimizations, like common sub-expression elimination (CSE), copy
propagation and constant folding. 

However, when inlining multiple times a function with a large body,
code size will increase. Furthermore, too much inlining can cause
bottlenecks in the front-end of Skylake's CPU, as it under-utilizes
the μop cache (DSB). Consider for instance the following code:

```c
for (int i = 0; i < 10; i++) {
    Sbox(&x0,&x1,&x2,&x3,&x4,&x5,&x6,&x7);
    Sbox(&x8,&x9,&x10,&x11,&x12,&x13,&x14,&x15);
    Sbox(&x16,&x17,&x18,&x19,&x20,&x21,&x22,&x23);
    Sbox(&x24,&x25,&x26,&x27,&x28,&x29,&x30,&x31);
}
```

where `Sbox` is a function computing a S-box using bitwise
instructions. If the code of `Sbox` is small enough to fit into the
DSB, then only the first call will fully decode its instructions, and
the next ones will be able to fetch its μops from the DSB.

To illustrate the trade-off of inlining, we compared three versions of
Usuba's bitslice DES on AVX registers: one where Usuba performed no
inlining at all, one where it inlined all nodes, and one where it
inlined only some nodes (follwing a heuristic which will be presented
later in this post). We compiled the produced C codes with gcc 8.3
(Clang is more aggressive on its inlining heuristcs than gcc, and thus
less suited for this experiment). The results follow:

<center>
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}
.tg .tg-9wq8{border-color:inherit;text-align:center;vertical-align:middle}
.tg .tg-wa1i{font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
.tg .tg-7btt{font-weight:bold;border-color:inherit;text-align:center;vertical-align:top}
.tg .tg-6ic8{font-weight:bold;border-color:inherit;text-align:right;vertical-align:top}
.tg .tg-fymr{font-weight:bold;border-color:inherit;text-align:left;vertical-align:top}
.tg .tg-uzvj{font-weight:bold;border-color:inherit;text-align:center;vertical-align:middle}
.tg .tg-nrix{text-align:center;vertical-align:middle}
</style>
<table class="tg" style="margin-top:30px;margin-bottom:30px">
  <tr>
    <th class="tg-0pky" style="border-left:none;border-top:none"></th>
    <th class="tg-7btt">without inlining</th>
    <th class="tg-6ic8">full inlining</th>
    <th class="tg-fymr">heuristic inlining</th>
  </tr>
  <tr>
    <td class="tg-uzvj">speed<br>(normalized)</td>
    <td class="tg-9wq8">1</td>
    <td class="tg-9wq8">1.69</td>
    <td class="tg-9wq8">1.93</td>
  </tr>
  <tr>
    <td class="tg-wa1i">number of loads/stores<br>(normalized)</td>
    <td class="tg-nrix">1</td>
    <td class="tg-nrix">0.61</td>
    <td class="tg-nrix">0.52</td>
  </tr>
  <tr>
    <td class="tg-uzvj">% of μops <br>issued by the DSB</td>
    <td class="tg-9wq8">27</td>
    <td class="tg-9wq8">1</td>
    <td class="tg-9wq8">26</td>
  </tr>
  <tr>
    <td class="tg-uzvj">% of cycles<br>with stalls in the frontend</td>
    <td class="tg-9wq8">15</td>
    <td class="tg-9wq8">86</td>
    <td class="tg-9wq8">10</td>
  </tr>
</table>
</center>


Inlining every node (column "full inlining") reduces the number of
loads and stores by x0.61 compare to inlining no node at all (column
"without inlining"), and thus improves performances by x1.69. However,
it completely fails to utilize the DSB: 99% of the μops are issued by
the legacy pipeline (MITE). A consequence of this under-utilization of
the DSB is that in 86% of the cycles, the front-end is unable to
deliver at least 4 μops to the backend (even though the backend is not
stalled).

Inlining only some carefuly chosen nodes (column "heuristic inlining")
can reduce even further the number of memory operations, and more
importantly, allows some instructions to be cached in the DSB. The
percentage of cycles where the front-end is stalling the backend is
thus reduced to only 10%, which translates into a x1.14 speedup over
the fully inlined version.

