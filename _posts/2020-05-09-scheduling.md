---
layout: post
title: Scheduling
date: "2020-05-09 00:00:00"
description: Usubac's scheduling optimizations
lang: en
locale: en_US
author: Darius Mercadier
excerpt: The C codes generated by Usubac are compiled to assembly using C compilers. While in C, a (virtually) unlimited amount of variables can be used, Assembly can only use a few registers (between 8 and 32 for commonly used CPUs). C variables are thus mapped to assembly registers using a _register allocation_ algorithms. When too many registers would be required, registers are spilled, and the stack is used to temporary store some variables. 
comments: true
hidden: false
---


## Introduction


The C codes generated by Usubac are compiled to assembly using C
compilers. While in C, a (virtually) unlimited amount of variables can
be used, Assembly can only use a few registers (between 8 and 32 for
commonly used CPUs). C variables are thus mapped to assembly registers
using a _register allocation_ algorithms. When too many registers
would be required, registers are spilled: the stack is used to
temporary store some variables. 

R. Sethi [1] showed that determining whether a program can be computed
using _k_ registers is NP-complete. Heuristic methods are thus used in
modern compilers to allocate registers to variables. The most
classical ones are based on graph coloring [2,3,4,17], and bound to be
approximative since graph coloring is NP-complete itself. Another
commonly used approach is an algorithm called _linear scan_ [6], which
just-in-time compilers often prefer to graph coloring, since it is
much faster, at the expense of the quality of the allocation
[7,8,9,10].

Register allocation is closely related to instruction scheduling,
which consists in ordering the instructions in the best way to take
advantage of a CPU's superscalar microarchitecture [11,12]. To
illustrate the importance of instruction scheduling, consider the
following instructions:

```c
u = a + b;
v = u + 2;
w = c + d;
x = e + f;
```

Consider a CPU that can compute two additions per cycle and performs
no reordering. Such a CPU would execute `u = a + b` in its first
cycle, and would be unable to compute `v = u + 2` in the same cycle
since `u` has not been computed yet. In a second cycle, it would
compute `v = u + 2` as well as `w = c + d`, and, finally, in a third
cycle, it would compute `x = e + f`. On the other hand, if the code
had been scheduled as:

```c
u = a + b;
w = c + d;
v = u + 2;
x = e + f;
```

It could have been executed in only 2 cycles. While out-of-order CPUs
reduce the impact of such data hazards, this phenomenons still occur
and need to be taken into account to schedule instructions.

The interaction between register allocation and instruction scheduling
is due to spilling, which introduces memory operations. The cost of
those additional memory operations can sometimes be reduced by using a
efficient instruction scheduling. Better yet, it is well known that
combining register allocation and instruction scheduling can produce
more efficient code that performing them separately [13,14,15,16].

In practice however, modern C compilers force themselves to be fast,
sometimes at the expense of the quality of the generated code. Both
GCC and LLVM thus perform instruction scheduling and register
allocation separately, starting instruction scheduling, followed by
register allocation, followed by some additional scheduling.

Despite being based on traditional algorithms, GCC and LLVM's
instruction schedulers and register allocators are highly optimized,
and are the product of decades of tweaking. GCC's register allocator
and instruction scheduler thus amount for more than 50.000 lines of C
code, and LLVM's for more than 30.000 lines of code.

Recreating from scratch a better register allocator and instruction
scheduler than Clang's and GCC's thus seem utopian. Instead, we
developped two schedulers for C code, that aim at helping GCC/LLVM's
schedulers and register allocator. The first scheduler reduces
register pressure in bitsliced ciphers, while the second increases
instruction-level parallelism in msliced ciphers.



## Bitslicing


In bitsliced codes, the major bottleneck is register pressure: a
significant portion of the execution time is spent spilling registers
to and from the stack. Given that hundreds of variables can be alive
at the same time in a bitslice cipher, it is not surprising that the C
compilers have a hard time keeping the register pressure down. For
instance, it is common for bitsliced ciphers to have up to 40% of
their instructions being loads and stores for spilling, as shown in
the following table (usuba-generated ciphers compiled with Clang
7.0.0):

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-ggg6{background-color:#ecf4ff;text-align:center;vertical-align:middle}
.tg .tg-wa1i{font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-yla0{font-weight:bold;text-align:left;vertical-align:middle}
.tg .tg-0qe0{background-color:#ecf4ff;text-align:left;vertical-align:top}
.tg .tg-0lax{text-align:left;vertical-align:top}
.tg .tg-nrix{text-align:center;vertical-align:middle}
</style>
<center>
<table class="tg" style="undefined;table-layout: fixed; width: 304px; margin-top:30px;margin-bottom:30px">
<colgroup>
<col style="width: 152px">
<col style="width: 152px">
</colgroup>
<thead>
  <tr>
    <th class="tg-yla0">Cipher</th>
    <th class="tg-wa1i">% of instructions related to spilling</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-0qe0">DES</td>
    <td class="tg-ggg6">41%</td>
  </tr>
  <tr>
    <td class="tg-0lax">Ascon</td>
    <td class="tg-nrix">43%</td>
  </tr>
  <tr>
    <td class="tg-0qe0">Gift</td>
    <td class="tg-ggg6">38%</td>
  </tr>
  <tr>
    <td class="tg-0lax">Present</td>
    <td class="tg-nrix">25%</td>
  </tr>
  <tr>
    <td class="tg-0qe0">Rectangle</td>
    <td class="tg-ggg6">36%</td>
  </tr>
  <tr>
    <td class="tg-0lax">Serpent</td>
    <td class="tg-nrix">39%</td>
  </tr>
</tbody>
</table>
</center>


We designed a scheduling algorithm that aims at reducing register
pressure (and thus improve performances) in bitsliced codes.

Let's take the example of Rectangle to illustrate why bitsliced codes
have so much spilling and how this can be improved. Rectangle's S-box
can be written in Usuba as:

```lustre
node sbox (a0:u32, a1:u32, a2:u32, a3:u32)
     returns  (b0:u32, b1:u32, b2:u32, b3:u32)
vars
    t1:u32, t2:u32, t3:u32, t4:u32, t5:u32, t6:u32,
    t7:u32, t8:u32, t9:u32, t10:u32, t11:u32, t12:u32
let
    t1 = ~a1;
    t2 = a0 & t1;
    t3 = a2 ^ a3;
    b0 = t2 ^ t3;
    t5 = a3 | t1;
    t6 = a0 ^ t5;
    b1 = a2 ^ t6;
    t8 = a1 ^ a2;
    t9 = t3 & t6;
    b3 = t8 ^ t9;
    t11 = b0 | t8;
    b2 = t6 ^ t11
tel
```

Usubac naive automatic bitslicing would replace all `u32` with `b32`,
which would cause the variables to become vectors of 32 boolean
elements, thus causing the operators to be unfolded as follows:

```lustre
node sbox (a0:b32, a1:b32, a2:b32, a3:b32)
     returns  (b0:b32, b1:b32, b2:b32, b3:b32)
vars ...
let
    t1[0] = ~a1[0];
    t1[1] = ~a1[1];
    t1[2] = ~a1[2];
    ...
    t1[31] = ~a1[31];
    t2[0] = a0[0] & t1[0];
    t2[1] = a0[1] & t1[1];
    ...
    t2[31] = a0[31] & t1[31];
    ...
```

### Optimizing the automatic bitslicing

While the initial S-box contained less than 10 variables
simultaneously alive, the bitsliced S-box contains 32 times more
variables alive at any point. A first optimization to reduce the
register pressure thus happens during the automatic bitslicing: Usubac
detects nodes computing only bitwise instructions and calls to nodes
with the same property. Those nodes are specialized to take `b1`
variables as input, and their call sites are replaced with several
calls instead of one. In the case of Rectangle, the shorter S-box is
thus called 32 times rather than calling the large S-box
once. Concretely, this optimization reduces the register pressure, at
the expanse of more function calls. The benefits heavily depends on
the ciphers and C compilers used. On AVX registers using Clang as C
compiler, this yields a 34% speedup on Ascon, 12% on Gift and 6% on
Clyde.


The same optimization cannot be applied to linear layers however, as
they almost always contain rotations, shifts or permutations. Consider
for instance Rectangle's linear layer:

```lustre
node ShiftRows (input:u16x4) returns (out:u16x4)
let
    out[0] = input[0];
    out[1] = input[1] <<< 1;
    out[2] = input[2] <<< 12;
    out[3] = input[3] <<< 13
tel
```

Using a `u1x4` input instead of a `u16x4` is not possible due to the
left rotations, which requires all 16 bits of each input. Instead,
this function will be bitsliced and become:

```lustre
node ShiftRows (input:b1[4][16]) returns (out:b1[4][16])
let 
    out[0][0] = input[0][0];       -- out[0] = input[0]
    out[0][1] = input[0][1];
    ...
    out[0][15] = input[0][15];
    out[1][0] = input[1][1];       -- out[1] = input[1] <<< 1
    out[1][1] = input[1][2];
    ...
    out[1][15] = input[1][0];
    out[2][0] = input[2][12];      -- out[2] = input[2] <<< 12
    out[2][1] = input[2][13];
    ...
    out[2][15] = input[2][11];
    out[3][0] = input[3][13];      -- out[3] = input[3] <<< 13
    out[3][1] = input[3][14];
    ...
    out[3][15] = input[3][12];
tel
```

In the case of Rectangle's `ShiftRows` function, it can be inlined and
entirely removed using copy propagation since it only contains
assignments. However, for some other ciphers like Ascon, Serpent,
Clyde or Skinny, the linear layers contains `xor`s, which cannot be
optimized away. Similarly, the `AddRoundKey` step of most ciphers
introduces a lot of `xor`s.

Overall, after bitslicing, the main function of Rectangle thus looks
like:

```lustre
state := AddRoundKey(state, key[0]);    -- <--- lots of spilling in this node
state[0..3] := Sbox(state[0..3]);
state[4..7] := Sbox(state[4..7]);
...
state[60..63] := Sbox(state[60..63]);
state := LinearLayer(state);            -- <--- lots of spilling in this node
state := AddRoundKey(state, key[1]);    -- <--- lots of spilling in this node
state[0..3] := Sbox(state[0..3]);
state[4..7] := Sbox(state[4..7]);
...
state[60..63] := Sbox(state[60..63]);
...
```


### Bitslice code scheduling

We designed a scheduling algorithm that aims at interleaving the
linear layers (and key additions) with S-box calls in order to reduce
the live ranges of some variables and thus reduce the need for
spilling.

This algorithm requires a first inlining step that heuristically tries
to recognize good candidates for inlining. We experimentally
determined three criterions for this first inlining pass that yield
good results:

 - if a node contains more than than 31 inputs and outputs, it's very
   unlikely to be an S-box and should therefore be inlined. The
   largest S-boxes we know of take 8 inputs and return 8 outputs, like
   in AES or Camellia.
   
 - if a node contains more than 65% of assigmnents, it is quite likely
   to be doing some kind of permutation, and should therefore be
   inlined. Since most of the instructions in S-boxes are bitwise
   instructions, a node containing 65% is thus unlikely to be an
   S-box.

 - if a node contains less than 10 instructions, it is unlikely to be
   a S-box and is therefore inlined. The shortest S-box we know of are
   Gift's with 11 instructions, and Rectangle's with 12
   instructions. Those nodes with few instructions often perform
   constant addition, key addition, or are used to factorize the S-box
   (like in Skinny for instance).

After this inlining step, Rectangle's code would thus be:

```lustre
state[0] := state[0] ^ key[0][0];        -- AddRoundKey 1
state[1] := state[1] ^ key[0][1];
state[2] := state[2] ^ key[0][2];
state[3] := state[3] ^ key[0][3];
state[4] := state[4] ^ key[0][4];
state[5] := state[5] ^ key[0][5];
state[6] := state[6] ^ key[0][6];
state[7] := state[7] ^ key[0][7];
state[8] := state[8] ^ key[0][8];
state[9] := state[9] ^ key[0][9];
...
state[63] := state[63] ^ key[0][63];
state[0..3] := Sbox(state[0..3]);        -- S-boxes 1
state[4..7] := Sbox(state[4..7]);
state[8..11] := Sbox(state[8..11]);
...
state[60..63] := Sbox(state[60..63]);
state[0] := state[0];                    -- Linear layer 1
state[1] := state[1];
state[2] := state[2];
state[3] := state[3];
state[4] := state[4];
state[5] := state[5];
state[6] := state[6];
...
state[63] := state[60];
state[0] := state[0] ^ key[1][0];        -- AddRoundKey 2
state[1] := state[1] ^ key[1][1];
state[2] := state[2] ^ key[1][2];
state[3] := state[3] ^ key[1][3];
state[4] := state[4] ^ key[1][4];
state[5] := state[5] ^ key[1][5];
...
state[63] := state[63] ^ key[1][63];
state[0..3] := Sbox(state[0..3]);        -- S-boxes 2
state[4..7] := Sbox(state[4..7]);
...
```

The inlined inlined linear and key addition introduce a lot of
spilling since they use a lot of variables a single time. After our
scheduling algorithm, Rectangle's code will be:


```lustre
state[0] := state[0] ^ key[0][0];        -- Part of AddRoundKey 1
state[1] := state[1] ^ key[0][1];
state[2] := state[2] ^ key[0][2];
state[3] := state[3] ^ key[0][3];
state[0..3] := Sbox(state[0..3]);        -- S-box 1
state[4] := state[4] ^ key[0][4];        -- Part of AddRoundKey 1
state[5] := state[5] ^ key[0][5];
state[6] := state[6] ^ key[0][6];
state[7] := state[7] ^ key[0][7];
state[4..7] := Sbox(state[4..7]);        -- S-box 1
...
...
state[0] := state[0];                    -- Part of Linear layer 1
state[1] := state[1];
state[2] := state[2]; 
state[3] := state[3];
state[0] := state[0] ^ key[1][0];        -- Part of AddRoundKey 2
state[1] := state[1] ^ key[1][1];
state[2] := state[2] ^ key[1][2];
state[3] := state[3] ^ key[1][3];
state[0..3] := Sbox(state[0..3]);        -- S-box 2
state[4] := state[4];                    -- Part of Linear layer 1
state[5] := state[5];
state[6] := state[6]; 
state[7] := state[7];
state[4] := state[4] ^ key[1][4];        -- Part of AddRoundKey 2
state[5] := state[5] ^ key[1][5];
state[6] := state[6] ^ key[1][6];
state[7] := state[7] ^ key[1][7];
state[4..7] := Sbox(state[0..3]);        -- S-box 2
...
...
```

Our scheduling algorithm aims at reducing the lifespan of variables
computed in the linear layers by interleaving linear layer with
S-boxes calls: the parameters of the S-boxes are computed right before
the S-box calls, thus removing the need to spill them. More formally,
the pseudo-code of this algorithm follows:

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">procedure</span> <span class="nf">Schedule</span><span class="p">(</span><span class="mi"><i>prog</i></span><span class="p">):</span>
    <span class="o">for</span> <span class="o">each</span> <span class="n">function</span> <span class="n">call</span> <span class="mi"><i>funCall</i></span> <span class="n">of</span> <span class="mi"><i>prog</i></span> <span class="o">do</span>
        <span class="o">for</span> <span class="o">each</span> <span class="n">variable</span> <span class="mi"><i>v</i></span> <span class="n">in</span> <span class="mi"><i>funCall</i></span><span class="n">'s</span> <span class="n">arguments</span> <span class="o">do</span>
            <span class="o">if</span> <span class="mi"><i>v</i></span><span class="n">'s</span> <span class="n">definition</span> <span class="n">is</span> <span class="n">not</span> <span class="n">scheduled</span> <span class="n">yet</span> <span class="o">then</span>
                <span class="n"><b>schedule</b></span> <span class="mi"><i>v</i></span><span class="n">'s</span> <span class="n">definition</span> <span class="p">(</span><span class="n">and</span> <span class="n">dependencies</span><span class="p">)</span> <span class="nb">next</span>
        <span class="n"><b>schedule</b></span> <span class="mi"><i>funCall</i></span> <span class="nb">next</span>
</code></pre></div></div>

<!--         <span class="o">for</span> <span class="o">each</span> <span class="n">variable</span> <span class="mi"><i>v</i></span> <span class="n">defined</span> <span class="n">by</span> <span class="mi"><i>funCall</i></span> <span class="o">do</span> -->
<!--             <span class="o">for</span> <span class="o">each</span> <span class="n">equation</span> <span class="mi"><i>eqn</i></span> <span class="n">of</span> <span class="mi"><i>prog</i></span> <span class="n">using</span> <span class="mi"><i>v</i></span> <span class="o">do</span> -->
<!--                 <span class="o">if</span> <span class="mi"><i>eqn</i></span> <span class="n">is</span> <span class="n">ready</span> <span class="n">to</span> <span class="n">be</span> <span class="n">scheduled</span> <span class="o">then</span> -->
<!--                     <span class="n"><b>schedule</b></span> <span class="mi"><i>eqn</i></span> <span class="nb">next</span> -->
<!-- </code></pre></div></div> -->


The optimization of the automatic bitslicing presented earlier is
crucial for this scheduling algorithm to work: without it, the S-box
is a single large function rather than several calls to small S-boxes,
and no interleaving can happen. Similarly, the inlining pass than
happens before the scheduling itself is essential to ensure that the
instructions of the linear layer are inlined and ready to be
interleaved with calls to the S-boxes.


### Performances

We evaluated this algorithm on 11 ciphers containing a distinct S-box
and linear layer, where the S-box only performs bitwise
instructions. We compiled the generated C codes with gcc 8.3, and ran
the benchmarks on a Intel i5 6500. The results are shown in the
following table:

<center>
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-ti2t{color:#32cb00;text-align:left;vertical-align:top}
.tg .tg-cjtp{background-color:#ecf4ff;border-color:inherit;text-align:left;vertical-align:top}
.tg .tg-gyiu{background-color:#ecf4ff;color:#32cb00;text-align:left;vertical-align:top}
.tg .tg-3u1j{background-color:#ecf4ff;border-color:#000000;color:#32cb00;text-align:left;vertical-align:top}
.tg .tg-wa1i{font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-aznb{background-color:#ecf4ff;font-style:italic;text-align:left;vertical-align:top}
.tg .tg-66qz{background-color:#ffffff;border-color:#000000;color:#32cb00;text-align:left;vertical-align:top}
.tg .tg-viqs{color:#fe0000;text-align:left;vertical-align:top}
.tg .tg-uzvj{border-color:inherit;font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-amwm{font-weight:bold;text-align:center;vertical-align:top}
.tg .tg-8zwo{font-style:italic;text-align:left;vertical-align:top}
.tg .tg-0lax{text-align:left;vertical-align:top}
.tg .tg-l2sb{background-color:#ecf4ff;color:#fe0000;text-align:left;vertical-align:top}
.tg .tg-c6of{background-color:#ffffff;border-color:inherit;text-align:left;vertical-align:top}
.tg .tg-7vke{background-color:#ffffff;color:#32cb00;text-align:left;vertical-align:top}
.tg .tg-0qe0{background-color:#ecf4ff;text-align:left;vertical-align:top}
.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
.tg .tg-085k{border-color:#000000;color:#32cb00;text-align:left;vertical-align:top}
</style>
<table class="tg" style="undefined;table-layout: fixed; width: 725px; margin-top:30px;margin-bottom:30px">
<colgroup>
<col style="width: 125px">
<col style="width: 100px">
<col style="width: 100px">
<col style="width: 100px">
<col style="width: 100px">
<col style="width: 100px">
<col style="width: 100px">
</colgroup>
<thead>
  <tr>
    <th class="tg-uzvj" rowspan="3">algorithm</th>
    <th class="tg-uzvj" colspan="6">Bitslice scheduling speedup</th>
  </tr>
  <tr>
    <td class="tg-wa1i" colspan="2">gcc -Os</td>
    <td class="tg-wa1i" colspan="2">gcc -O3</td>
    <td class="tg-wa1i" colspan="2">clang -O3</td>
  </tr>
  <tr>
    <td class="tg-uzvj">x86</td>
    <td class="tg-uzvj">AVX2</td>
    <td class="tg-amwm">x86</td>
    <td class="tg-amwm">AVX2</td>
    <td class="tg-amwm">x86</td>
    <td class="tg-amwm">AVX2</td>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-8zwo">ACE*</td>
    <td class="tg-0lax">1.00</td>
    <td class="tg-0lax">1.00</td>
    <td class="tg-ti2t">1.02</td>
    <td class="tg-ti2t">1.01</td>
    <td class="tg-0lax">1.00</td>
    <td class="tg-viqs">0.99</td>
  </tr>
  <tr>
    <td class="tg-cjtp">AES</td>
    <td class="tg-3u1j">1.04</td>
    <td class="tg-l2sb">0.99</td>
    <td class="tg-gyiu">1.06</td>
    <td class="tg-l2sb">0.98</td>
    <td class="tg-gyiu">1.08</td>
    <td class="tg-gyiu">1.04</td>
  </tr>
  <tr>
    <td class="tg-c6of">Ascon</td>
    <td class="tg-66qz">1.35</td>
    <td class="tg-66qz">1.32</td>
    <td class="tg-7vke">1.25</td>
    <td class="tg-7vke">1.27</td>
    <td class="tg-7vke">1.04</td>
    <td class="tg-7vke">1.19</td>
  </tr>
  <tr>
    <td class="tg-cjtp">Clyde</td>
    <td class="tg-3u1j">1.06</td>
    <td class="tg-3u1j">1.06</td>
    <td class="tg-gyiu">1.06</td>
    <td class="tg-gyiu">1.04</td>
    <td class="tg-gyiu">1.01</td>
    <td class="tg-l2sb">0.99</td>
  </tr>
  <tr>
    <td class="tg-c6of">DES</td>
    <td class="tg-66qz">1.16</td>
    <td class="tg-66qz">1.19</td>
    <td class="tg-7vke">1.16</td>
    <td class="tg-7vke">1.23</td>
    <td class="tg-7vke">1.01</td>
    <td class="tg-7vke">1.02</td>
  </tr>
  <tr>
    <td class="tg-aznb">Gimli*</td>
    <td class="tg-0qe0">1.00</td>
    <td class="tg-l2sb">0.99</td>
    <td class="tg-gyiu">1.01</td>
    <td class="tg-0qe0">1.00</td>
    <td class="tg-0qe0">1.00</td>
    <td class="tg-gyiu">1.01</td>
  </tr>
  <tr>
    <td class="tg-0pky">Gift</td>
    <td class="tg-085k">1.16</td>
    <td class="tg-085k">1.18</td>
    <td class="tg-ti2t">1.12</td>
    <td class="tg-ti2t">1.16</td>
    <td class="tg-ti2t">1.04</td>
    <td class="tg-ti2t">1.09</td>
  </tr>
  <tr>
    <td class="tg-cjtp">Photon</td>
    <td class="tg-3u1j">1.05</td>
    <td class="tg-3u1j">1.14</td>
    <td class="tg-l2sb">0.97</td>
    <td class="tg-l2sb">0.93</td>
    <td class="tg-l2sb">0.96</td>
    <td class="tg-l2sb">0.97</td>
  </tr>
  <tr>
    <td class="tg-0pky">Present</td>
    <td class="tg-085k">1.30</td>
    <td class="tg-085k">1.10</td>
    <td class="tg-ti2t">1.16</td>
    <td class="tg-ti2t">1.16</td>
    <td class="tg-0lax">1.00</td>
    <td class="tg-0lax">1.00</td>
  </tr>
  <tr>
    <td class="tg-cjtp">Pyjamask</td>
    <td class="tg-3u1j">1.19</td>
    <td class="tg-3u1j">1.35</td>
    <td class="tg-gyiu">1.04</td>
    <td class="tg-gyiu">1.04</td>
    <td class="tg-l2sb">0.99</td>
    <td class="tg-0qe0">1.00</td>
  </tr>
  <tr>
    <td class="tg-0pky">Rectangle</td>
    <td class="tg-085k">1.28</td>
    <td class="tg-085k">1.20</td>
    <td class="tg-ti2t">1.15</td>
    <td class="tg-ti2t">1.15</td>
    <td class="tg-0lax">1.00</td>
    <td class="tg-viqs">0.99</td>
  </tr>
  <tr>
    <td class="tg-cjtp">Serpent</td>
    <td class="tg-3u1j">1.18</td>
    <td class="tg-3u1j">1.20</td>
    <td class="tg-gyiu">1.20</td>
    <td class="tg-gyiu">1.20</td>
    <td class="tg-gyiu">1.04</td>
    <td class="tg-0qe0">1.00</td>
  </tr>
  <tr>
    <td class="tg-0pky">Skinny</td>
    <td class="tg-085k">1.14</td>
    <td class="tg-085k">1.16</td>
    <td class="tg-ti2t">1.18</td>
    <td class="tg-ti2t">1.18</td>
    <td class="tg-ti2t">1.03</td>
    <td class="tg-ti2t">1.14</td>
  </tr>
  <tr>
    <td class="tg-aznb">Spongent*</td>
    <td class="tg-0qe0">1.00</td>
    <td class="tg-0qe0">1.00</td>
    <td class="tg-0qe0">1.00</td>
    <td class="tg-gyiu">1.02</td>
    <td class="tg-0qe0">1.00</td>
    <td class="tg-l2sb">0.99</td>
  </tr>
  <tr>
    <td class="tg-8zwo">Subterranean*</td>
    <td class="tg-0lax">1.00</td>
    <td class="tg-viqs">0.99</td>
    <td class="tg-0lax">1.00</td>
    <td class="tg-ti2t">1.01</td>
    <td class="tg-0lax">1.00</td>
    <td class="tg-0lax">1.00</td>
  </tr>
  <tr>
    <td class="tg-aznb">Xoodoo*</td>
    <td class="tg-0qe0">1.00</td>
    <td class="tg-gyiu">1.01</td>
    <td class="tg-0qe0">1.00</td>
    <td class="tg-0qe0">1.00</td>
    <td class="tg-l2sb">0.98</td>
    <td class="tg-0qe0">1.00</td>
  </tr>
</tbody>
</table>
</center>


Our scheduling algorithm is clearly beneficial, yielding speedups of
up to x1.35. The ciphers marked with a * are not supposed to benefit
from this scheduling algorithm, since they do not contain a small
S-box composed of bitwise instructions alternating with a large linear
layer. We still provide their performances to show that our algorithm
is not too detrimental to them: on average, it does not change their
performances. Note that all the speedups are significant (even a x1.01
speedup) according to Wilcoxon's rank-sum test [19]. 

The exact benefits of this scheduling algorithm however greatly vary
from one cipher to the other, from one architecture to the other, and
from one compiler to the other. For instance, while on general purpose
register our algorithm improves AES's performances by a factor 1.04,
it actually reduces them by 0.99 on AVX2 registers. On Present, our
algorithm is clearly more efficient on general purpose registers,
while on Pyjamask, it is clearly better on AVX2 registers.

We do not provide a detailed analysis of the performances because of
the heuristic nature the results: our algorithm relies on a heuristic
inlining, and is only meant to help GCC/Clang's scheduler, which are
themselves very heuristic.



## mslicing


Unlike bitsliced code, m-sliced programs have much lower register
pressure. Spilling is less of an issue, the latency of the few
resulting load and store operations being hidden by the CPU
pipeline. Instead, the challenge consists in being able to saturate
the parallel CPU execution units. To do so, one must increase ILP,
taking into account data hazards. Consider for instance Clyde's linear
layer:

```lustre
node lbox(x,y:u32) returns (xr,yr:u32)
vars
    a, b, c, d: u32
let
    a  = x ^ (x >>> 12);
    b  = y ^ (y >>> 12);
    a := a ^ (a >>> 3);
    b := b ^ (b >>> 3);
    a := a ^ (x >>> 17);
    b := b ^ (y >>> 17);
    c  = a ^ (a >>> 31);
    d  = b ^ (b >>> 31);
    a := a ^ (d >>> 26);
    b := b ^ (c >>> 25);
    a := a ^ (c >>> 15);
    b := b ^ (d >>> 15);
    (xr, yr) = (a,b)
tel
```

Only 2 instructions per cycles can ever be computed because of data
dependencies: `x >>> 12` and `y >>> 12` during the first cycle, then
`x ^ (x >>> 12)` and `y ^ (y >>> 12)` in the second cycle, `a >>> 3`
and `b >>> 3` in the third one, _etc_. However, after inlining, it may
possible to partially interleave this function with other parts of the
cipher (for instance the S-box or the key addition).

One might think that the out-of-order nature of modern CPU would
alleviate this issue, allowing the processor to execute independent
instructions ahead in the execution streams. However, due to the bulky
nature of sliced code, we observe that the reservation station is
quickly saturated, preventing actual out-of-order
execution. Unfortunately, C compilers have their own heuristic to
schedule the instructions, and they often fail to generate codes that
are optimal with regard to data hazards.

We statically increase ILP in Usubac by maintaining a look-behind
window of the previous 10 instructions while scheduling. To schedule
an instruction, we search among the remaining instructions one with no
data hazard with the instructions in the look-behind window, and that
would execute on a different execution unit. If no such instruction
can be found, we reduce the size of the look-behind window, and,
utlimately just schedule any instruction that is ready. While the C
compilers are free to completely undo this optimization when the
perform their own scheduling, we observe significant performance
improvements when performing this first scheduling pass ourselves.

The speedup gained by using this scheduling algorithm are summarized
in the following table (using Clang 7.0.0):

<center>
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-ff21{background-color:#ecf4ff;border-color:#000000;color:#333333;text-align:left;vertical-align:top}
.tg .tg-cjtp{background-color:#ecf4ff;border-color:inherit;text-align:left;vertical-align:top}
.tg .tg-ee30{background-color:#ffffff;border-color:inherit;font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-3u1j{background-color:#ecf4ff;border-color:#000000;color:#32cb00;text-align:left;vertical-align:top}
.tg .tg-hrrh{background-color:#ffffff;border-color:#000000;color:#333333;text-align:left;vertical-align:top}
.tg .tg-66qz{background-color:#ffffff;border-color:#000000;color:#32cb00;text-align:left;vertical-align:top}
.tg .tg-7g6k{background-color:#ffffff;border-color:inherit;font-weight:bold;text-align:center;vertical-align:top}
.tg .tg-c6of{background-color:#ffffff;border-color:inherit;text-align:left;vertical-align:top}
.tg .tg-iks7{background-color:#ffffff;border-color:#000000;text-align:left;vertical-align:top}
.tg .tg-376w{background-color:#ecf4ff;border-color:#000000;color:#fe0000;text-align:left;vertical-align:top}
.tg .tg-0uhg{background-color:#ffffff;border-color:#000000;color:#fe0000;text-align:left;vertical-align:top}
</style>
<table class="tg" style="undefined;table-layout: fixed; margin-top:30px;margin-bottom:30px">
<colgroup>
<col style="width: 117px">
<!-- <col style="width: 95px"> -->
<!-- <col style="width: 95px"> -->
<!-- <col style="width: 95px"> -->
<!-- <col style="width: 95px"> -->
<!-- <col style="width: 95px"> -->
<!-- <col style="width: 95px"> -->
<col style="width: 95px">
<col style="width: 95px">
</colgroup>
<thead>
  <tr>
    <th class="tg-ee30" rowspan="2">algorithm</th>
    <th class="tg-ee30" colspan="2">Mitslice scheduling speedup</th>
  </tr>
  <!-- <tr> -->
  <!--   <td class="tg-ee30" colspan="2">Look-behind: 2</td> -->
  <!--   <td class="tg-ee30" colspan="2">Look-behind: 3</td> -->
  <!--   <td class="tg-ee30" colspan="2">Look-behind: 4</td> -->
  <!--   <td class="tg-7g6k" colspan="2">Look-behind: 10</td> -->
  <!-- </tr> -->
  <tr>
    <!-- <td class="tg-ee30">x86</td> -->
    <!-- <td class="tg-ee30">AVX2</td> -->
    <!-- <td class="tg-7g6k">x86</td> -->
    <!-- <td class="tg-7g6k">AVX2</td> -->
    <!-- <td class="tg-7g6k">x86</td> -->
    <!-- <td class="tg-7g6k">AVX2</td> -->
    <td class="tg-7g6k">x86</td>
    <td class="tg-7g6k">AVX2</td>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-c6of">ACE</td>
    <!-- <td class="tg-66qz">1.15</td> -->
    <!-- <td class="tg-66qz">1.15</td> -->
    <!-- <td class="tg-66qz">1.20</td> -->
    <!-- <td class="tg-66qz">1.28</td> -->
    <!-- <td class="tg-66qz">1.32</td> -->
    <!-- <td class="tg-66qz">1.35</td> -->
    <td class="tg-66qz">1.35</td>
    <td class="tg-66qz">1.39</td>
  </tr>
  <tr>
    <td class="tg-cjtp">AES</td>
    <!-- <td class="tg-ff21">-</td> -->
    <!-- <td class="tg-3u1j">1.01</td> -->
    <!-- <td class="tg-ff21">-</td> -->
    <!-- <td class="tg-3u1j">1.01</td> -->
    <!-- <td class="tg-ff21">-</td> -->
    <!-- <td class="tg-3u1j">1.03</td> -->
    <td class="tg-ff21">-</td>
    <td class="tg-3u1j">1.04</td>
  </tr>
  <tr>
    <td class="tg-c6of">Ascon</td>
    <!-- <td class="tg-66qz">1.01</td> -->
    <!-- <td class="tg-hrrh">1</td> -->
    <!-- <td class="tg-66qz">1.02</td> -->
    <!-- <td class="tg-hrrh">1</td> -->
    <!-- <td class="tg-66qz">1.03</td> -->
    <!-- <td class="tg-hrrh">1.00</td> -->
    <td class="tg-66qz">1.10</td>
    <td class="tg-66qz">1.04</td>
  </tr>
  <tr>
    <td class="tg-cjtp">Chacha20</td>
    <!-- <td class="tg-3u1j">1.02</td> -->
    <!-- <td class="tg-3u1j">1.03</td> -->
    <!-- <td class="tg-ff21">1</td> -->
    <!-- <td class="tg-3u1j">1.04</td> -->
    <!-- <td class="tg-3u1j">1.05</td> -->
    <!-- <td class="tg-3u1j">1.10</td> -->
    <td class="tg-3u1j">1.05</td>
    <td class="tg-3u1j">1.10</td>
  </tr>
  <tr>
    <td class="tg-c6of">Clyde</td>
    <!-- <td class="tg-iks7">1</td> -->
    <!-- <td class="tg-iks7">1</td> -->
    <!-- <td class="tg-iks7">1</td> -->
    <!-- <td class="tg-66qz">1.01</td> -->
    <!-- <td class="tg-66qz">1.02</td> -->
    <!-- <td class="tg-66qz">1.02</td> -->
    <td class="tg-66qz">1.02</td>
    <td class="tg-66qz">1.04</td>
  </tr>
  <tr>
    <td class="tg-cjtp">Gift</td>
    <!-- <td class="tg-376w">0.98</td> -->
    <!-- <td class="tg-ff21">1</td> -->
    <!-- <td class="tg-ff21">1</td> -->
    <!-- <td class="tg-376w">0.99</td> -->
    <!-- <td class="tg-ff21">1</td> -->
    <!-- <td class="tg-ff21">1.00</td> -->
    <td class="tg-3u1j">1.01</td>
    <td class="tg-ff21">1.00</td>
  </tr>
  <tr>
    <td class="tg-c6of">Gimli</td>
    <!-- <td class="tg-66qz">1.01</td> -->
    <!-- <td class="tg-66qz">1.03</td> -->
    <!-- <td class="tg-66qz">1.04</td> -->
    <!-- <td class="tg-0uhg">0.99</td> -->
    <!-- <td class="tg-66qz">1.04</td> -->
    <!-- <td class="tg-0uhg">0.99</td> -->
    <td class="tg-0uhg">0.98</td>
    <td class="tg-66qz">1.01</td>
  </tr>
  <tr>
    <td class="tg-cjtp">Rectangle (V)</td>
    <!-- <td class="tg-3u1j">1.01</td> -->
    <!-- <td class="tg-3u1j">1.03</td> -->
    <!-- <td class="tg-376w">0.97</td> -->
    <!-- <td class="tg-ff21">1</td> -->
    <!-- <td class="tg-376w">0.97</td> -->
    <!-- <td class="tg-ff21">1.00</td> -->
    <td class="tg-376w">0.97</td>
    <td class="tg-ff21">1.00</td>
  </tr>
  <tr>
    <td class="tg-c6of">Rectangle (H)</td>
    <!-- <td class="tg-hrrh">-</td> -->
    <!-- <td class="tg-66qz">1.03</td> -->
    <!-- <td class="tg-hrrh">-</td> -->
    <!-- <td class="tg-66qz">1.02</td> -->
    <!-- <td class="tg-hrrh">-</td> -->
    <!-- <td class="tg-66qz">1.02</td> -->
    <td class="tg-hrrh">-</td>
    <td class="tg-66qz">1.02</td>
  </tr>
  <tr>
    <td class="tg-cjtp">Serpent</td>
    <!-- <td class="tg-376w">0.99</td> -->
    <!-- <td class="tg-3u1j">1.01</td> -->
    <!-- <td class="tg-376w">0.98</td> -->
    <!-- <td class="tg-3u1j">1.01</td> -->
    <!-- <td class="tg-376w">0.97</td> -->
    <!-- <td class="tg-ff21">1.00</td> -->
    <td class="tg-376w">0.97</td>
    <td class="tg-ff21">1.00</td>
  </tr>
  <tr>
    <td class="tg-c6of">Xoodoo</td>
    <!-- <td class="tg-hrrh">1</td> -->
    <!-- <td class="tg-0uhg">0.99</td> -->
    <!-- <td class="tg-hrrh">0.99</td> -->
    <!-- <td class="tg-0uhg">0.99</td> -->
    <!-- <td class="tg-hrrh">1</td> -->
    <!-- <td class="tg-0uhg">0.98</td> -->
    <td class="tg-66qz">1.03</td>
    <td class="tg-hrrh">1.00</td>
  </tr>
</tbody>
</table>
</center>


This algorithm is useful in particular with ciphers that rely on
functions with heavy data dependencies. For instance, consider ACE's
`f` function:

<div class="language-lustre highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">node</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="o">:</span><span class="n">u32</span><span class="p">)</span> <span class="k">returns</span> <span class="p">(</span><span class="n">y</span><span class="o">:</span><span class="n">u32</span><span class="p">)</span>
<span class="k">let</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">((</span><span class="n">x</span> <span class="o">&lt;&lt;&lt;</span> <span class="mi">5</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">x</span><span class="p">)</span> <span class="o">^</span> <span class="p">(</span><span class="n">x</span> <span class="o">&lt;&lt;&lt;</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">tel</span>
</code></pre></div></div>


It contains only 4 instructions, but cannot execute in less than 3
cycles due to data-dependencies. However, looking at the bigger
picture of ACE, this function is wrapped inside the so-called
`Simeck-box`:

<div class="language-lustre highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">node</span> <span class="nf">simeck_box</span><span class="p">(</span><span class="n">input</span><span class="o">:</span><span class="n">u32x2</span><span class="o">,</span> <span class="n">rc</span><span class="o">:</span><span class="n">u32</span><span class="p">)</span> <span class="k">returns</span> <span class="p">(</span><span class="n">output</span><span class="o">:</span><span class="n">u32x2</span><span class="p">)</span>
<span class="k">vars</span> <span class="n">round</span><span class="o">:</span><span class="n">u32x2</span><span class="p">[</span><span class="mi">9</span><span class="p">]</span>
<span class="k">let</span>
    <span class="n">round</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">input</span><span class="p">;</span>
    <span class="k">forall</span> <span class="n">i</span> <span class="k">in</span> <span class="p">[</span><span class="mi">0</span><span class="o">,</span> <span class="mi">7</span><span class="p">]</span> <span class="p">{</span>
      <span class="n">round</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">( </span><span class="n">f</span><span class="p">(</span><span class="n">round</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span> <span class="o">^</span> <span class="n">round</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">^</span> 
                      <span class="mi">0xfffffffe</span> <span class="o">^</span> <span class="p">((</span><span class="n">rc</span> <span class="o">&gt;&gt;</span> <span class="n">i</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mi">1</span><span class="p">)</span><span class="o">,</span> 
                     <span class="n">round</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">] )</span> <span class="p">;</span>
    <span class="p">}</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">round</span><span class="p">[</span><span class="mi">8</span><span class="p">]</span>
<span class="k">tel</span>
</code></pre></div></div>

This function is bottelnecking because of data-dependencies as well,
but it is actually called 3 times consecutively each round, with
independent inputs:


<div class="language-lustre highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">node</span> <span class="nf">ACE_step</span><span class="p">(</span><span class="n">A</span><span class="o">,</span><span class="n">B</span><span class="o">,</span><span class="n">C</span><span class="o">,</span><span class="n">D</span><span class="o">,</span><span class="n">E</span><span class="o">:</span><span class="n">u32x2</span><span class="o">,</span><span class="n">RC</span><span class="o">,</span><span class="n">SC</span><span class="o">:</span><span class="n">u32</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span> <span class="k">returns</span> <span class="p">(</span><span class="n">Ar</span><span class="o">,</span><span class="n">Br</span><span class="o">,</span><span class="n">Cr</span><span class="o">,</span><span class="n">Dr</span><span class="o">,</span><span class="n">Er</span><span class="o">:</span><span class="n">u32x2</span><span class="p">)</span>
<span class="k">let</span>
    <span class="n">A</span> <span class="o">:=</span> <span class="n">simeck_box</span><span class="p">(</span><span class="n">A</span><span class="o">,</span><span class="n">RC</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
    <span class="n">C</span> <span class="o">:=</span> <span class="n">simeck_box</span><span class="p">(</span><span class="n">C</span><span class="o">,</span><span class="n">RC</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
    <span class="n">E</span> <span class="o">:=</span> <span class="n">simeck_box</span><span class="p">(</span><span class="n">E</span><span class="o">,</span><span class="n">RC</span><span class="p">[</span><span class="mi">2</span><span class="p">]);</span>
    <span class="o">...</span>
</code></pre></div></div>

After inlining and unrolling `simeck_box`, the effect of our
scheduling algorithm will be to interleave those 3 `simeck_box`, thus
removing any pipeline stalls from data hazard. We thus observe that
this scheduling algorithm brings up the number of instructions
executed per cycle (IPC) from 1.93 to 2.67 on AVX2 registers,
translating into a x1.35 speedup.

Similarly, Chacha20's round is composed of 4 functions called _quarter
rounds_:

<div class="language-lustre highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">node</span> <span class="nf">QuarterRound</span> <span class="p">(</span><span class="n">a</span><span class="o">:</span><span class="n">u&lt;V&gt;32</span><span class="o">,</span> <span class="n">b</span><span class="o">:</span><span class="n">u&lt;V&gt;32</span><span class="o">,</span> <span class="n">c</span><span class="o">:</span><span class="n">u&lt;V&gt;32</span><span class="o">,</span> <span class="n">d</span><span class="o">:</span><span class="n">u&lt;V&gt;32</span><span class="p">)</span>
     <span class="k">returns</span> <span class="p">(</span><span class="n">aR</span><span class="o">:</span><span class="n">u&lt;V&gt;32</span><span class="o">,</span> <span class="n">bR</span><span class="o">:</span><span class="n">u&lt;V&gt;32</span><span class="o">,</span> <span class="n">cR</span><span class="o">:</span><span class="n">u&lt;V&gt;32</span><span class="o">,</span> <span class="n">dR</span><span class="o">:</span><span class="n">u&lt;V&gt;32</span><span class="p">)</span>
<span class="k">let</span>
    <span class="n">a</span> <span class="o">:=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">;</span>
    <span class="n">d</span> <span class="o">:=</span> <span class="p">(</span><span class="n">d</span> <span class="o">^</span> <span class="n">a</span><span class="p">)</span> <span class="o">&lt;&lt;&lt;</span> <span class="mi">16</span><span class="p">;</span>
    <span class="n">c</span> <span class="o">:=</span> <span class="n">c</span> <span class="o">+</span> <span class="n">d</span><span class="p">;</span>
    <span class="n">b</span> <span class="o">:=</span> <span class="p">(</span><span class="n">b</span> <span class="o">^</span> <span class="n">c</span><span class="p">)</span> <span class="o">&lt;&lt;&lt;</span> <span class="mi">12</span><span class="p">;</span>
    <span class="n">aR</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">;</span>
    <span class="n">dR</span> <span class="o">=</span> <span class="p">(</span><span class="n">d</span> <span class="o">^</span> <span class="n">aR</span><span class="p">)</span> <span class="o">&lt;&lt;&lt;</span> <span class="mi">8</span><span class="p">;</span>
    <span class="n">cR</span> <span class="o">=</span> <span class="n">c</span> <span class="o">+</span> <span class="n">dR</span><span class="p">;</span>
    <span class="n">bR</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">^</span> <span class="n">cR</span><span class="p">)</span> <span class="o">&lt;&lt;&lt;</span> <span class="mi">7</span><span class="p">;</span>
<span class="k">tel</span>
</code></pre></div></div>

The function, depsite containing only 12 instructions, cannot be
executed in less than 12 cycles: none of the instructions of this
function can be computed in the same cycle, since each of them has a
dependency with the previous one. However, this function is called
consecutively 4 times on independent inputs:

<div class="language-lustre highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">node</span> <span class="nf">DoubleRound</span> <span class="p">(</span><span class="n">state</span><span class="o">:</span><span class="n">u&lt;V&gt;32x16</span><span class="p">)</span> <span class="k">returns</span> <span class="p">(</span><span class="n">stateR</span><span class="o">:</span><span class="n">u&lt;V&gt;32x16</span><span class="p">)</span>
<span class="k">let</span>
    <span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="o">,</span><span class="mi">4</span><span class="o">,</span><span class="mi">8</span><span class="o">,</span><span class="mi">12</span><span class="p">]</span>  <span class="o">:=</span> <span class="n">QR</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="o">,</span><span class="mi">4</span><span class="o">,</span><span class="mi">8</span><span class="o">,</span><span class="mi">12</span><span class="p">]);</span>
    <span class="n">state</span><span class="p">[</span><span class="mi">1</span><span class="o">,</span><span class="mi">5</span><span class="o">,</span><span class="mi">9</span><span class="o">,</span><span class="mi">13</span><span class="p">]</span>  <span class="o">:=</span> <span class="n">QR</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="mi">1</span><span class="o">,</span><span class="mi">5</span><span class="o">,</span><span class="mi">9</span><span class="o">,</span><span class="mi">13</span><span class="p">]);</span>
    <span class="n">state</span><span class="p">[</span><span class="mi">2</span><span class="o">,</span><span class="mi">6</span><span class="o">,</span><span class="mi">10</span><span class="o">,</span><span class="mi">14</span><span class="p">]</span> <span class="o">:=</span> <span class="n">QR</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="mi">2</span><span class="o">,</span><span class="mi">6</span><span class="o">,</span><span class="mi">10</span><span class="o">,</span><span class="mi">14</span><span class="p">]);</span>
    <span class="n">state</span><span class="p">[</span><span class="mi">3</span><span class="o">,</span><span class="mi">7</span><span class="o">,</span><span class="mi">11</span><span class="o">,</span><span class="mi">15</span><span class="p">]</span> <span class="o">:=</span> <span class="n">QR</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="mi">3</span><span class="o">,</span><span class="mi">7</span><span class="o">,</span><span class="mi">11</span><span class="o">,</span><span class="mi">15</span><span class="p">]);</span>
    ...
</code></pre></div></div>

Our scheduling algorithm is thus able to interleave each of those
calls, allowing each of them to be executed simultaneously, and
removing stalls from data dependencies. We thus observe than on
general purpose registers, using this algorithm on Chacha20 brings up
the IPC from 2.79 to 3.44, which translates directly into a x1.05
speedup.

For other ciphers likes AES, Ascon and Clyde, the speedup is lesser
but still a significant x1.04. AES's `ShiftRows` contains 8 shuffle
instructions and nothing else, and thus cannot be executed in less
than 8 cycles. This algorithm allows this function to be performed
simultaneously with either the S-box (`SubBytes`) or the `MixColumn`
step. Both Clyde's and Ascon's linear layer are bottlenecked by
data-dependencies. This algorithm allows those linear layers to be
interleaved with the S-boxes, thus reducing data hazards. 

**Look-behind window size**

The look-behind window needs to be at least _n-1_ on an architecture
than can execute _n_ bitwise/arithmetic instructions per
cycle. However, experimentally, increasing the size of the look-behind
window beyond this number leads to better performances.

To illustrate the impact of the look-behind window size, let's assume
that we want to run the C code below on an CPU that can compute two
xors each cycle:

```c
a1 = x1 ^ x2;
a2 = x3 ^ x4;
b1 = a1 ^ x5;
b2 = a2 ^ x6;
c1 = x7 ^ x8;
c2 = c1 ^ x9;
```

As is, this code would be executed in 4 cycles: during the first one,
`a1` and `a2` would be computed, and during the second one `b1` and
`b2`. However, `c2` depends on `c1` and thus cannot be computed during
the same cycle.

If we were to re-schedule this code using our algorithm with a
look-behind window of 1 instructions, the final scheduling would not
change (assuming that ties are broken using the initial order of the
source, _ie_ that when 2 instructions could be scheduled without
dependencies with the previous ones, the one that came first in the
initial code is selected).

Using a look-behind window of 2 instructions however would produce the
following scheduling:

```c
a1 = x1 ^ x2;
a2 = x3 ^ x4;
c1 = x7 ^ x8;
b1 = a1 ^ x5;
b2 = a2 ^ x6;
c2 = c1 ^ x9;
```

This code can now run in 3 cycles rather than 4. This shows why using
a look-behind window of 2 instructions for SSE/AVX architectures is
not always optimal. In practice, the complexity of the algorithm
depends on the size of the look-behind window, and using arbitrarily
large look-behind windows would be prohibitively
expensive. Experimentally, there is very little to gain by using more
than 10 instructions in the look-behind window, and this size allows
the algorithm to still be fairly fast.




<!-- To do so, one must increase ILP, -->
<!-- taking into account the availability of specialized execution -->
<!-- units. For instance, hsliced code will rely on SIMD shuffle -->
<!-- instructions (vpshufb) that can be executed on a single execution unit -->
<!-- on current Skylake architecture. Performing a sequence of shuffles is -->
<!-- extremely detrimental to performance: the execution of the shuffles -->
<!-- (and their respective dependencies) become serialized, bottlenecking -->
<!-- the dedicated execution unit. -->


<!-- The optimal look-behind window size also depends on the cipher. On -->
<!-- chacha20 for instance, the optimal size is 4 because of the 4 quarter -->
<!-- rounds performed each round, and that need to be interleaved. On ACE -->
<!-- on the other hand, only 3 functions `f` need to be interleaved, and a -->
<!-- look-behind window of 3 instructions is enough to yield a x1.35 -->
<!-- speedup. -->




<!-- Ultimately, C compilers have their own heuristics for scheduling, -->
<!-- prioritizing some instructions over some others. For instance, GCC's -->
<!-- scheduler selects an instruction to schedule among all instructions -->
<!-- ready using the following criteria: -->

<!-- ``` -->
<!-- 1- the instruction with the longest path to the end of the current -->
<!--    basic block. -->
<!-- 2- the instruction contributing the least to register pressure. -->
<!-- ... -->
<!-- 6- the instruction with the least dependencies upon the previously  -->
<!--    scheduled instruction. -->
<!-- ... -->
<!-- ``` -->

<!-- Scheduling the C code prior to this algorithm slightly  -->

<!-- On ciphers which do not need their inner functions to be interleaved, -->
<!-- the performances gained the increasing the size of the look-behind -->
<!-- window -->


## References

[1] R. Sethi, [Complete Register Allocation Problems](https://epubs.siam.org/doi/pdf/10.1137/0204020?casa_token=NVMheBw109IAAAAA%3Ae86ZIKaHkzbEDSYAIJgKzx96NA9ibs9i4nRT2uepjdzHB45wvIgYPQwjxacwkUwapsZREwdNJ8A&), STOC, 1973.

[2] G. J. Chaitin _et al._, [Register allocation via coloring](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.452.8606&rep=rep1&type=pdf), 1981.

[3] G. J. Chaitin, [Register allocation & spilling via graph coloring](https://dl.acm.org/doi/pdf/10.1145/872726.806984), CC, 1982.

[4] P. Briggs _et al._, [Coloring heuristics for register allocation](https://dl.acm.org/doi/pdf/10.1145/74818.74843), PLDI, 1989.

[5] P. Briggs _et al._, [Improvements to graph coloring register allocation](https://dl.acm.org/doi/pdf/10.1145/177492.177575), 1994.

[6] M. Poletto, V. Sarkar, [Linear scan register allocation](https://dl.acm.org/doi/pdf/10.1145/330249.330250), 1999.

[7] B. Alpern _et al._, [The Jalapeño virtual machine](https://pdfs.semanticscholar.org/31e4/5feb1fcc0bd65991e814c68d601402efece2.pdf), 2000.

[8] T. Kotzmann _et al._, [Design of the Java HotSpot client compiler for Java 6](https://dl.acm.org/doi/pdf/10.1145/1369396.1370017), 2008.

[9] C. Wimmer, M. Franz, [Linear scan register allocation on SSA form](https://dl.acm.org/doi/pdf/10.1145/1772954.1772979), CGO, 2010.

[10] H. Mössenböck, M. Pfeiffer, [Linear Scan Register Allocation in the Context of SSA Form and Register Constraints](https://link.springer.com/content/pdf/10.1007/3-540-45937-5_17.pdf), CC, 2002.

[11] P. B. Gibbons, S. S. Muchnick, [Efficient instruction scheduling for a pipelined architecture](https://dl.acm.org/doi/pdf/10.1145/12276.13312), CC, 1986.

[12] D. Bernstein, M. Rodeh, [Global instruction scheduling for superscalar machines](https://dl.acm.org/doi/pdf/10.1145/113445.113466), PLDI, 1991.

[13] R. F. Touzeau, [A Fortran compiler for the FPS-164 scientific computer](https://dl.acm.org/doi/pdf/10.1145/502949.502879), CC, 1984.

[14] J. R. Goodman, W.-C. Hsu, [Code scheduling and register allocation in large basic blocks](https://dl.acm.org/doi/pdf/10.1145/2591635.2667158), ICS, 1988.

[15] S. S. Pinter, [Register allocation with instruction scheduling: a new approach](https://dl.acm.org/doi/pdf/10.1145/155090.155114), PLDI, 1993.

[16] R. Motwani _et al._, [Combining register allocation and instruction scheduling](http://i.stanford.edu/pub/cstr/reports/cs/tn/95/22/CS-TN-95-22.pdf), 1995.

[17] M. D. Smith, G. Holloway, [Graph-Coloring Register Allocation for Irregular Architectures](https://www.cs.tufts.edu/comp/150FP/archive/mike-smith/irreg.pdf), 2001.

[18] V. N. Makarov, [The Integrated Register Allocator for GCC](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.66.1330&rep=rep1&type=pdf#page=77), 2007.

[19] F. Wilcoxon, [Individual comparisons by ranking methods](https://link.springer.com/content/pdf/10.1007%2F978-1-4612-4380-9.pdf), 1992.
