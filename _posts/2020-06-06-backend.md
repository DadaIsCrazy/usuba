---
layout: post
title: Usubac - backend
date: "2020-06-06 00:00:00"
description: The backend of Usuba
lang: en
locale: en_US
author: Darius Mercadier
excerpt: 
comments: false
hidden: true
---


Usubac's backend is responsible of optimizing the codes and utlimately
generating C code.

Generating C code allows us to partially rely on C compiler's
optimizer to improve the performances of the generated
ciphers. However, that alone would not be sufficient to achieve
similar performances as carefuly hand-tuned codes.

We divide our optimizations in two categories. The simple ones (common
subexpression elimination, inlining, unrolling...) are already done by
most C compilers, but we still perform them in Usuba, mainly in order
to improve the effectiveness of the more advanced ones, but also to
not rely too much on the C compiler's optimizers heuristic, which may
not be tailored for cryptographic codes. The more advanced
optimizations include two [scheduling algorithms]({{ site.baseurl}} {%
post_url 2020-05-09-scheduling %}), and an [interleaving pass]({{
site.baseurl}} {% post_url 2020-03-16-interleaving %}), which are
presented in separate posts.

Those advanced optimizations can only be done thanks to the knowledge
we have in Usuba regarding the codes we are dealing with (ciphers),
which C compilers do not have. One of our scheduling algorithm is thus
tailored to reduce the spilling in linear layers of bitsliced ciphers,
while the other one improves instruction level parallelism by mixing
linear layers and S-boxes of msliced ciphers.

Usuba's dataflow programming model is also key for our interleaving
optimization: since Usuba manipulates streams rather than scalars, we
are able to increase instruction level parallelism by processing
several elements of the input stream simultaneously.



### Common Subexpression Elimination, Copy Propagation, Constant Folding

Common subexpression elimination (CSE) is a classical optimization
that aim at preventing identical expressions to be computed multiple
times. When an expression that has already been computed is
recomputed, it is instead replaced by the previously computed
value. For instance,

```c
x = a + b;
y = a + b;
```

would be transformed by CSE into

```c
x = a + b;
y = x;
```

Copy propagation is also a traditional optimization that removes
assignments of a variable into another variable. For instance,

```c
x = a + b;
y = x;
return y;
```

would be transformed by CP into

```c
x = a + b;
return x;
```

Finally, constant folding consists in computing constant expressions
at compile time. The expressions that Usuba simplifies using constant
folding are either arithmetic or bitwise operations between constants
(_eg._ replacing `x = 20 + 22` by `x = 42`) or bitwise operations
whose operand is either `0` or `0xffffffff` (_eg._ replacing `x = a |
0` by `x = a`).

CSE, copy propagation and constant folding are already done by C
compilers. However, performing them in Usubac has two main benefits:

 - It produces smaller C codes, often with very little cost to
   readability. A non-negligible part of the copies removed by copy
   propagation comes from temporary variables introduced by the
   compiler itself. Removing such assignments actually improves
   readability. This matters especially in bitsliced codes, which can
   contain tens of thousands lines of C code after those
   optimizations, and that would contain hundreds of thousands lines
   without them. For instance, ACE bitsliced is about 200.000
   instructions without those optimizations but only 50.000 with them.
   
 - It makes the [scheduling optimizations]({{ site.baseurl}} {%
   post_url 2020-05-09-scheduling %}) more efficient. Needless
   assignments and redundant expressions increase the number of live
   variables, which may throw off the schedulers. 

### Unrolling



### Inlining

The decision of inlining nodes is partly justified by the usual
reasoning applied by C compilers: a function call implies a
significant overhead that, for very frequently called functions (such
as S-boxes, in our case) makes it worth the increase in code size. In
fact, all the compilers we have tested (excepted GCC in some
situations) are able to spot the fact that S-boxes, for example,
benefit from being inlined. Usubac is only a helping hand here, making
sure that the user does not observe a performance regression because
of what could only be characterized as a bug in the C compiler’s
heuristics.

Bitslicing, however, sends the inlining heuristics of C compilers
astray. A bitsliced node compiles to a C function taking hundreds of
variables as inputs and outputs. For instance, the round function in
DES takes 120 arguments once bitsliced. Calling such a function
requires the caller to push hundreds of variables onto the stack while
the callee has to go through the stack to retrieve them, leading to a
significant execution overhead but also a growth in code size. C
compilers naturally avoid inlining this function because its code is
quite large, missing the fact that calling it actually becomes a
bottleneck.

On DES, inlining results in a 44.8% improvement in throughput while
actually reducing code size by 9.1%. Similarly, a bitsliced
implementation of AES (automatically obtained from the more efficient
hsliced version) is 24.24% more efficient with inlining at the expense
of a 24.8% increase in code size.  Because the AES round function is
significantly larger than its number of input variables, we notice an
increase of code size. However, increasing code size is hardly a
performance issue in our setting: our code is executed in a
straight-line sequence, with few to no control flow instructions. As a
result, whatever big the resulting binary is, instruction prefetch
allows us to amortize the few cache misses over the whole cache lines.

Besides, inlining offers more opportunities for scheduling. For
instance, symmetric cipher are usually composed of a sequence of 10 to
20 applications of a single round function.  Inlining this function
enables Usubac to schedule instructions across rounds, so as to
increase ILP.


### Benchmark-guided optimizations


The impact of some optimizations is hard to predict. Inlining reduces
the overhead of calling functions, but increases the register pressure
and produces codes that do not fully exploit the μop cache (DSB). Our
interleaving algorithm improves instruction level parallelism, but at
the expense of register pressure.

Usubac can enable or disable heuristic optimizations by benchmarking
their outcome. The optimizations concerned by this approach are
inlining, unrolling, scheduling and interleaving. Two important facts allows us
to do this:

 - The compilation time is not as important as with traditional C
   compilers.  
   Futhermore, time-costly optimizations can be disabled while
   developping in order to speed up debugging, and enabled again to
   generate the final optimized C code.
   
 - The control flow is independent of the inputs, as a direct
   consequence of using bitslicing and mslicing.



The limitation of this technique however, is that benchmarks are run
on the machine used to compile the Usuba program, and that the tuning
resulting of the benchmarks by not be optimal for another architecture.



### Code generation


C + SIMD (macros)




### Remark

It would be tempting to integrate the above optimizations as a
domain-specific backend for, say, LLVM [1].  We conjecture that the
resulting compiler would not be radically different nor significantly
faster than Usuba. First, our optimizations are complementary to those
performed by the C compiler (_e.g._, inlining). They would be
expressed almost as-is over LLVM-IR. Second, Table 2 will show that
there is no silver bullet among compilers: we are currently free to
pick the absolute best compiler, even if closed source. Third, going
the extra mile and targeting C simplifies integration in existing code
bases, as witnessed by the incorporation of the C files produced by
HACL* [2] into the Firefox and Wireguard projects. This allows the
cryptographical primitives to potentially outlive the DSL. In the
following, we evaluate the performance of the code generated by our
compiler.


---
## References

[1] C. Lattner, V. Adve, [LLVM: A Compilation Framework for Lifelong Program Analysis & Transformation](https://llvm.org/pubs/2003-09-30-LifelongOptimizationTR.pdf), CGO, 2004.

[2] J.-K. Zinzindohoué _et al_, [HACL*, A Verified Modern Crytographic Library](https://hal.inria.fr/hal-01588421v2/document), ACM Conference on Computer and Communications Security, 2017.
