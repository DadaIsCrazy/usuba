---
layout: post
title: Usubac - backend
date: "2020-06-06 00:00:00"
description: The backend of Usuba
lang: en
locale: en_US
author: Darius Mercadier
excerpt: subac's backend is responsible of optimizing the Usuba0 code and utlimately generating C code. Masking is also done in the backend, but will be presented in a later post.
comments: true
hidden: false
---


Usubac's backend is responsible of optimizing the Usuba0 code and
utlimately generating C code. Masking is also done in the backend, but
will be presented in a later post.

Generating C code allows us to partially rely on C compiler's
optimizer to improve the performances of the generated
ciphers. However, that alone would not be sufficient to achieve
similar performances as carefuly hand-tuned codes.

We divide our optimizations in two categories. The simple ones (common
subexpression elimination, inlining, unrolling...) are already done by
most C compilers, but we still perform them in Usuba, mainly in order
to improve the effectiveness of the more advanced ones, but also to
not rely too much on the C compiler's optimizers heuristic, which may
not be tailored for cryptographic codes. The more advanced
optimizations include two [scheduling algorithms]({{ site.baseurl}} {%
post_url 2020-05-09-scheduling %}), and an [interleaving pass]({{
site.baseurl}} {% post_url 2020-03-16-interleaving %}), which are
presented in separate posts.

Those advanced optimizations can only be done thanks to the knowledge
we have in Usuba regarding the codes we are dealing with (ciphers),
which C compilers do not have. One of our scheduling algorithm is thus
tailored to reduce the spilling in linear layers of bitsliced ciphers,
while the other one improves instruction level parallelism by mixing
linear layers and S-boxes of msliced ciphers.

Usuba's dataflow programming model is also key for our interleaving
optimization: since Usuba manipulates streams rather than scalars, we
are able to increase instruction level parallelism by processing
several elements of the input stream simultaneously.



### Common Subexpression Elimination, Copy Propagation, Constant Folding

Common subexpression elimination (CSE) is a classical optimization
that aim at preventing identical expressions to be computed multiple
times. When an expression that has already been computed is
recomputed, it is instead replaced by the previously computed
value. For instance,

```c
x = a + b;
y = a + b;
```

would be transformed by CSE into

```c
x = a + b;
y = x;
```

Copy propagation is also a traditional optimization that removes
assignments of a variable into another variable. For instance,

```c
x = a + b;
y = x;
return y;
```

would be transformed by CP into

```c
x = a + b;
return x;
```

Finally, constant folding consists in computing constant expressions
at compile time. The expressions that Usuba simplifies using constant
folding are either arithmetic or bitwise operations between constants
(_eg._ replacing `x = 20 + 22` by `x = 42`) or bitwise operations
whose operand is either `0` or `0xffffffff` (_eg._ replacing `x = a |
0` by `x = a`).

CSE, copy propagation and constant folding are already done by C
compilers. However, performing them in Usubac has two main benefits:

 - It produces smaller C codes, often with very little cost to
   readability. A non-negligible part of the copies removed by copy
   propagation comes from temporary variables introduced by the
   compiler itself. Removing such assignments actually improves
   readability. This matters especially in bitsliced codes, which can
   contain tens of thousands lines of C code after those
   optimizations, and that would contain hundreds of thousands lines
   without them. For instance, ACE bitsliced is about 200.000
   instructions without those optimizations but only 50.000 with them.
   
 - It makes the [scheduling optimizations]({{ site.baseurl}}{%
   post_url 2020-05-09-scheduling %}) more efficient. Needless
   assignments and redundant expressions increase the number of live
   variables, which may throw off the schedulers. 

### Unrolling


Unrolling is actually done is the frontend rather than in the
backend. However, it is considered as an optimization in most
compilers, and heavily impacts performances, which is why we discuss
it now.

**Normalization**

In two cases, unrolling is necessary to normalize to Usuba code down
to Usuba0. The first one is shifts and rotations on tuples that
depends on loop variables. For instance,

<div class="language-lustre highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="ow">forall</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="p">]</span> <span class="p">{</span>
    <span class="p">(</span><span class="n">x0</span><span class="o">,</span><span class="n">x1</span><span class="o">,</span><span class="n">x2</span><span class="p">)</span> <span class="o">:=</span> <span class="p">(</span><span class="n">x0</span><span class="o">,</span><span class="n">x1</span><span class="o">,</span><span class="n">x2</span><span class="p">)</span> <span class="o">&lt;&lt;&lt;</span> <span class="n">i</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

Since rotations on tuples are resolved at compile time, this one
requires the loop to be unrolled into

```lustre
(x0,x1,x2) := (x0,x1,x2) <<< 1;
(x0,x1,x2) := (x0,x1,x2) <<< 2;
```

Which is then simplified to

```lustre
(x0,x1,x2) := (x1,x2,x0);
(x0,x1,x2) := (x2,x0,x1);
```

Which we be later optimized away by copy propagation.

The other case where unrolling is needed at compile time is when nodes
from arrays of nodes are called in loops. This is for instance the
case with Serpent, which uses a different S-box for each round, and
whose main loop is thus:

<div class="language-lustre highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="ow">forall</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="o">,</span><span class="mi">30</span><span class="p">]</span> <span class="p">{</span>
    <span class="n">state</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">linear_layer</span><span class="p">(</span><span class="n">sbox</span><span class="o">&lt;</span><span class="n">i</span><span class="o">%</span><span class="mi">8</span><span class="o">&gt;</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">^</span> <span class="n">keys</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
<span class="p">}</span>
</code></pre></div></div>

Which, after unrolling, becomes:

```lustre
state[1] = linear_layer(sbox0(state[0] ^ keys[0]))
state[2] = linear_layer(sbox1(state[1] ^ keys[1]))
state[3] = linear_layer(sbox2(state[2] ^ keys[2]))
...
```

Note that unrolling is not is only possible way to deal with arrays of
nodes. We could have for instance introduced conditionals in Usuba in
order to normalize this code into something like

<div class="language-lustre highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="ow">forall</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="o">,</span><span class="mi">30</span><span class="p">]</span> <span class="p">{</span>
    <span class="ow">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="mi">8</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">state</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">linear_layer</span><span class="p">(</span><span class="n">sbox0</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">^</span> <span class="n">keys</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    <span class="p">}</span> <span class="ow">elsif</span> <span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="mi">8</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">state</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">linear_layer</span><span class="p">(</span><span class="n">sbox1</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">^</span> <span class="n">keys</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    <span class="p">}</span> <span class="ow">elsif</span> 
        <span class="o">...</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>


However, we advised against it in order to no introduce unnecessary
complexity into Usuba0, which could have made other optimizations
harder to implement, and would have produce C code that would have
likely be less efficient.


**Optimization**

In practice, all loops are automatically unrolled by Usubac by
default. Experimentally, this produce the most efficient codes. The
user can still use the flag `-no-unroll` to disable non-essential
unrolling (_ie._ unrolling that is not required by the
normalization). In the following, we explain the reasoning behind the
aggressive unrolling performed by Usubac.

For bitsliced codes, the decision of unrolling is very straightforward
since almost all ciphers contain some permutations or rotations that
can be optimized away at compile time only if the loop they are in are
unrolled. For msliced codes, the decision to unroll all loops is more
complex.

Very small loops are always more efficient when unrolled since the
overhead of looping would hurt the performances, and the unrolling
does not increase code size too much.

Furthermore, unrolling small and medium-sized loops is often
beneficial as well because it allows our scheduling algorithm to be
more efficient. Loops are bound to contain dependencies from one
iteration to the next one, which may limit their performances, and
thus benefit from being unrolled and interleaved (by the scheduler)
with other parts of the cipher. The [scheduling post]({{
site.baseurl}}{% post_url 2020-05-09-scheduling %}#mslicing) shows for
instance the of ACE, which is bottlenecked by a loop and that our
scheduling algorithm is able to optimize by interleaving 3 loops (at
the condition that they are unrolled).


We may want to keep large loops in the final code in order to reduce
code size and maximize the usage of the μop cache (DSB). For instance,
in Chacha20, unrolling the main loop (_ie_ the one that calls the
round function) does not offer any performance improvement (nor does
it decrease the performances for that matter). However, it is hard to
chose an upper bound above which unrolling should not be done. For
instance, Pyjamask contains a matrix multiplication in a loop:

<div class="language-lustre highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="ow">forall</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="o">,</span> <span class="mi">3</span><span class="p">]</span> <span class="p">{</span>
    <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">mat_mult</span><span class="p">(</span><span class="n">M</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">,</span> <span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="p">}</span>
</code></pre></div></div>


After inlining, `mat_mult` becomes 160 instructions, which is more
that the number of instructions in Rectangle's round (15), or in
Ascon's (32) or in Chacha20's (96). However, those instructions are
heavily bottlenecked by data-dependencies, and unrolling the loop in
Usuba (Clang choses not to unroll it on its own) speeds up the
performances of Pyjasmask by a factor 1.68.


In practice, we thus chose to aggressively unroll all loops in Usuba,
regardless of their contents. We never observed any performance
regression because of our unrolling.


### Inlining

The decision of inlining nodes is partly justified by the usual
reasoning applied by C compilers: a function call implies a
significant overhead that, for very frequently called functions (such
as S-boxes, in our case) makes it worth the increase in code
size. However, Usuba's [m-sliched code scheduling algorithm]({{
site.baseurl}}{% post_url 2020-05-09-scheduling %}) requires some
inlining since one of its effects is to interleave nodes to increase
instruction level parallelism. We thus perform some inlining in
Usuba. The following table shows the speedups gained by inlining all
nodes on some msliced ciphers, compared to inlining none:

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-18eh{border-color:#000000;font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-65px{background-color:#ecf4ff;border-color:#000000;text-align:left;vertical-align:top}
.tg .tg-wsl5{border-color:#000000;color:#fe0000;text-align:left;vertical-align:top}
.tg .tg-3u1j{background-color:#ecf4ff;border-color:#000000;color:#32cb00;text-align:left;vertical-align:top}
.tg .tg-mqa1{border-color:#000000;font-weight:bold;text-align:center;vertical-align:top}
.tg .tg-73oq{border-color:#000000;text-align:left;vertical-align:top}
.tg .tg-085k{border-color:#000000;color:#32cb00;text-align:left;vertical-align:top}
.tg .tg-376w{background-color:#ecf4ff;border-color:#000000;color:#fe0000;text-align:left;vertical-align:top}
</style>

<center>
<table class="tg" style="undefined;table-layout: fixed; width: 614px; margin-top:30px;margin-bottom:30px">
<colgroup>
<col style="width: 156px">
<col style="width: 115px">
<col style="width: 115px">
<col style="width: 114px">
<col style="width: 114px">
</colgroup>
<thead>
  <tr>
    <td class="tg-mqa1" colspan="5">mslicing</td>
  </tr>
  <tr>
    <th class="tg-18eh" rowspan="3">Cipher</th>
    <th class="tg-18eh" colspan="4">Inlining speedup</th>
  </tr>
  <tr>
    <td class="tg-18eh" colspan="2">clang</td>
    <td class="tg-18eh" colspan="2">gcc</td>
  </tr>
  <tr>
    <td class="tg-18eh">x86</td>
    <td class="tg-18eh">AVX2</td>
    <td class="tg-18eh">x86</td>
    <td class="tg-18eh">AVX2</td>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-73oq">ACE</td>
    <td class="tg-085k">1.54</td>
    <td class="tg-085k">1.33</td>
    <td class="tg-085k">1.64</td>
    <td class="tg-085k">1.01</td>
  </tr>
  <tr>
    <td class="tg-65px">AES</td>
    <td class="tg-65px">-</td>
    <td class="tg-3u1j">1.01</td>
    <td class="tg-65px">-</td>
    <td class="tg-3u1j">1.43</td>
  </tr>
  <tr>
    <td class="tg-73oq">Ascon</td>
    <td class="tg-085k">1.20</td>
    <td class="tg-085k">1.01</td>
    <td class="tg-085k">1.89</td>
    <td class="tg-085k">1.15</td>
  </tr>
  <tr>
    <td class="tg-65px">Chacha20</td>
    <td class="tg-3u1j">1.25</td>
    <td class="tg-3u1j">1.11</td>
    <td class="tg-3u1j">1.23</td>
    <td class="tg-3u1j">1.20</td>
  </tr>
  <tr>
    <td class="tg-73oq">Clyde</td>
    <td class="tg-085k">1.16</td>
    <td class="tg-085k">1.02</td>
    <td class="tg-085k">1.16</td>
    <td class="tg-085k">1.22</td>
  </tr>
  <tr>
    <td class="tg-65px">Gift</td>
    <td class="tg-3u1j">1.69</td>
    <td class="tg-376w">0.93</td>
    <td class="tg-3u1j">1.37</td>
    <td class="tg-3u1j">1.05</td>
  </tr>
  <tr>
    <td class="tg-73oq">Gimli</td>
    <td class="tg-wsl5">0.97</td>
    <td class="tg-wsl5">0.99</td>
    <td class="tg-085k">1.23</td>
    <td class="tg-085k">1.33</td>
  </tr>
  <tr>
    <td class="tg-65px">Pyjamask</td>
    <td class="tg-3u1j">1.35</td>
    <td class="tg-376w">0.99</td>
    <td class="tg-3u1j">1.08</td>
    <td class="tg-3u1j">1.11</td>
  </tr>
  <tr>
    <td class="tg-73oq">Rectangle (H)</td>
    <td class="tg-73oq">-</td>
    <td class="tg-wsl5">0.96</td>
    <td class="tg-73oq">-</td>
    <td class="tg-wsl5">0.97</td>
  </tr>
  <tr>
    <td class="tg-65px">Rectangle (V)</td>
    <td class="tg-65px">1.00</td>
    <td class="tg-376w">0.99</td>
    <td class="tg-376w">0.97</td>
    <td class="tg-376w">0.96</td>
  </tr>
  <tr>
    <td class="tg-73oq">Serpent</td>
    <td class="tg-085k">1.01</td>
    <td class="tg-wsl5">0.99</td>
    <td class="tg-085k">1.27</td>
    <td class="tg-085k">1.27</td>
  </tr>
  <tr>
    <td class="tg-65px">Xoodoo</td>
    <td class="tg-3u1j">1.25</td>
    <td class="tg-376w">0.98</td>
    <td class="tg-3u1j">1.61</td>
    <td class="tg-3u1j">1.39</td>
  </tr>
</tbody>
</table>
</center>

The impact of inlining depends on which C compiler is used, and the
architecture targeted. For instance, inlining every node of Xoodoo
speeds it up by a factor 1.61 on general purpose x86 register when
compiling with gcc, but slows it down by a factor 0.98 on AVX2
registers when compiling with Clang. Overall, inlining every nodes is
generally beneficial for performances, providing speedups of up to
1.89 (Ascon on GP x86 registers with gcc), but can sometimes be
detrimental and reduce the performances by a few percents.

On AVX2 registers, when compiling with Clang, inlining tends to be
slightly detrimental, as can be seen from the lower half of the third
column. Those ciphers are the ones that benefits the less from our
scheduling optimization, as can be seen from the table in the [section
mslicing of the scheduling post]({{site.baseurl}}{% post_url
2020-05-09-scheduling %}#mslicing). 
One of the reason for this performance regression is the fact that
fully inlined AVX code do not use the μop cache (DSB), but falls back
to the MITE. On Gift compiled with Clang for instance, when all nodes
are inlined, almost no μop is issued by the DSB, while when no node is
inlined, 85% of the μops come from the DSB. This translates directly
into a reduces instruction per cycle count: the inlined version is at
2.58 instructions per cycles, while the non-inlined version is at
3.25. The translates in a mere 0.93 slowdown however, because the
fully inlined code still contains 15% less instructions.

The gain of inlining are not only explained by the scheduling that
follows. For instance, scheduling improves the performances of Gift,
Clyde, Xoodoo and Chacha20 on general purpose by merely x1.01, x1.02,
x1.03 and x1.05, yet fully inlining those ciphers speeds them up by
x1.69, x1.16, x1.25 and x1.25 (with Clang). In those cases, both Clang
and gcc chose not to be too aggressive on inlining, probably in order
not to increase code size too much, but this came at the expense of
performances.



Bitslicing, however, sends the inlining heuristics of C compilers much
more astray. A bitsliced node compiles to a C function taking hundreds
of variables as inputs and outputs. For instance, the round function
in DES takes 120 arguments once bitsliced. Calling such a function
requires the caller to push hundreds of variables onto the stack while
the callee has to go through the stack to retrieve them, leading to a
significant execution overhead but also a growth in code
size. Similarly, permutations, depending on how they are written in
the Usuba source, can be compiled into a function which takes hundreds
of arguments and just does assignments, while once inlined, it is
virtually optimized away by copy propagation. C compilers avoid
inlining such functions because their codes are quite large, missing
the fact that they are major bottlenecks.

The following table shows the performance impact of inlining in
bitsliced ciphers:

<center>
<table class="tg" style="undefined;table-layout: fixed; width: 614px; margin-top:30px;margin-bottom:30px">
<colgroup>
<col style="width: 156px">
<col style="width: 115px">
<col style="width: 115px">
<col style="width: 114px">
<col style="width: 114px">
</colgroup>
<thead>
  <tr>
    <td class="tg-mqa1" colspan="5">bitslicing</td>
  </tr>
  <tr>
    <th class="tg-18eh" rowspan="3">Cipher</th>
    <th class="tg-18eh" colspan="4">Inlining speedup</th>
  </tr>
  <tr>
    <td class="tg-18eh" colspan="2">clang</td>
    <td class="tg-18eh" colspan="2">gcc</td>
  </tr>
  <tr>
    <td class="tg-18eh">x86</td>
    <td class="tg-18eh">AVX2</td>
    <td class="tg-18eh">x86</td>
    <td class="tg-18eh">AVX2</td>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-73oq">ACE</td>
    <td class="tg-085k">1.16</td>
    <td class="tg-085k">1.54</td>
    <td class="tg-085k">1.75</td>
    <td class="tg-085k">3.57</td>
  </tr>
  <tr>
    <td class="tg-65px">AES</td>
    <td class="tg-3u1j">1.28</td>
    <td class="tg-3u1j">1.64</td>
    <td class="tg-3u1j">1.27</td>
    <td class="tg-3u1j">1.43</td>
  </tr>
  <tr>
    <td class="tg-73oq">Ascon</td>
    <td class="tg-085k">1.20</td>
    <td class="tg-085k">2.50</td>
    <td class="tg-085k">1.45</td>
    <td class="tg-085k">2.56</td>
  </tr>
  <tr>
    <td class="tg-65px">Clyde</td>
    <td class="tg-3u1j">1.08</td>
    <td class="tg-3u1j">1.79</td>
    <td class="tg-3u1j">1.02</td>
    <td class="tg-3u1j">1.35</td>
  </tr>
  <tr>
    <td class="tg-73oq">DES</td>
    <td class="tg-085k">1.41</td>
    <td class="tg-085k">1.96</td>
    <td class="tg-085k">1.30</td>
    <td class="tg-085k">1.72</td>
  </tr>
  <tr>
    <td class="tg-65px">Gift</td>
    <td class="tg-3u1j">3.70</td>
    <td class="tg-3u1j">5.88</td>
    <td class="tg-3u1j">3.45</td>
    <td class="tg-3u1j">8.33</td>
  </tr>
  <tr>
    <td class="tg-73oq">Gimli</td>
    <td class="tg-085k">1.41</td>
    <td class="tg-085k">2.00</td>
    <td class="tg-085k">1.79</td>
    <td class="tg-085k">3.03</td>
  </tr>
  <tr>
    <td class="tg-65px">Photon</td>
    <td class="tg-3u1j">1.18</td>
    <td class="tg-3u1j">1.75</td>
    <td class="tg-3u1j">2.00</td>
    <td class="tg-3u1j">2.44</td>
  </tr>
  <tr>
    <td class="tg-73oq">Present</td>
    <td class="tg-085k">1.23</td>
    <td class="tg-085k">1.08</td>
    <td class="tg-085k">1.05</td>
    <td class="tg-wsl5">0.97</td>
  </tr>
  <tr>
    <td class="tg-65px">Pyjamask</td>
    <td class="tg-3u1j">5.26</td>
    <td class="tg-3u1j">1.20</td>
    <td class="tg-3u1j">8.33</td>
    <td class="tg-3u1j">8.33</td>
  </tr>
  <tr>
    <td class="tg-73oq">Rectangle</td>
    <td class="tg-085k">1.72</td>
    <td class="tg-085k">2.33</td>
    <td class="tg-085k">1.59</td>
    <td class="tg-085k">2.44</td>
  </tr>
  <tr>
    <td class="tg-65px">Skinny</td>
    <td class="tg-3u1j">2.63</td>
    <td class="tg-3u1j">4.00</td>
    <td class="tg-3u1j">2.78</td>
    <td class="tg-3u1j">4.76</td>
  </tr>
  <tr>
    <td class="tg-73oq">Spongent</td>
    <td class="tg-085k">1.52</td>
    <td class="tg-085k">3.12</td>
    <td class="tg-085k">1.49</td>
    <td class="tg-085k">3.03</td>
  </tr>
  <tr>
    <td class="tg-65px">Subterranean</td>
    <td class="tg-3u1j">2.00</td>
    <td class="tg-3u1j">3.03</td>
    <td class="tg-3u1j">1.96</td>
    <td class="tg-3u1j">2.86</td>
  </tr>
  <tr>
    <td class="tg-73oq">Xoodoo</td>
    <td class="tg-085k">1.37</td>
    <td class="tg-085k">2.33</td>
    <td class="tg-085k">1.47</td>
    <td class="tg-085k">2.08</td>
  </tr>
</tbody>
</table>
</center>

Inlining improves performances in all cases, reaching an impressive 8
times speed up for Pyjamask on general purpose registers with
gcc. With some of those improvements are explained by the scheduling
enabled by inlining, most of them are due to the overhead saved by not
calling functions, and by the copy propagation being able to remove
unnecessary asignments. One of the take away from those benchmarks is
that modern C compilers' heuristic for inlining are not suited for
Usuba-generated bitsliced codes.


### Benchmark-guided optimizations


The impact of some optimizations is hard to predict. Inlining reduces
the overhead of calling functions, but increases the register pressure
and produces codes that do not fully exploit the μop cache (DSB). Our
interleaving algorithm improves instruction level parallelism, but at
the expense of register pressure. Our scheduling algorithm for
bitsliced code tries to reduce register pressure, but this could fail
depending on the heuristic of the C compilers that comes after. Our
scheduling algorithm for msliced codes increases instruction level
parallelism, but this sometimes either increase register pressure or
simply produces codes that the C compiler is less keen to optimize.

Since our goal is to produce the most efficient codes possible, it is
counter-productive that some optimizations hurt the performances. In
order to overcome those "failed" optimizations, Usubac can enable or
disable heuristic optimizations (inlining, scheduling, interleaving)
by benchmarking their outcome. We are able to do this because we are
in a setting where:

 - The compilation time is not as important as with traditional C
   compilers. The generated ciphers will likely be ran for a long
   time, and _need_ to be optimized for performance in order not to
   bottleneck any application. Futhermore, time-costly optimizations
   can be disabled while developping in order to speed up debugging,
   and enabled again to generate the final optimized C code.
   
 - The control flow is independent of the inputs, as a direct
   consequence of using bitslicing and mslicing. While benchmarking a
   C program requires some kind of fuzzy testing, and always risk
   missing a frequent case, in Usuba, every run of a program will have
   the same performances regardless of the inputs.


In the performance results presented throughout above for the
inlining, or in the scheduling and interleaving post, any performance
regression will be caught by Usubac's benchmark engine, and the
optimization will thus be disabled.


The limitation of this technique however, is that benchmarks are run
on the machine used to compile the Usuba program, and the tuning
resulting of the benchmarks may not be optimal for another
architecture. This could be partly mitigated by modifying Usubac's
benchmarking engine to remotely connect to another machine for the
benchmarks, but we have not done so yet.



### Code generation


Compiling Usuba0 to C is very straightforward. Nodes are translated to
function definitions, and node calls to function calls. All
expressions in Usuba0 have a natural equivalent in C, with the
exception of Usuba's `Shuffle`, which can only be compiled for SIMD
architecture and uses the available intrinsics (`_mm256_shuffle_epi32`
or `_mm256_shuffle_epi8` on AVX2 for instance).

The generated C code relies on macros rather than inline
operators. For instance, compiling the following Usuba0 nodes to C:

<div class="language-lustre highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">node</span> <span class="nf">sbox</span> <span class="p">(</span><span class="n">i0</span><span class="o">:</span><span class="n">u32</span><span class="o">,</span> <span class="n">i1</span><span class="o">:</span><span class="n">u32</span><span class="p">)</span>
     <span class="k">returns</span> <span class="p">(</span><span class="n">r0</span><span class="o">:</span><span class="n">u32</span><span class="o">,</span> <span class="n">r1</span><span class="o">:</span><span class="n">u32</span><span class="p">)</span>
<span class="k">vars</span> <span class="n">t1</span> <span class="o">:</span> <span class="n">u32</span>
<span class="k">let</span>
    <span class="n">t1</span> <span class="o">=</span> <span class="o">~</span><span class="n">i0</span><span class="p">;</span>
    <span class="n">r0</span> <span class="o">=</span> <span class="n">t1</span> <span class="o">&amp;</span> <span class="n">i1</span><span class="p">;</span>
    <span class="n">r1</span> <span class="o">=</span> <span class="n">t1</span> <span class="o">|</span> <span class="n">i1</span><span class="p">;</span>
<span class="k">tel</span>
</code></pre></div></div>

Produces


<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">sbox__</span> <span class="p">(</span><span class="cm">/*inputs*/</span> <span class="kt">DATATYPE</span> <span class="n">i0__</span><span class="p">,</span><span class="kt">DATATYPE</span> <span class="n">i1__</span><span class="p">,</span> 
             <span class="cm">/*outputs*/</span> <span class="kt">DATATYPE</span><span class="o">*</span> <span class="n">r0__</span><span class="p">,</span><span class="kt">DATATYPE</span><span class="o">*</span> <span class="n">r1__</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// Variables declaration</span>
  <span class="kt">DATATYPE</span> <span class="n">t1__</span><span class="p">;</span>

  <span class="c1">// Instructions (body)</span>
  <span class="n">t1__</span> <span class="o">=</span> <span class="n">NOT</span><span class="p">(</span><span class="n">i0__</span><span class="p">);</span>
  <span class="o">*</span><span class="n">r0__</span> <span class="o">=</span> <span class="n">AND</span><span class="p">(</span><span class="n">t1__</span><span class="p">,</span><span class="n">i1__</span><span class="p">);</span>
  <span class="o">*</span><span class="n">r1__</span> <span class="o">=</span> <span class="n">OR</span><span class="p">(</span><span class="n">t1__</span><span class="p">,</span><span class="n">i1__</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>


Where `DATATYPE` is `unsigned int` on 32-bit registers, `__m128i` on
SSE, `__m256i` on AVX2, etc., and `NOT`, `AND` and `OR` are defined to
use the architecture's instructions. Using macros allows us to change
the architecture of the generated code by simply changing a
header. The new header must provide the same instructions, which means
that for instance a code compiled for AVX2 and using `Shuffle`s cannot
be ran on general purpose registers by simply changing the header
since no shuffle would be available.


Usubac performs no architecture-specific optimizations, beyond its
scheduling and interleaving that targets superscalar
architectures. Put otherwise, we do not compile any differently a code
for SSE or AVX2, execpt that Usubac's automatic benchmarking may
select different optimizations for each architecture. For general
purpose registers, SSE, AVX and AVX2, the instructions used for
crytpographic primitives are fairly similar, and we felt that there
was no need to optimize differently on each architecture. In most
cases where architecture-specific instructions can be used to speed up
computation, Clang and gcc are able to detect it and optimize for us.


The AVX512 instruction is however much richer, and opens the door for
more optimizations. For instance, it offers the instruction
`vpternlogd` which can compute any boolean function with 3 inputs. It
can be useful to speed up S-boxes in particular. For instance,

```c
t1 = a ^ b;
t2 = t1 & c;
```

Can be written with a single `vpternlog` as

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">t2</span> <span class="o">=</span> <span class="n">_mm512_ternarylogic_epi64</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="mi">0b00010100</span><span class="p">);</span>
</code></pre></div></div>

Thus requiring one instruction rather than two. Clang is able to
automatically perform this optimization in some cases, but we leave
for future work to evaluate whether Usubac could improve on Clang on
that aspect.
