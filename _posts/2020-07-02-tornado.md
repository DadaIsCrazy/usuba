---
layout: post
title: Tornado, Automatic Generation of Probing-Secure Masked Sliced Implementations
date: "2020-07-02 00:00:00"
description: 
lang: en
locale: en_US
author: Darius Mercadier
excerpt: CPU leak information through timings, caches accesses, power consumption, electromagnetic radiations or other compromising emanations. One very powerful way to recover this leaked information is to design a Simple Power Analysis (SPA) or a more powerful Differential Power Analysis (DPA) attack, which work by analyzing power or EM traces from a cipher's execution to recover the key and plaintext. Several approaches to mitigate SPA and DPA have been proposed
comments: true
hidden: false
---


CPU leak information through timings [49], caches accesses [52,53,54],
power consumption [48,49,42], electromagnetic radiations [45,46,47] or
other _compromising emanations_ [50,51]. One very powerful way to
recover this leaked information is to design a Simple Power Analysis
(SPA) or a more powerful Differential Power Analysis (DPA) attack [23],
which work by analyzing power or EM traces from a cipher's execution
to recover the key and plaintext.

Several approaches to mitigate SPA and DPA have been proposed. For
instance, inserting dummy instructions, working with both data and
their complements or using hardware modules to randomize power
consumption [40], designing hardware gates whose power consumption is
independent of their inputs [32,41] or other hardware randomization
modules [75]. The most popular countermeasures against SPA and DPA are
however based on _secret sharing_ [24,25], since they offer provable
security.


#### Masking

The first masking schemes were proposed by Chari _et al._ [38] and
Goubin and Patarin [39]. The principle of masking is to split each
intermediate value _b_ of a cipher into _k_ random values _r1 ... rk_
(called _shares_) such that `b = r1 ∗ r2 ∗ ... ∗ rk` for some group
operation `∗`. The most commonly used operation is the exclusive or
(resulting in a _boolean masking_ scheme), but modular addition or
modular multiplication can also be used (resulting in an _arithmetic
masking_ scheme) [28,26]. 

The number of shares (_k_) is called the _masking order_. Early masked
implementations were only using two shares [28,26,37,27], which is
sufficient to protect against first-order DPA. However, _higher order
DPA_ (HO-DPA) can be designed by combining multiple sources of leakage
to reconstruct the secrets, and can break first-order masked
implementations [23,42,55,56]. When the masking order is greater than
one, the term _higher-order_ masking is used [29,63,65,66,68].

The _probing-model_ is widely used to analyze the security of masked
software implementations against side-channel attacks. This model was
introduced by Ishai, Sahai and Wagner in [29] to construct circuits
resistant to hardware probing attacks. It was latter shown that this
model and the underlying construction were instrumental to the design
of efficient practically-secure masked cryptographic implementations
[63,68,64]. A masking scheme secure against a _t_-probing adversary,
_i.e._ who can probe _t_ arbitrary variables in the computation, is
indeed secure by design against the class of side-channel attacks of
order _t_ [91].

Most masking schemes consider the implementation to be protected as a
Boolean or arithmetic circuit composed of gates of different
natures. These gates are then replaced bygadgets processing masked
variables. One of the important contributions of [29] was to propose a
multiplication gadget secure against _t_-probing attacks for any _t_,
based on a Boolean masking of order _n = 2t+1_. This was reduced to
the tight order _n = t+1_ in [66] by constraining the two input
sharings to be independent, which could be ensured by the application
of a mask-refreshing gadget when necessary. The design of secure
refresh gadgets and, more generally, the secure composition of gadgets
were subsequently subject to many works [64,87,92]. Of particular
interest, the notions of Non-Interference (NI) and Strong
Non-Interference (SNI) introduced in [87] provide a practical
framework for the secure composition of gadgets which yields tight
probing-secure masked implementations. In a nutshell, such
implementations are composed of ISW multiplication and refresh gadgets
(from the names oftheir inventors Ishai, Sahai, and Wagner [48])
achieving the SNI property, and of sharewise addition gadgets. The
main technical challenge in such a context is to identify the number
of required refresh gadgets and their (optimal) placing in the
implementation to obtain a provablet-probing security.

#### Automatic software countermeasures

Several approaches have been proposed to automatically secure
implementations against power-based side-channel attacks. We review
the main ones in chronological order.


Bayrak _et al._ [74] designed one of the first automated
tool to automatically protect cryptographic code at software
level. Their approach is experimental: they determine sensitive
operations in a program by running it while recording power
traces. The operations that are found to leak information are then
protected using _random precharging_ [73], which consists in adding
random instructions before and after leaking instructions in order to
increase the noise.

Agosta _et al._ [78] developed a tool to automatically protect ciphers
against DPA using _code morphing_, which consists in dynamically (at
runtime) and randomly generating the code to be executed. To do so,
the cipher is broken into fragments of a few instructions. For each
fragment, several alternative (but semantically equivalent) sequences
of instructions are generated at compile time. At runtime, a
_polymorphic engine_ selects one sequence from each of the
fragments. The resulting code can leak secret data, but an attacker
would not know where in the original cipher the leak is, since the
code executing is dynamically randomized.

Moss _et al._ [76] proposed the first compiler to automate first-order
Boolean masking. Based on CAO's type system [77], the developers
annotates the inputs of the program with `secret` or `public`, and the
compiler infers for each computation whether the result is `secret`
(one of its operand is `secret`) or `public` (all operands are
`public`). The compiler then searches for operations on `secret`
values that break the masking (for instance a `xor` where the masks of
the operands would cancel out), and fixes them by changing the masks
of its operands.

Agosta _et al._ [89] designed a dataflow analysis to a automatically
mask ciphers at higher orders. Their analysis tracks the secret
dependencies (plaintext or key) of each intermediate variable, and is
thus able to detect intermediate results that would leak secret
information and require to be masked. They implemented their algorithm
in LLVM [80], allowing them to mask ciphers written in C (although
they require some annotations in the C code to spot the plaintext and
key).

Sleuth [79] is a tool to automatically verify whether an implementation
leaks information that is statistically dependent on any secret input,
and would thus be vulnerable to SCA. Sleuth reduces this verification
to a Boolean satisfiability problem, and uses a SAT solver (in
practice, KLEE [81]) to solve it. In practice, Sleuth is implemented
as a pass in LLVM's backend, and is thus also able to ensure that
the compiler (LLVM) does not break masking by reordering instructions.

Eldib _et al._ [82] developed a tool similar to Sleuth called SC
Sniffer. However, whereas Sleuth verifies that all leakage is
statistically independent on any input, SC Sniffer ensures that a
cipher is _perfectly masked_, which is a stronger property: a masked
algorithm is perfectly masked at order _d_ if the distribution of any
_d_ intermediate results is statistically independent of any secret
input [27]. SC Sniffer is also implemented as an LLVM pass and relies
on the Yices SMT solver [84] to conduct its analysis. Eldib and Wang
[83] then built MC Masker, to perform synthesis of masking
countermeasures (SC Sniffer only performs analysis). MC Masker
generates the masked program using _inductive synthesis_: it
iteratively adds countermeasures until the SMT solver is able to prove
that the program is perfectly masked.

G. Barthe _et al._ [85] propose to verify masking using program
equivalence. More specifically, their tool (later dubbed _maskverif_),
inspired by [86], tries to construct a bijection between the
distribution intermediate values of the masked program of interest and
a distribution that is independent from the secret inputs. Maskverif
scales better than previous work (_eg._ MC Masker) at higher masking
order than, even though it does not seem to be able to handle a full
second-order masked AES. Furthermore, Maskverif works is not limited
to analyze 1-bit variables, unlike Sleuth and SCSniffer.

G. Barthe _et al._ [87] later introduced the notion of _strong
non-interference_. Intuitively, a strongly _t_-non-interfering code is
_t_-probing secure (or _t-non-interfering_) _and_ composable with any
other strongly _t_-non-interfering code. This is a stronger property
than _t_-probing security, since combining _t_-probing secure gadgets
does not always produce a _t_-probing secure implementation [64]. They
developed a tool (later dubbed _maskComp_) to generate masked C
implementations from unmasked ones. Unlike previous work which could
only verify the security of an implementation at a given order,
maskComp is able to prove the security of an implementation at any
order.

Coron [88] designed a tool called _CheckMasks_ to automatically verify
the security of higher-order masked implementations, similarly to
_maskverif_ [85]. For large implementations, CheckMasks can only
verify the security at small orders. However, CheckMasks is also able
to verify the _t_-SNI (or _t_-NI) property of gadgets at any order.

Belaïd _et al._ [72] developed a tool named _tightPROVE_, which is
able to verify the _t_-probing security of a masked implementation at
any order _t_. TightPROVE improves on maskComp by proposing a method
which is tight in the sense that it is able to minimize the number of
refreshes needed to make an implementation _t_-probing secure.



## Tornado


tightPROVE [72] verifies the _t_-probing security of programs in the
_bit probing model_, meaning that each probe only retrieves a single
bit of data. It is thus limited to verify the security of programs
manipulating 1-bit variables. Raphaël Wintersdorff, Sonia Belaïd, and
Matthieu Rivain thus improved on their previous work by proposing
tightPROVE<sup>+</sup>, an extension of tightPROVE to the _register
probing model_ where variables represents _l_-bit registers, all of
which leak together. Futhermore, tightPROVE<sup>+</sup> automatically
insert refreshes when needed, whereas tightPROVE was only able to
detect that _some_ refreshes were missing. We worked with them to
integrate tightPROVE<sup>+</sup> in Usuba [90] (the resulting tool is
called _Tornado_) to generate provably _t_-probing secure masked
implementations in either the bit-probing or the register-probing
model.


Given a high-level description of a cryptographic primitive, Tornado
synthesizes a masked implementation using ISW-based multiplication and
refresh gadgets [1], and sharewise addition gadgets. The key role of
Usuba is to automate the generation of a sliced implementation, upon
which tightPROVE+ is then able to verify either the bit probing or
register probing security, or identify the necessary refreshes. By
integrating both tools, we derive a probing-secure masked
implementation from a high-level description of a cipher.

The overall architecture of Tornado is shown below:

<p align="center" style="margin-top:30px;margin-bottom:30px">
<img src="{{ site.baseurl }}/assets/images/blog/tornado-pipeline-final-small.png">
</p>

After normalization and optimization, the Usuba0 program is sent to
tightPROVE<sup>+</sup>, which adds refreshes if necessary. The output
of tightPROVE<sup>+</sup> is translated back to Usuba0, which Usubac
then masks: variables are replaced with arrays of shares, linear
operators and non-linear operators involving constants are applied
share-wise, and other non-linear operators and refreshes are left as
is to be replaced by masked gadgets during C code generation. Before
generating C code, a pass of _loop fusion_ merges share-wise
applications of linear operators when possible.


### Encoding and Decoding Usuba0 for tightPROVE<sup>+</sup>

Tornado targets low-end embedded devices with drastic memory
constraints. It is therefore essential to produce a C code that uses
loops and functions, in order to reduce code size, especially when
masking at high orders. This is one of the main motivation to keep
loops and nodes in the Usuba pipeline despite their semantics being
defined through macro-expansion to simpler constructions.

However, the input language of tightPROVE+ consists of unrolled
inlined register-based circuits. Usubac thus fully unrolls and inlines
the Usuba0 code before generating tightPROVE<sup>+</sup>'s input, but
the refreshes inserted by tightPROVE<sup>+</sup> are propagated back
into the Usuba0 program with loops, nodes and node calls.

To do so, when inlining and unrolling, we keep track of the origin of
each instruction: which node they come from, and which instruction in
that node. For each refresh inserted by TightPROVE<sup>+</sup>, we
therefore know where (_i.e._ which node and loop if any) the refreshed
variable comes from, and are therefore able to insert the refresh
directly in the right node.

In order to insert the refreshes as early as possible, a first pass
sends each node to tightPROVE<sup>+</sup> for verification. Only then
are all nodes inlined and the whole program sent to
tightPROVE<sup>+</sup>. This is useful for instance on Ace, which
contains the following node:

```lustre
node f(x:u32) returns (y:u32)
let
    y = ((x <<< 5) & x) ^ (x <<< 1)
tel
```

This node is obviously vulnerable to probing attacks, and
tightPROVE<sup>+</sup> is able to insert a refresh on one of the `x`
to make it probing-secure. Once the secure version of `f` is inlined
in Ace, no other refreshes are needed.

Since tightPROVE<sup>+</sup>'s verification often takes hours or even
days to verify a whole cipher [3], Usubac uses a cache to avoid
calling tightPROVE<sup>+</sup> multiple times on the same
circuit. This is useful especially when debugging a cipher written in
Usuba, or when compiling several ciphers that share some nodes.

<!--

```python
def refresh_prog(ua_source):
   ua_expanded  = inline_and_unroll(ua_source)
   tp_source    = usuba_to_tightprove(ua_expanded)
   tp_refreshed = call_tightprove(tp_source)
   ua_refreshed = tightprove_to_usuba(tp_refreshed, ua_expanded)
   return propagate_refreshes(ua_refreshed, ua_source)
```
-->


### Masking

To mask an Usuba0 program, Usubac replaces each variable with an array
of shares, and each operator with a masked gadget. The gadget to mask
a linear operator (`xor`) is simply a loop applying the operator on
each share, written directly in Usuba. To mask a negation, we only
negate the first share (since `~(r0 ^ r1 ^ ... ^ rk) == ~r0 ^ r1 ^
... ^ rk`), still in Usuba. To mask non-linear operators (`and` and
`or`), however, we introduce the operators `m&` and `m|` into Usuba,
which are transformed into calls to masked C gadgets when generating
the C code. In particular, for the multiplication (`and`), we use the
so-called ISW gadget gadget introduced in [1]:


```c
static void isw_mult(uint32_t *res,
                     const uint32_t *op1,
                     const uint32_t *op2) {
    for (int i = 0; i <= MASKING_ORDER; i++)
        res[i] = 0;
     
    for (int i = 0; i <= MASKING_ORDER; i++) {
        res[i] ^= op1[i] & op2[i];
        
        for (int j = i+1; j <= MASKING_ORDER; j++) {
            uint32_t rnd = get_random();
            res[i] ^= rnd;
            res[j] ^= (rnd ^ (op1[i] & op2[j])) ^ (op1[j] & op2[i]);
        }
    }
}
```

while the `or`s are transformed into `not` and `and`, since `a | b ==
~(~a & ~b)`. Similarly, refreshes, either inserted manually by the
developper or automatically by tightPROVE<sup>+</sup>, are compiled
into calls to the ISW refresh routine when generating C code:


```c
static void isw_refresh(uint32_t *res,
                        const uint32_t *in) {
    for (int i=0; i<=MASKING_ORDER; i++)
        res[i] = in[i];

    for (int i=0; i<=MASKING_ORDER; i++) {
        for (int j=i+1; j<=MASKING_ORDER; j++) {
            uint32_t rnd = get_random();
            res[i] ^= rnd;
            res[j] ^= rnd;
        }
    }
}
```


#### Constants

Constants are not secret values and thus do not need to be
shared. Furthermore, when multiplying a constant with a secret value,
there is no need to use the ISW mutliplication gadgets: we can simply
multiply each share of the secret value with the constant. The cost of
masking a multiplication by a constant is thus linear in the number of
shares, rather than quadratic as the ISW gadget is. Our benchmarks
(see section "Evaluation" below) show that indeed, the more masked
multiplication a cipher has, the slower it is. Avoiding unnecessary
masked multiplications is thus essential.

For instance, Pyjamask's linear layer contains a matrix
multiplication, implemented by calling 4 times the following Usuba
node, which multiplies two 32-bit vectors `a` and `b`:

<div class="language-lustre highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">node</span> <span class="nf">col_mult</span> <span class="p">(</span><span class="n">a</span><span class="o">:</span><span class="n">b32</span><span class="o">,</span><span class="n">b</span><span class="o">:</span><span class="n">b32</span><span class="p">)</span> <span class="k">returns</span> <span class="p">(</span><span class="n">r</span><span class="o">:</span><span class="n">b1</span><span class="p">)</span>
<span class="k">vars</span> <span class="n">acc</span><span class="o">:</span><span class="n">b32</span>
<span class="k">let</span>
    <span class="n">acc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&amp;</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
    <span class="k">forall</span> <span class="n">i</span> <span class="k">in</span> <span class="p">[</span><span class="mi">1</span><span class="o">,</span><span class="mi">31</span><span class="p">]</span> <span class="p">{</span>
        <span class="n">acc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">acc</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">^</span> <span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&amp;</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="p">}</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">acc</span><span class="p">[</span><span class="mi">31</span><span class="p">]</span>
<span class="k">tel</span>
</code></pre></div></div>

When this node is called in Pyjamask, `b` is always constant, and the
multiplication (`a[i] & b[i]`) therefore does not need to be
masked. Usubac uses a simple inference algorithm to track which
variables are constant and which are not, and is thus able to identify
that `b` does not need to be shared, and that the multiplication `a[i]
& b[i]` does not need to be masked.  This optimization both reduces
stack usage (since constant variables are kept as a single share
rather than an array of share) and increases performances (since
multiplying by a constant becomes linear rather than quadratic).


### Loop Fusion

Since each linear operation is replaced with a loop applying the
operation on each share, the masked code contains a lot of loops. The
overhead of those loops becomes quickly detrimental to
performances. Consider for instance the following Usuba0 snippet:

```lustre
x = a ^ b;
y = c ^ d;
z = x ^ y;
```

After masking, it becomes:


<div class="language-lustre highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">forall</span> <span class="n">i</span> <span class="k">in</span> <span class="p">[</span><span class="mi">0</span><span class="o">,</span> <span class="n">MASKING_ORDER</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">{</span>
    <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">^</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>
<span class="k">forall</span> <span class="n">i</span> <span class="k">in</span> <span class="p">[</span><span class="mi">0</span><span class="o">,</span> <span class="n">MASKING_ORDER</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">{</span>
    <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">^</span> <span class="n">d</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>
<span class="k">forall</span> <span class="n">i</span> <span class="k">in</span> <span class="p">[</span><span class="mi">0</span><span class="o">,</span> <span class="n">MASKING_ORDER</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">{</span>
    <span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">^</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>
</code></pre></div></div>


In order to reduce the overhead of looping over each share for linear
operations, we aggressively perform loop fusion (also called _loop
jamming_) in Usubac, which consists in replacing multiple loops with a
single one. The above snippet is thus optimized to:


<div class="language-lustre highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">forall</span> <span class="n">i</span> <span class="k">in</span> <span class="p">[</span><span class="mi">0</span><span class="o">,</span> <span class="n">MASKING_ORDER</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">{</span>
    <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">^</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">^</span> <span class="n">d</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">^</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>
</code></pre></div></div>


Loop fusion is also able to reduce the amount of stack used by
allowing Usubac to replace temporary arrays with temporary
variables. In the example above, Usubac would thus convert `x` and `y`
into scalars rather than arrays and produce the following code:


<div class="language-lustre highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">forall</span> <span class="n">i</span> <span class="k">in</span> <span class="p">[</span><span class="mi">0</span><span class="o">,</span> <span class="n">MASKING_ORDER</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">{</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">^</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">^</span> <span class="n">d</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span> <span class="o">^</span> <span class="n">y</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>


On embedded devices (which Tornado targets), this is especially
beneficial since the amount of stack available is very limited (_e.g._
a few dozen of kilobytes).

C compilers also perform loop fusion, but experimentally, they are
less aggressive than Usubac. We thus obtain better performances by
fusing loops directly in Usubac. On the 11 ciphers of the NIST
competition we implemented in Usuba and compiled with Tornado,
performing loop fusion in Usubac allows us to reduce stack usage of
our bitsliced implementations by 11kB on average whereas this saves
us, on average, 3kB of stack for our _n_-sliced implementations
(note that our platform offers a measly 96kB of SRAM). It also
positively impacts performance, with a 16% average speedup for
bitslicing and a 21% average speedup for n-slicing.


## Evaluation

We used Tornado to compare 11 cryptographic primitives from the second
round of the NIST lightweight cryptography competition. The choice of
cryptographic primitives was made on the basis that they were
self-identified as being amenable to masking. We stress that we do not
focus on the full authenticated encryption, message authentication, or
hash protocols but on the underlying primitives, mostly block ciphers
and permutations. The complete list of primitives follows:


<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-9wq8{border-color:inherit;text-align:center;vertical-align:middle}
.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
.tg .tg-uzvj{border-color:inherit;font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-xwyw{border-color:#000000;text-align:center;vertical-align:middle}
.tg .tg-wruy{border-color:#000000;color:#32cb00;text-align:center;vertical-align:middle}
.tg .tg-73t7{border-color:#000000;color:#cb0000;text-align:center;vertical-align:middle}
.tg .tg-y0n7{background-color:#efefef;text-align:center;vertical-align:middle}
</style>
<center>
<table class="tg" style="margin-bottom:25px">
<thead>
  <tr>
    <th class="tg-uzvj">submissions</th>
    <th class="tg-uzvj">primitive</th>
    <th class="tg-uzvj">n-sliceable</th>
    <th class="tg-uzvj">slice size</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-y0n7" colspan="4">block ciphers</td>
  </tr>
  <tr>
    <td class="tg-9wq8">Gift-Cofb [7],<br>Hyena [17],<br>Sundae-Gift [18]</td>
    <td class="tg-9wq8">Gift-128</td>
    <td class="tg-wruy">✔</td>
    <td class="tg-xwyw">32</td>
  </tr>
  <tr>
    <td class="tg-c3ow">Pyjamask [10]</td>
    <td class="tg-9wq8">Pyjamask-128</td>
    <td class="tg-wruy">✔</td>
    <td class="tg-xwyw">32</td>
  </tr>
  <tr>
    <td class="tg-9wq8">Skinny [11],<br>Romulus [19]</td>
    <td class="tg-9wq8">Skinny-128-256</td>
    <td class="tg-73t7">✖</td>
    <td class="tg-xwyw">-</td>
  </tr>
  <tr>
    <td class="tg-9wq8">Spook [6]</td>
    <td class="tg-9wq8">Clyde-128</td>
    <td class="tg-wruy">✔</td>
    <td class="tg-xwyw">32</td>
  </tr>
  <tr>
    <td class="tg-y0n7" colspan="4">permutations</td>
  </tr>
  <tr>
    <td class="tg-9wq8">Ace [4]</td>
    <td class="tg-9wq8">Ace</td>
    <td class="tg-wruy">✔</td>
    <td class="tg-xwyw">32</td>
  </tr>
  <tr>
    <td class="tg-9wq8">Ascon [5]</td>
    <td class="tg-9wq8"><i>p<sup>12</sup></i></td>
    <td class="tg-wruy">✔</td>
    <td class="tg-xwyw">64</td>
  </tr>
  <tr>
    <td class="tg-9wq8">Elephant [13,12]</td>
    <td class="tg-9wq8">Spongent-π[160]</td>
    <td class="tg-73t7">✖</td>
    <td class="tg-xwyw">-</td>
  </tr>
  <tr>
    <td class="tg-9wq8">Gimli [8]</td>
    <td class="tg-9wq8">Gimli-36</td>
    <td class="tg-wruy">✔</td>
    <td class="tg-xwyw">32</td>
  </tr>
  <tr>
    <td class="tg-9wq8">Orange [20],<br>Photon-Beetle [9]</td>
    <td class="tg-9wq8">Photon-256</td>
    <td class="tg-73t7">✖</td>
    <td class="tg-xwyw">-</td>
  </tr>
  <tr>
    <td class="tg-9wq8">Xoodyak [15,16]</td>
    <td class="tg-9wq8">Xoodoo</td>
    <td class="tg-wruy">✔</td>
    <td class="tg-xwyw">32</td>
  </tr>
  <tr>
    <td class="tg-y0n7" colspan="4">others</td>
  </tr>
  <tr>
    <td class="tg-c3ow">Subterranean [14]</td>
    <td class="tg-9wq8">blank(8)</td>
    <td class="tg-73t7">✖</td>
    <td class="tg-xwyw">-</td>
  </tr>
</tbody>
</table>
</center>


Whenever possible, we generate both a bitsliced and an _n_-sliced
implementation for each primitive, which allows us to exercise the
bit-probing and the register-probing models of tightPROVE+. However, 4
primitives do not admit a straightforward n-sliced implementation. The
Subterranean permutation involves a significant amount of
bit-twiddling across its 257-bit state, which makes it a resolutely
bitsliced primitive (as confirmed by its reference
implementation). Photon, Skinny, Spongent rely on lookup tables that
would be too expansive to emulate in n-sliced mode. In bitslicing,
these tables are simply implemented by their Boolean circuit, either
provided by the authors (Photon, Skinny) or generated through SAT [2]
with the objective of minimizing multiplicative complexity (Spongent,
with 4 ANDs and 28 XORs).


Note that the _n_-sliced implementations, when they exist, are either
32-sliced or 64-sliced.  This means in particular that, unlike
bitslicing that processes multiple blocks in parallel, these
implementations process a single block at once on our 32-bit Cortex
M4. Note also that in practice, all _n_-sliced implementation are
vsliced, since the Cortex M4 we consider does not provide SIMD
extensions, which are required for hslicing.


Running tightPROVE<sup>+</sup> on our Usuba implementations showed
that all of them were _t_-probing secure in the bit-probing model, but
3 were not secure in the register-probing model. ACE required 384
additional refreshes, Clyde-128 required 6 refreshes, and Gimli
required 120. In the case of ACE and Clyde, the number of refreshes
inserted by tightPROVE<sup>+</sup> is known minimal, while for Gimli,
it is only an upper bound [3].


### Baseline Performance Evaluation

In the following, we benchmark our implementations –in Usuba and
compiled with Tornado– of the NIST submissions against the reference
implementation provided by the contestants. This allows us to
establish a performance baseline (without masking), thus providing a
common frame of reference for the performance of these primitives
based on their implementation synthesized from Usuba. In doing so, we
have to bear in mind that the reference implementations provided by
the NIST contestants are of varying quality: some appear to have been
finely tuned for performance while others focus on simplicity, acting
as an executable specification.

In an effort to level the playing field, we ran our benchmark on an
Intel i5-6500 @ 3.20GHz, running Linux 4.15.0-54. The implementations
were compiled with Clang 7.0.0 with flags `-O3 -fno-slp-vectorize
-fno-vectorize`. These flags prevent Clang from trying to produce
vectorized code, which would artificially advantage some
implementations at the expense of others because of brittle,
hard-to-predict vectorization heuristics. Besides, vectorized
instructions remain an exception in the setting of embedded devices
(_e.g._, Cortex M). At the exception of Subterranean (which is
bitsliced), the reference implementations follow a n-sliced
implementation pattern, representing the state of the primitive
through a matrix of 32-bit values, or 64-bit in the case of Ascon. To
evaluate bitsliced implementations, we simulate a 32-bit architecture,
meaning that the throughput we report corresponds to the parallel
encryption of 32 independent blocks. The cost of transposing data into
a bitslice format (around 9 cycles/bytes to transpose a 32x32 matrix)
is excluded. The results are shown in the following table:

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-wa1i{font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-0lax{text-align:left;vertical-align:top}
</style>
<center>
<table class="tg" style="margin-bottom:25px;margin-top:25px">
<thead>
  <tr>
    <th class="tg-wa1i" rowspan="2">Primitive</th>
    <th class="tg-wa1i" colspan="3">Performances (cycles/bytes)<br><span style="font-style:italic">(lower is better)</span></th>
  </tr>
  <tr>
    <td class="tg-wa1i">Usuba n-slice</td>
    <td class="tg-wa1i">Usuba bitslice</td>
    <td class="tg-wa1i">reference</td>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-0lax">Ace</td>
    <td class="tg-0lax">34.25</td>
    <td class="tg-0lax">55.89</td>
    <td class="tg-0lax">273.53</td>
  </tr>
  <tr>
    <td class="tg-0lax">Ascon</td>
    <td class="tg-0lax">9.84</td>
    <td class="tg-0lax">4.94</td>
    <td class="tg-0lax">5.18</td>
  </tr>
  <tr>
    <td class="tg-0lax">Clyde</td>
    <td class="tg-0lax">33.72</td>
    <td class="tg-0lax">21.99</td>
    <td class="tg-0lax">37.69</td>
  </tr>
  <tr>
    <td class="tg-0lax">Gimli</td>
    <td class="tg-0lax">15.77</td>
    <td class="tg-0lax">5.80</td>
    <td class="tg-0lax">44.35</td>
  </tr>
  <tr>
    <td class="tg-0lax">Gift</td>
    <td class="tg-0lax">565.30</td>
    <td class="tg-0lax">45.51</td>
    <td class="tg-0lax">517.27</td>
  </tr>
  <tr>
    <td class="tg-0lax">Photon</td>
    <td class="tg-0lax">-</td>
    <td class="tg-0lax">44.88</td>
    <td class="tg-0lax">214.47</td>
  </tr>
  <tr>
    <td class="tg-0lax">Pyjamask</td>
    <td class="tg-0lax">246.72</td>
    <td class="tg-0lax">131.33</td>
    <td class="tg-0lax">267.35</td>
  </tr>
  <tr>
    <td class="tg-0lax">Skinny</td>
    <td class="tg-0lax">-</td>
    <td class="tg-0lax">46.87</td>
    <td class="tg-0lax">207.82</td>
  </tr>
  <tr>
    <td class="tg-0lax">Spongent</td>
    <td class="tg-0lax">-</td>
    <td class="tg-0lax">146.93</td>
    <td class="tg-0lax">4824.97</td>
  </tr>
  <tr>
    <td class="tg-0lax">Subterranean</td>
    <td class="tg-0lax">-</td>
    <td class="tg-0lax">17.64</td>
    <td class="tg-0lax">355.38</td>
  </tr>
  <tr>
    <td class="tg-0lax">Xoodoo</td>
    <td class="tg-0lax">14.93</td>
    <td class="tg-0lax">6.47</td>
    <td class="tg-0lax">10.14</td>
  </tr>
</tbody>
</table>
</center>

We notice that Usuba often delivers performance that is on par or
better than the reference implementations. Note that this does not
come at the expense of intelligibility: our Usuba implementations are
written in a high-level language, which is amenable to formal
reasoning thanks to its straightforward semantic model (unlike any
implementation in C). The reference implementations of Skinny and
Photon use lookup tables, which do not admit a straightforward
implementation in terms of constant-time, combinational operations. As
a result, we are unable to implement a constant-time n-sliced version
in Usuba and to mask such an implementation.

We now turn our attention specifically to a few implementations that
exhibit interesting performance with the following observations:

 - The reference implementation of Subterranean is an order of
   magnitude slower than in Usuba because its implementation is
   bit-oriented (each bit is stored in a distinct 8-bit variable) but
   only a single block is encrypted at a time. Switching to 32-bit
   variables and encrypting 32 blocks in parallel, as Usuba does,
   significantly improves performance.
   
 - The reference implementation of Spongent is slowed down by a
   prohibitively expensive bitpermutation over 160 bits, which is
   spread across 20 8-bit variables. Thanks to bitslicing, Usuba turns
   this permutation into a purely static renaming of variable, which
   occurs purely at compile-time.
   
 - On Ascon, our n-sliced implementation is twice slower than the
   reference implementation. Unlike the reference implementation, we
   have refrained from performing aggressive function inlining and
   loop unrolling to keep code size in check, since we target embedded
   systems.  However, if we instruct the Usuba compiler to perform
   these optimizations, the performance of our n-sliced implementation
   is on par with the reference one.
   
 - Ace reference implementation suffers from significant performance
   issues, relying on an excessive number of temporary variables to
   store intermediate results.
   
 - Gimli offers two reference implementations, one being a
   high-performance SSE implementation with the other serving as an
   executable specification on general-purpose registers.  We chose
   the general-purpose one here (which had not been subjected to the
   same level of optimizations) because our target architecture
   (Cortex M) does not provide a vectorized instruction set.
   
 - Finally, Gift's n-slice implementation suffers from sever
   performance issues because of its expensive linear layer. Using a
   the recent _fixslicing_ technique [21] improves the performance of
   Usuba's _n_-slice Gift implementation down to 42 cycles/byte.


### Masking benchmarks

We ran our benchmarks on a Nucleo STM32F401RE offering an Arm
Cortex-M4 with 512 Kbytes of Flash memory and 96 Kbytes of SRAM. We
used the GNU C compiler arm-none-eabi-gcc version 9.2.0 at
optimization level -O3.  We considered two modes regarding the Random
Number Generator (RNG):


 - Pooling mode: The RNG generates random numbers at a rate of 32 bits
   every 64 clock cycles.  Fetching a random number can thus take up
   to 65 clock cycles.

 - Fast mode: The RNG only takes a few clock cycles to generate a
   32-bit random word. The RNG routine thus can simply read a register
   containing this 32-bit random word without checking for its
   availability.


Those two modes were chosen because they are the ones used in the
submission of Pyjamask, which is the only submission detailing the
question of how to get random numbers for a masked implementation.


#### Scaling




<!--
Since masking a multiplication has a quadratic cost in the number of
shares, we expect performance at high orders to be mostly proportional
with the number of multiplications used by the primitives. We thus
report the number of multiplications involved in our implementation
(bitsliced and nsliced) in the following table:


<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-wa1i{font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-uzvj{border-color:inherit;font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
.tg .tg-0lax{text-align:left;vertical-align:top}
</style>
<center>
<table class="tg">
<thead>
  <tr>
    <th class="tg-uzvj" rowspan="2">primitive</th>
    <th class="tg-wa1i" rowspan="2">state size<br>(bits)</th>
    <th class="tg-uzvj" colspan="2">multiplications</th>
    <th class="tg-uzvj" colspan="2">multiplications/bits</th>
  </tr>
  <tr>
    <td class="tg-wa1i">n-slice</td>
    <td class="tg-wa1i">bitslice</td>
    <td class="tg-wa1i">n-slice</td>
    <td class="tg-wa1i">bitslice</td>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-0pky">ACE</td>
    <td class="tg-0lax">320<br></td>
    <td class="tg-0pky">384</td>
    <td class="tg-0lax">12288</td>
    <td class="tg-0pky">1.2</td>
    <td class="tg-0lax">38</td>
  </tr>
  <tr>
    <td class="tg-0pky">ASCON</td>
    <td class="tg-0lax">320</td>
    <td class="tg-0pky">60</td>
    <td class="tg-0lax">3840</td>
    <td class="tg-0pky">0.19</td>
    <td class="tg-0lax">12</td>
  </tr>
  <tr>
    <td class="tg-0pky">Clyde</td>
    <td class="tg-0lax">128</td>
    <td class="tg-0pky">48</td>
    <td class="tg-0lax">1536</td>
    <td class="tg-0pky">0.37</td>
    <td class="tg-0lax">12</td>
  </tr>
  <tr>
    <td class="tg-0pky">GIFT</td>
    <td class="tg-0lax">128</td>
    <td class="tg-0pky">160</td>
    <td class="tg-0lax">5120</td>
    <td class="tg-0pky">1.25</td>
    <td class="tg-0lax">40</td>
  </tr>
  <tr>
    <td class="tg-0pky">Gimli</td>
    <td class="tg-0lax">384</td>
    <td class="tg-0pky">288</td>
    <td class="tg-0lax">9216</td>
    <td class="tg-0pky">0.75</td>
    <td class="tg-0lax">24</td>
  </tr>
  <tr>
    <td class="tg-0pky">PHOTON</td>
    <td class="tg-0lax">256</td>
    <td class="tg-0pky">-</td>
    <td class="tg-0lax">3072</td>
    <td class="tg-0pky">-</td>
    <td class="tg-0lax">12</td>
  </tr>
  <tr>
    <td class="tg-0pky">Pyjamask</td>
    <td class="tg-0lax">128</td>
    <td class="tg-0pky">56</td>
    <td class="tg-0lax">1792</td>
    <td class="tg-0pky">0.44</td>
    <td class="tg-0lax">14</td>
  </tr>
  <tr>
    <td class="tg-0pky">SKINNY</td>
    <td class="tg-0lax">128</td>
    <td class="tg-0pky">-</td>
    <td class="tg-0lax">6144</td>
    <td class="tg-0pky">-</td>
    <td class="tg-0lax">48</td>
  </tr>
  <tr>
    <td class="tg-0pky">SPONGENT</td>
    <td class="tg-0lax">160</td>
    <td class="tg-0pky">-</td>
    <td class="tg-0lax">12800</td>
    <td class="tg-0pky">-</td>
    <td class="tg-0lax">80</td>
  </tr>
  <tr>
    <td class="tg-0pky">Subterranean</td>
    <td class="tg-0lax">257</td>
    <td class="tg-0pky">-</td>
    <td class="tg-0lax">2056</td>
    <td class="tg-0pky">-</td>
    <td class="tg-0lax">8</td>
  </tr>
  <tr>
    <td class="tg-0pky">Xoodoo</td>
    <td class="tg-0lax">384</td>
    <td class="tg-0pky">144</td>
    <td class="tg-0lax">4608</td>
    <td class="tg-0pky">0.37</td>
    <td class="tg-0lax">12</td>
  </tr>
</tbody>
</table>
</center>
-->


#### N-slicing

The table bellow gives the performances of the _n_-sliced
implementations produced by Tornado in terms of cycles per bloc. Note
that this does not reflect the performances in term of cycles/bytes,
since those ciphers have different bloc size. For instance, encrypting
a single bloc with Xoodoo is more than twice slower than with Clyde
(at any given order), but since Xoodoo's bloc is 384 bits, while
Clyde's is only 128 bits, the performances of Xoodoo in terms of
cycles/bytes are _better_ than Clyde's. Nevertheless, we focus here on
the performances per bloc, and analyze the performances per bytes in
the next section, when considering bitsliced implementations.


<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}
.tg .tg-wa1i{font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-nrix{font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-0lax{text-align:left;vertical-align:top}
.tg .tg-0qe0{background-color:#ecf4ff;text-align:left;vertical-align:top}
.tg .tg-2col{background-color:#efefef;text-align:center;vertical-align:middle}
</style>
<center>
<table class="tg" style="margin-bottom:25px;margin-top:25px">
<thead>
  <tr>
    <th class="tg-nrix" rowspan="2">primitive</th>
    <th class="tg-nrix" rowspan="2">mults</th>
    <th class="tg-nrix" rowspan="2">RNG<br>mode</th>
    <th class="tg-nrix" colspan="7">Performances (cycles)<br><span style="font-style:italic">(lower is better)</span></th>
  </tr>
  <tr>
    <th class="tg-nrix"><span style="font-style:italic">d</span> = 0</th>
    <th class="tg-nrix"><span style="font-style:italic">d</span> = 3</th>
    <th class="tg-nrix"><span style="font-style:italic">d</span> = 7</th>
    <th class="tg-nrix"><span style="font-style:italic">d</span> = 15</th>
    <th class="tg-nrix"><span style="font-style:italic">d</span> = 31</th>
    <th class="tg-nrix"><span style="font-style:italic">d</span> = 63</th>
    <th class="tg-nrix"><span style="font-style:italic">d</span> = 127</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-2col" rowspan="2">Clyde</td>
    <td class="tg-2col" rowspan="2">48</td>
    <td class="tg-0qe0">fast</td>
    <td class="tg-0qe0">1.47k</td>
    <td class="tg-0qe0">15.38k</td>
    <td class="tg-0qe0">56.48k</td>
    <td class="tg-0qe0">189.44k</td>
    <td class="tg-0qe0">670.08k</td>
    <td class="tg-0qe0">2.58m</td>
    <td class="tg-0qe0">10.45m</td>
  </tr>
  <tr>
    <td class="tg-0lax">pooling</td>
    <td class="tg-0lax">1.47k</td>
    <td class="tg-0lax">30.08k</td>
    <td class="tg-0lax">121.08k</td>
    <td class="tg-0lax">502.88k</td>
    <td class="tg-0lax">1.94m</td>
    <td class="tg-0lax">7.73m</td>
    <td class="tg-0lax">29.92m</td>
  </tr>
  
  <tr>
    <td class="tg-2col" rowspan="2">Pyjamask</td>
    <td class="tg-2col" rowspan="2">56</td>
    <td class="tg-0qe0">fast</td>
    <td class="tg-0qe0">15.90k</td>
    <td class="tg-0qe0">79.52k</td>
    <td class="tg-0qe0">205.44k</td>
    <td class="tg-0qe0">614.40k</td>
    <td class="tg-0qe0">1.73m</td>
    <td class="tg-0qe0">4.75m</td>
    <td class="tg-0qe0">15.20m</td>
  </tr>
  <tr>
    <td class="tg-0lax">pooling</td>
    <td class="tg-0lax">15.90k</td>
    <td class="tg-0lax">94.88k</td>
    <td class="tg-0lax">274.56k</td>
    <td class="tg-0lax">954.56k</td>
    <td class="tg-0lax">3.10m</td>
    <td class="tg-0lax">10.34m</td>
    <td class="tg-0lax">36.32m</td>
  </tr>

  <tr>
    <td class="tg-2col" rowspan="2">Ascon</td>
    <td class="tg-2col" rowspan="2">60</td>
    <td class="tg-0qe0">fast</td>
    <td class="tg-0qe0">1.96k</td>
    <td class="tg-0qe0">42.00k</td>
    <td class="tg-0qe0">123.20k</td>
    <td class="tg-0qe0">464.40k</td>
    <td class="tg-0qe0">1.70m</td>
    <td class="tg-0qe0">6.52m</td>
    <td class="tg-0qe0">25.60m</td>
  </tr>
  <tr>
    <td class="tg-0lax">pooling</td>
    <td class="tg-0lax">1.96k</td>
    <td class="tg-0lax">53.60k</td>
    <td class="tg-0lax">182.80k</td>
    <td class="tg-0lax">821.60k</td>
    <td class="tg-0lax">3.17m</td>
    <td class="tg-0lax">12.96m</td>
    <td class="tg-0lax">52.00m</td>
  </tr>

  <tr>
    <td class="tg-2col" rowspan="2">Xoodoo</td>
    <td class="tg-2col" rowspan="2">144</td>
    <td class="tg-0qe0">fast</td>
    <td class="tg-0qe0">3.02k</td>
    <td class="tg-0qe0">42.67k</td>
    <td class="tg-0qe0">156.48k</td>
    <td class="tg-0qe0">520.32k</td>
    <td class="tg-0qe0">1.89m</td>
    <td class="tg-0qe0">6.86m</td>
    <td class="tg-0qe0">26.64m</td>
  </tr>
  <tr>
    <td class="tg-0lax">pooling</td>
    <td class="tg-0lax">3.02k</td>
    <td class="tg-0lax">82.08k</td>
    <td class="tg-0lax">334.08k</td>
    <td class="tg-0lax">1.40m</td>
    <td class="tg-0lax">5.42m</td>
    <td class="tg-0lax">21.50m</td>
    <td class="tg-0lax">83.04m</td>
  </tr>
  
  <tr>
    <td class="tg-2col" rowspan="2">Gift</td>
    <td class="tg-2col" rowspan="2">160</td>
    <td class="tg-0qe0">fast</td>
    <td class="tg-0qe0">17.92k</td>
    <td class="tg-0qe0">200.48k</td>
    <td class="tg-0qe0">516.32k</td>
    <td class="tg-0qe0">1.24m</td>
    <td class="tg-0qe0">6.45m</td>
    <td class="tg-0qe0">13.10m</td>
    <td class="tg-0qe0">42.24m</td>
  </tr>
  <tr>
    <td class="tg-0lax">pooling</td>
    <td class="tg-0lax">17.92k</td>
    <td class="tg-0lax">244.32k</td>
    <td class="tg-0lax">714.88k</td>
    <td class="tg-0lax">2.21m</td>
    <td class="tg-0lax">8.51m</td>
    <td class="tg-0lax">29.12m</td>
    <td class="tg-0lax">102.40m</td>
  </tr>
  
  <tr>
    <td class="tg-2col" rowspan="2">Gimli</td>
    <td class="tg-2col" rowspan="2">288</td>
    <td class="tg-0qe0">fast</td>
    <td class="tg-0qe0">2.69k</td>
    <td class="tg-0qe0">84.96k</td>
    <td class="tg-0qe0">342.72k</td>
    <td class="tg-0qe0">1.19m</td>
    <td class="tg-0qe0">4.57m</td>
    <td class="tg-0qe0">17.09m</td>
    <td class="tg-0qe0">67.20m</td>
  </tr>
  <tr>
    <td class="tg-0lax">pooling</td>
    <td class="tg-0lax">2.69k</td>
    <td class="tg-0lax">190.56k</td>
    <td class="tg-0lax">832.80k</td>
    <td class="tg-0lax">3.52m</td>
    <td class="tg-0lax">14.06m</td>
    <td class="tg-0lax">56.16m</td>
    <td class="tg-0lax">218.88m</td>
  </tr>
  
  <tr>
    <td class="tg-2col" rowspan="2">Ace</td>
    <td class="tg-2col" rowspan="2">384</td>
    <td class="tg-0qe0">fast</td>
    <td class="tg-0qe0">3.68k</td>
    <td class="tg-0qe0">155.20k</td>
    <td class="tg-0qe0">531.60k</td>
    <td class="tg-0qe0">1.60m</td>
    <td class="tg-0qe0">7.60m</td>
    <td class="tg-0qe0">29.84m</td>
    <td class="tg-0qe0">113.60m</td>
  </tr>
  <tr>
    <td class="tg-0lax">pooling</td>
    <td class="tg-0lax">3.68k</td>
    <td class="tg-0lax">302.00k</td>
    <td class="tg-0lax">1.32m</td>
    <td class="tg-0lax">4.56m</td>
    <td class="tg-0lax">19.80m</td>
    <td class="tg-0lax">78.40m</td>
    <td class="tg-0lax">310.80m</td>
  </tr>
</tbody>
</table>
</center>


Since masking a multiplication has a quadratic cost in the number of
shares, we expect performance at high orders to be mostly proportional
with the number of multiplications used by the primitives. We thus
report the number of multiplications involved in our implementations
of the primitives. This is confirmed by our results with 128 shares
(on the Cortex M4). This effect is less pronounced at small orders
since the execution time remains dominated by linear operations. Using
the pooling RNG increases the cost of multiplications compared to the
fast RNG, which results in performances being proportional to the
number of multiplications at smaller order than with the fast RNG.

Pyjamask illustrates the influence of the number of multiplications on
scaling. Because of its use of dense binary matrix multiplications, it
involves a significant number of linear operations for only a few
multiplications. As a result, it is slower than Xoodoo order 3,
despite the fact that Xoodoo uses 2.5× more multiplications. With the
fast RNG, the inflection point is reached at order 31 only to improve
afterward. Similarly when compared to Clyde, Pyjamask goes from 5×
slower at order 3 to 50% slower at order 127 with the fast RNG and 20%
slower at order 127 with the pooling RNG. The same analysis applies to
Gift and Gimli, where the linear overhead of Gift is only dominated at
order 7 with the pooling RNG and at order 63 with the fast RNG.

One notable exception is Ascon with the fast RNG, compared in
particular to Clyde and Pyjamask. Despite Ascon using only slightly
more multiplications, it involves a 64-sliced implementation, unlike
its counterparts that are 32-sliced. Running on our 32-bit Cortex-M4
requires GCC to generate 64-bit emulation code, which induces a
significant operational overhead and prevents further optimization by
the compiler. Regardless of the RNG used, Ascon is thus significantly
slower than Clyde (at order 3 at beyond) and Pyjamask (at order 63 and
beyond).


<!-- <p align="center" style="margin-top:30px;margin-bottom:30px;"> -->
<!-- <img style="height:auto;width:auto;max-width:100%" src="{{ site.baseurl }}/assets/images/blog/n-slice-masking-scaling-bloc-pooling.png"> -->
<!-- </p> -->

<!-- <p align="center" style="margin-top:30px;margin-bottom:30px"> -->
<!-- <img style="height:auto;width:auto;max-width:100%" src="{{ site.baseurl }}/assets/images/blog/n-slice-masking-scaling-bloc-fast.png"> -->
<!-- </p> -->

<!-- <p align="center" style="margin-top:30px;margin-bottom:30px;"> -->
<!-- <img style="height:auto;width:auto;max-width:100%" src="{{ site.baseurl }}/assets/images/blog/n-slice-masking-scaling-byte-pooling.png"> -->
<!-- </p> -->

<!-- <p align="center" style="margin-top:30px;margin-bottom:30px"> -->
<!-- <img style="height:auto;width:auto;max-width:100%" src="{{ site.baseurl }}/assets/images/blog/n-slice-masking-scaling-byte-fast.png"> -->
<!-- </p> -->


#### Bitslicing

The key limiting factor to execute bitslice code on an embedded device
is the amount of memory available. Bitsliced programs tend to be large
and to consume a significant amount of stack. Masking such
implementations at high orders becomes quickly impractical because of
the quadratic growth of the stack usage.

To reduce stack usage and allow us to explore high masking orders, our
bitsliced programs manipulate 8-bit variables, meaning that 8
independent blocks can be processed in parallel. This trades memory
usage for performance, as we could have used 32-bit variables and
improved our throughput by a factor 4. However, doing so would have
put an unbearable amount of pressure on the stack, which would have
prevented us from considering masking orders beyond 7. Besides, it is
not clear whether there is a use-case for such a massively parallel
(32 independent blocks) encryption primitive in a lightweight
setting. As a result of our compilation strategy, we have been able to
mask all primitives with up to 16 shares and, additionally, reach 32
shares for Photon, Skinny, Spongent and Subterranean.

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-wa1i{font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-0lax{text-align:left;vertical-align:top}
</style>
<center>
<table class="tg" style="margin-bottom:25px;margin-top:25px">
<thead>
  <tr>
    <th class="tg-wa1i" colspan="7">Bitslice performances (fast RNG)</th>
  </tr>
  <tr>
    <th class="tg-wa1i" rowspan="2">primitive</th>
    <th class="tg-wa1i" rowspan="2">mults/bits</th>
    <th class="tg-wa1i" colspan="5">Performances (cycles/bytes)<br><span style="font-style:italic">(lower is better)</span></th>
  </tr>
  <tr>
    <td class="tg-wa1i"><span style="font-style:italic">d</span> = 0</td>
    <td class="tg-wa1i"><span style="font-style:italic">d</span> = 3</td>
    <td class="tg-wa1i"><span style="font-style:italic">d</span> = 7</td>
    <td class="tg-wa1i"><span style="font-style:italic">d</span> = 16</td>
    <td class="tg-wa1i"><span style="font-style:italic">d </span>= 32</td>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-0lax">Subterranean</td>
    <td class="tg-0lax">8</td>
    <td class="tg-0lax">94</td>
    <td class="tg-0lax">2.15k</td>
    <td class="tg-0lax">7.18k</td>
    <td class="tg-0lax">27.23k</td>
    <td class="tg-0lax">95.19k</td>
  </tr>
  <tr>
    <td class="tg-0lax">Ascon</td>
    <td class="tg-0lax">12</td>
    <td class="tg-0lax">101</td>
    <td class="tg-0lax">3.07k</td>
    <td class="tg-0lax">11.45k</td>
    <td class="tg-0lax">42.39k</td>
    <td class="tg-0lax"></td>
  </tr>
  <tr>
    <td class="tg-0lax">Xoodoo</td>
    <td class="tg-0lax">12</td>
    <td class="tg-0lax">112</td>
    <td class="tg-0lax">3.12k</td>
    <td class="tg-0lax">10.49k</td>
    <td class="tg-0lax">38.35k</td>
    <td class="tg-0lax"></td>
  </tr>
  <tr>
    <td class="tg-0lax">Clyde</td>
    <td class="tg-0lax">12</td>
    <td class="tg-0lax">177</td>
    <td class="tg-0lax">3.44k</td>
    <td class="tg-0lax">13.57k</td>
    <td class="tg-0lax">45.34k</td>
    <td class="tg-0lax"></td>
  </tr>
  <tr>
    <td class="tg-0lax">Photon</td>
    <td class="tg-0lax">12</td>
    <td class="tg-0lax">193</td>
    <td class="tg-0lax">7.66k</td>
    <td class="tg-0lax">14.28k</td>
    <td class="tg-0lax">44.99k</td>
    <td class="tg-0lax">154k</td>
  </tr>
  <tr>
    <td class="tg-0lax">Pyjamask</td>
    <td class="tg-0lax">14</td>
    <td class="tg-0lax">1.59k</td>
    <td class="tg-0lax">16.52k</td>
    <td class="tg-0lax">31.76k</td>
    <td class="tg-0lax">97.88k</td>
    <td class="tg-0lax"></td>
  </tr>
  <tr>
    <td class="tg-0lax">Gimli</td>
    <td class="tg-0lax">24</td>
    <td class="tg-0lax">127</td>
    <td class="tg-0lax">5.51k</td>
    <td class="tg-0lax">19.15k</td>
    <td class="tg-0lax">76.91k</td>
    <td class="tg-0lax"></td>
  </tr>
  <tr>
    <td class="tg-0lax">Ace</td>
    <td class="tg-0lax">38</td>
    <td class="tg-0lax">336</td>
    <td class="tg-0lax">8.22k</td>
    <td class="tg-0lax">35.29k</td>
    <td class="tg-0lax">123k</td>
    <td class="tg-0lax"></td>
  </tr>
  <tr>
    <td class="tg-0lax">Gift</td>
    <td class="tg-0lax">40</td>
    <td class="tg-0lax">358</td>
    <td class="tg-0lax">11.08k</td>
    <td class="tg-0lax">36.79k</td>
    <td class="tg-0lax">136k</td>
    <td class="tg-0lax"></td>
  </tr>
  <tr>
    <td class="tg-0lax">Skinny</td>
    <td class="tg-0lax">48</td>
    <td class="tg-0lax">441</td>
    <td class="tg-0lax">18.19k</td>
    <td class="tg-0lax">61.75k</td>
    <td class="tg-0lax">200k</td>
    <td class="tg-0lax">664k</td>
  </tr>
  <tr>
    <td class="tg-0lax">Spongent</td>
    <td class="tg-0lax">80</td>
    <td class="tg-0lax">624</td>
    <td class="tg-0lax">19.45k</td>
    <td class="tg-0lax">64.78k</td>
    <td class="tg-0lax">259k</td>
    <td class="tg-0lax">948k</td>
  </tr>
</tbody>
</table>
</center>

As for the n-sliced implementations, we observe a close match between
the asymptotic performance of the primitive and their number of
multiplications per bits, which becomes even more prevalent as order
increases and the overhead of linear operations becomes comparatively
smaller. Pyjamask remains a good example to illustrate this
phenomenon, the inflection point being reached at order 15 with
respect to Ace (which uses 3× more multiplications).

The performance of Ascon with the fast RNG, which was slowed down by
its suboptimal use of 64-bit registers in n-slicing, is streamlined in
bitslicing: here, it exhibits the same number of multiplication per
bits as Xoodoo and, indeed, their performance match remarkably well.

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-wa1i{font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-0lax{text-align:left;vertical-align:top}
</style>
<center>
<table class="tg" style="margin-bottom:25px;margin-top:25px">
<thead>
  <tr>
    <th class="tg-wa1i" colspan="7">Bitslice performances (pooling RNG)</th>
  </tr>
  <tr>
    <th class="tg-wa1i" rowspan="2">primitive</th>
    <th class="tg-wa1i" rowspan="2">mults/bits</th>
    <th class="tg-wa1i" colspan="5">Performances (cycles/bytes)<br><span style="font-style:italic">(lower is better)</span></th>
  </tr>
  <tr>
    <td class="tg-wa1i"><span style="font-style:italic">d</span> = 0</td>
    <td class="tg-wa1i"><span style="font-style:italic">d</span> = 3</td>
    <td class="tg-wa1i"><span style="font-style:italic">d</span> = 7</td>
    <td class="tg-wa1i"><span style="font-style:italic">d</span> = 16</td>
    <td class="tg-wa1i"><span style="font-style:italic">d </span>= 32</td>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-0lax">Subterranean</td>
    <td class="tg-0lax">8</td>
    <td class="tg-0lax">94</td>
    <td class="tg-0lax">4.46k</td>
    <td class="tg-0lax">19.13k</td>
    <td class="tg-0lax">79.63k</td>
    <td class="tg-0lax">312k</td>
  </tr>
  <tr>
    <td class="tg-0lax">Ascon</td>
    <td class="tg-0lax">12</td>
    <td class="tg-0lax">101</td>
    <td class="tg-0lax">7.33k</td>
    <td class="tg-0lax">30.33k</td>
    <td class="tg-0lax">125k</td>
    <td class="tg-0lax"></td>
  </tr>
  <tr>
    <td class="tg-0lax">Xoodoo</td>
    <td class="tg-0lax">12</td>
    <td class="tg-0lax">112</td>
    <td class="tg-0lax">6.69k</td>
    <td class="tg-0lax">28.79K</td>
    <td class="tg-0lax">120K</td>
    <td class="tg-0lax"></td>
  </tr>
  <tr>
    <td class="tg-0lax">Clyde</td>
    <td class="tg-0lax">12</td>
    <td class="tg-0lax">177</td>
    <td class="tg-0lax">7.88k</td>
    <td class="tg-0lax">31.04k</td>
    <td class="tg-0lax">127k</td>
    <td class="tg-0lax"></td>
  </tr>
  <tr>
    <td class="tg-0lax">Photon</td>
    <td class="tg-0lax">12</td>
    <td class="tg-0lax">193</td>
    <td class="tg-0lax">10.47k</td>
    <td class="tg-0lax">31.77k</td>
    <td class="tg-0lax">126k</td>
    <td class="tg-0lax">476k</td>
  </tr>
  <tr>
    <td class="tg-0lax">Pyjamask</td>
    <td class="tg-0lax">14</td>
    <td class="tg-0lax">1.59k</td>
    <td class="tg-0lax">20.33k</td>
    <td class="tg-0lax">52.81k</td>
    <td class="tg-0lax">193k</td>
    <td class="tg-0lax"></td>
  </tr>
  <tr>
    <td class="tg-0lax">Gimli</td>
    <td class="tg-0lax">24</td>
    <td class="tg-0lax">127</td>
    <td class="tg-0lax">12.14k</td>
    <td class="tg-0lax">53.64k</td>
    <td class="tg-0lax">236k</td>
    <td class="tg-0lax"></td>
  </tr>
  <tr>
    <td class="tg-0lax">Ace</td>
    <td class="tg-0lax">38</td>
    <td class="tg-0lax">336</td>
    <td class="tg-0lax">19.94k</td>
    <td class="tg-0lax">89.12k</td>
    <td class="tg-0lax">395k</td>
    <td class="tg-0lax"></td>
  </tr>
  <tr>
    <td class="tg-0lax">Gift</td>
    <td class="tg-0lax">40</td>
    <td class="tg-0lax">358</td>
    <td class="tg-0lax">21.38k</td>
    <td class="tg-0lax">93.92k</td>
    <td class="tg-0lax">405k</td>
    <td class="tg-0lax"></td>
  </tr>
  <tr>
    <td class="tg-0lax">Skinny</td>
    <td class="tg-0lax">48</td>
    <td class="tg-0lax">441</td>
    <td class="tg-0lax">34.28k</td>
    <td class="tg-0lax">131k</td>
    <td class="tg-0lax">525k</td>
    <td class="tg-0lax">1.97m</td>
  </tr>
  <tr>
    <td class="tg-0lax">Spongent</td>
    <td class="tg-0lax">80</td>
    <td class="tg-0lax">624</td>
    <td class="tg-0lax">44.04k</td>
    <td class="tg-0lax">188k</td>
    <td class="tg-0lax">816k</td>
    <td class="tg-0lax">3.15m</td>
  </tr>
</tbody>
</table>
</center>

Finally, we observe that with the pooling RNG, already at order 15,
the performances of our implementations is in accord with their
relative number of multiplications per bits. In bitslicing (more
evidently than in n-slicing), the number of multiplications is
performance critical, even at relatively low masking order.



### Usuba vs reference and future work


Of these 11 NIST submissions, only Pyjamask provides a masked
implementation. Our implementation is consistently (at every order,
and with both the pooling and fast RNGs) 1.8 times slower than their
masked implementation. The main reason is that they manually
implemented in assembly the two most used routines.

The first of those two routines is the matrix multiplication. The
Usuba code for this matrix multiplication is:

```lustre

node mat_mult(col:u32,vec:u32) returns (res:u32)
vars
    mask:u32
let
    res  = 0;

    forall i in [0, 31] {
        mask    := bitmask(vec,i);
        res     := res ^ (mask & mat_col);
        mat_col := mat_col[i] >>> 1;
    }
tel
```

When compiled with gcc arm-none-eabi-gcc 4.9.3, the body of the loop
is compiled to 6 instructions. The reference implementation on the
other hand inlines the loop and using ARM's barrel shifter, they are
able to compute each iteration in only 3 instructions. Using the
hand-tuned matrix multiplication Usuba's matrix multiplication offers
a speedup of 15% to 52%, depending on the masking order, as shown in
the Table below:

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}
.tg .tg-baqh{text-align:center;vertical-align:top}
</style>
<center>
<table class="tg" style="margin-bottom:25px;margin-top:25px">
<thead>
  <tr>
    <th class="tg-1wig">masking order</th>
    <th class="tg-baqh">3</th>
    <th class="tg-baqh">7</th>
    <th class="tg-baqh">15</th>
    <th class="tg-baqh">31</th>
    <th class="tg-baqh">63</th>
    <th class="tg-baqh">127</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-1wig">speedup</td>
    <td class="tg-baqh">52%</td>
    <td class="tg-baqh">49%</td>
    <td class="tg-baqh">43%</td>
    <td class="tg-baqh">34%</td>
    <td class="tg-baqh">24%</td>
    <td class="tg-baqh">15%</td>
  </tr>
</tbody>
</table>
</center>

The slowdown is less important at high masking orders because this
matrix multiplication has a linear cost in the masking order, while
the masked multiplication has a quadratic cost in the masking order
(since it must compute all cross products between two shared values).

The second hand-optimized routine is the masked multiplication. The
authors of the reference implementation used the same ISW
multiplication gadget as we used in Usuba (shown in Section
[Masking](#masking-1)), but manually optimized it in assembly. They
unrolled twice the main loop of the multiplication, then fused the two
resulting inner loops, and carefully assigned 6 variables to
registers. If we note _m_ the masking order, this optimization allows
the masked multiplication to require _m_ less jumps (_m/2_ for inner
loops and _m/2_ outer loops), to use _m/2 * 10_ less memory accesses
thanks to their manual assignment of array values to registers, and to
require _m/2*3_ less memory accesses thanks to the merged inner
loops. gcc is unable to automatically perform such optimization.

Unlike the hand-optimized matrix multiplication, whose benefits
diminish as the masking order increases, the optimized masked
multiplication is more beneficial at higher masking order, as can be
seen from the Table below:
 
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}
.tg .tg-baqh{text-align:center;vertical-align:top}
</style>
<center>
<table class="tg" style="margin-bottom:25px;margin-top:25px">
<thead>
  <tr>
    <th class="tg-1wig">masking order</th>
    <th class="tg-baqh">3</th>
    <th class="tg-baqh">7</th>
    <th class="tg-baqh">15</th>
    <th class="tg-baqh">31</th>
    <th class="tg-baqh">63</th>
    <th class="tg-baqh">127</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-1wig">speedup</td>
    <td class="tg-baqh">14%</td>
    <td class="tg-baqh">21%</td>
    <td class="tg-baqh">33%</td>
    <td class="tg-baqh">37%</td>
    <td class="tg-baqh">39%</td>
    <td class="tg-baqh">41%</td>
  </tr>
</tbody>
</table>
</center>


While the Usuba implementations can be sped up by using the hand-tuned
version of the ISW masked multiplication, those two examples (matrix
multiplication and masked multiplication) raise the concern that
high-performance cryptography might not be achieved on embedded
devices using C. Indeed, while the superscalar nature of high-end CPUs
can make up for occational non-optimal codes generated by C compilers,
embedded devices are less forgiving. Similarly, Schwabe and Stoffelen
[22] designed high-performance implementations of AES on Cortex-M3 and
M4 microprocessors, and prefered to write their own register allocator
and instruction scheduler (in less that 250 lines of Python),
suggesting that gcc's register allocator and instruction scheduler may
be far from optimal for cryptography on embedded devices.

We leave for future work to directly target ARM assembly in Usuba, and
implement architecture-specific optimizations for embedded
microprocessors. The end of the pipeline of Usubac incorporating those
modifications should be similar as shown in the figure below:


<p align="center" style="margin-top:30px;margin-bottom:30px;">
<img style="height:auto;width:auto;max-width:100%" src="{{ site.baseurl }}/assets/images/blog/usuba-to-asm-pipeline.png">
</p>

As of now, code-generation is the very last pass of Usubac, and does
not go through its own intermediate representation (IR): the C code is
generated directly from the Usuba AST. Optimizing down to assembly
would require a "lowering" pass that would convert the Usuba AST into
a pseudo-assembly AST (which would represent AST but would use virtual
registers rather than machine registers since register-allocation has
not happened yet). Then, several optimization passes would be
needed. Among the most important, a _peephole optimizer_ to recognize
and optimize commonly used idioms. For instance, a shift followed by
an instruction using that shift could be optimized into a single
instruction using the barrel shifter. Finally, register allocation and
instruction scheduling (performed either separately or together) would
produce an AST representing real machine code, which could then be
printed to produce an assembly file. Each of those passes would be
architecture-specific.


---
## References

[1] Y. Ishai _et al._, [Private Circuits: Securing Hardware against Probing Attacks](https://people.eecs.berkeley.edu/~daw/papers/privcirc-crypto03.pdf), CRYPTO, 2003.

[2] K. Stoffelen, [Efficient cryptography on the RISC-V architecture](https://eprint.iacr.org/2019/794.pdf), LATINCRYPT, 2019.

[3] S. Belaïd _et al._, [Tornado: Automatic Generation of Probing-Secure Masked Bitsliced Implementations](https://eprint.iacr.org/2020/506.pdf), EUROCRYPT, 2020.

[4] M. Aagaard _et al._, [ACE: An Authenticated Encryption and Hash Algorithm](https://csrc.nist.gov/CSRC/media/Projects/Lightweight-Cryptography/documents/round-1/spec-doc/ace-spec.pdf), 2019.

[5] C. Dobraunig _et al._, [ASCON](https://csrc.nist.gov/CSRC/media/Projects/lightweight-cryptography/documents/round-2/spec-doc-rnd2/ascon-spec-round2.pdf), 2019.

[6] D. Bellizia _et al._, [Spook: Sponge-Based Leakage-Resilient Authenticated Encryption with a Masked Tweakable Block Cipher](https://csrc.nist.gov/CSRC/media/Projects/Lightweight-Cryptography/documents/round-1/spec-doc/Spook-spec.pdf), 2019.

[7] S. Banik _et al._, [GIFT-COFB](https://csrc.nist.gov/CSRC/media/Projects/Lightweight-Cryptography/documents/round-1/spec-doc/GIFT-COFB-spec.pdf), 2019.

[8] D. J. Bernstein _et al._, [Gimli : A cross-platform permutation](https://eprint.iacr.org/2017/630.pdf), CHES, 2017.

[9] Z. Bao _et al._, [PHOTON-Beetle Authenticated Encryption and Hash Family](https://csrc.nist.gov/CSRC/media/Projects/Lightweight-Cryptography/documents/round-1/spec-doc/PHOTON-Beetle-spec.pdf), 2019.

[10] D. Goudarzi _et al._, [Pyjamask](https://csrc.nist.gov/CSRC/media/Projects/lightweight-cryptography/documents/round-2/spec-doc-rnd2/pyjamask-spec-round2.pdf), 2019.

[11] C. Beierle _et al._, [SKINNY-AES and SKINNY-Hash](https://csrc.nist.gov/CSRC/media/Projects/Lightweight-Cryptography/documents/round-1/spec-doc/SKINNY-spec.pdf), 2019.

[12] A. Bogdanov _et al._, [SPONGENT: A lightweight hash function](https://eprint.iacr.org/2011/697.pdf), CHES, 2011.

[13] T. Byene _et al._, [Elephant v1](https://csrc.nist.gov/CSRC/media/Projects/Lightweight-Cryptography/documents/round-1/spec-doc/elephant-spec.pdf), 2019.

[14] J. Daemen _et al._, [The Subterranean 2.0 cipher suite](https://cs.ru.nl/~joan/Subterranean/subterranean_ToSC_preprint.pdf), 2019.

[15] J. Daemen _et al._, [Xoodoo cookbook](https://eprint.iacr.org/2018/767.pdf), 2018.

[16] J. Daemen _et al._, [Xoodyak, a lightweight cryptographic scheme](https://pdfs.semanticscholar.org/7be0/c4cd872f3acb816b1737975f17d8ede942b0.pdf), 2019.

[17] A. Chakraborti _et al._, [Security Analysis of HYENA Authenticated Encryption Mode](https://csrc.nist.gov/CSRC/media/Events/lightweight-cryptography-workshop-2019/documents/papers/security-analysis-of-hyena-lwc2019.pdf), 2019.

[18] S. Banik _et al._, [SUNDAE-GIFT](https://csrc.nist.gov/CSRC/media/Projects/Lightweight-Cryptography/documents/round-1/spec-doc/SUNDAE-GIFT-spec.pdf), 2019.

[19] T. Iwata _et al._, [Romulus](https://csrc.nist.gov/CSRC/media/Projects/Lightweight-Cryptography/documents/round-1/spec-doc/Romulus-spec.pdf), 2019.

[20] B. Chakraborty, M. Nandi, [ORANGE](https://csrc.nist.gov/CSRC/media/Projects/Lightweight-Cryptography/documents/round-1/spec-doc/orange-spec.pdf), 2019.

[21] A. Adomnicai _et al._, [Fixslicing: A New GIFT Representation](https://eprint.iacr.org/2020/412.pdf), TCHES, 2020.

[22] P. Schwabe, K. Stoffelen, [All the AES You Need on Cortex-M3 and M4](https://repository.ubn.ru.nl/bitstream/handle/2066/178459/178459.pdf?sequence=1), SAC, 2016.

[23] P. Kocher _et al._, [Differential Power Analysis](https://www.paulkocher.com/DifferentialPowerAnalysis.pdf), CRYPTO, 1999.

[24] G. R. Blakley, [Safeguarding cryptographic keys](https://pdfs.semanticscholar.org/32d2/1ccc21a807627fcb21ea829d1acdab23be12.pdf), 1979.

[25] A. Shamir, [How to Share a Secret](https://cs.jhu.edu/~sdoshi/crypto/papers/shamirturing.pdf), 1979.

[26] M. L. Akkar, C. Giraud, [An Implementation of DES and AES, Secure against Some Attacks](https://link.springer.com/content/pdf/10.1007/3-540-44709-1_26.pdf), CHES, 2001.

[27] J. Blömer _et al._, [Provably Secure Masking of AES](https://link.springer.com/content/pdf/10.1007/978-3-540-30564-4_5.pdf), SAC, 2004.

[28] T. S. Messerges, [Securing the AES finalists against power analysis attacks](https://link.springer.com/content/pdf/10.1007%2F3-540-44706-7_11.pdf), FSE, 2000.

[29] Y. Ishai _et al._, [Private Circuits: Securing Hardware against Probing Attacks](https://people.eecs.berkeley.edu/~daw/papers/privcirc-crypto03.pdf), CRYPTO, 2003.

[32] K. Tiri _et al._, [A dynamic and differential CMOS logic with signal independent power consumption to withstand differential power analysis on smart cards](https://www.esat.kuleuven.be/cosic/publications/article-705.pdf), 2002.

[37] J. D. Golic, C. Tymen, [Multiplicative Masking and Power Analysis of AES](https://link.springer.com/content/pdf/10.1007%2F3-540-36400-5_16.pdf), CHES, 2002.

[38] S. Chari _et al._, [Towards sound approaches to counteract power-analysis attacks](https://link.springer.com/content/pdf/10.1007/3-540-48405-1_26.pdf), CRYPTO, 1999.

[39] L. Goubin, J. Patarin, [DES and Differential Power Analysis, the duplication method](http://www.goubin.fr/papers/dpafinal.pdf), CHES, 1999.

[40] J. Daemen, V. Rijmen, [Resistance Against Implementation Attacks A Comparative Study of the AES Proposals](https://www.esat.kuleuven.be/cosic/publications/article-362.ps), 1999.

[41] T. Popp, S. Mangard, [Masked dual-rail pre-charge logic: DPA-resistance without routing constraints](https://link.springer.com/content/pdf/10.1007/11545262_13.pdf), CHES, 2005.

[42] T. Messerges, [Using second-order power analysis to attack DPA resistant software](https://link.springer.com/content/pdf/10.1007/3-540-44499-8_19.pdf), CHES, 2000.

[45] J.-J. Quisquater, D. Samyde, [ElectroMagnetic Analysis (EMA): Measures and CounterMeasures for Smart Cards](https://link.springer.com/content/pdf/10.1007%2F3-540-45418-7.pdf), Esmart, 2002.

[46] K. Gandolfi _et al._, [Electromagnetic Analysis: Concrete Results](https://link.springer.com/content/pdf/10.1007/3-540-44709-1_21.pdf), CHES, 2001.

[47] J. R. Rao, P. Rohatgi, [EMpowering Side-Channel Attacks](https://eprint.iacr.org/2001/037.pdf), 2001.

[48] E. Biham, A. Shamir, [Power Analysis of the Key Scheduling of the AES Candidates](http://www.cs.technion.ac.il/~biham/Reports/aes-power.ps.gz), 1999.

[49] P. C. Kocher, [Timing Attacks on Implementations of Diffie-Hellman, RSA, DSS, and Other Systems](https://link.springer.com/content/pdf/10.1007/3-540-68697-5_9.pdf), CRYPTO, 1996.

[50] W. Eck, [Electromagnetic Radiation from Video Display Units: An Eavesdropping Risk](https://cryptome.org/emr.pdf), 1985

[51] P. Wright, Spycatcher – The Candid Autobiography of a Senior Intelligence Officer, 1987.

[52] J. Kesley _et al._, [Side Channel Cryptanalysis of Product Ciphers](https://link.springer.com/content/pdf/10.1007/BFb0055858.pdf), ESORICS, 1998.

[53] D. Page, [Theoretical use of cache memory as a cryptanalytic side-channel](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.152.9987&rep=rep1&type=pdf), 2002.

[54] D. J. Bernstein, [Cache-timing attacks on AES](https://cr.yp.to/antiforgery/cachetiming-20050414.pdf), 2005.

[55] J. Waddle, D. Wagner, [Towards Efficient Second-Order Power Analysis](https://link.springer.com/content/pdf/10.1007/978-3-540-28632-5_1.pdf), CHES, 2004.

[56] M. Joye _et al._, [On Second-Order Differential Power Analysis](https://link.springer.com/content/pdf/10.1007/11545262_22.pdf), CHES, 2005.

[63] M. Rivain, E. Prouff, [Provably Secure Higher-Order Masking of AES](https://eprint.iacr.org/2010/441.pdf), CHES, 2010.

[64] J.-S. Coron _et al._, [Higher-Order Side Channel Security and Mask Refreshing](https://eprint.iacr.org/2015/359.pdf), FSE, 2013.

[65] K. Schramm, C. Paar, [Higher Order Masking of the AES](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.496.7125&rep=rep1&type=pdf), CT-RSA, 2006.

[66] M. Rivain _et al._, [Block Ciphers Implementations Provably Secure Against Second Order Side Channel Analysis](https://link.springer.com/content/pdf/10.1007/978-3-540-71039-4_8.pdf), FSE, 2008.

[68] C. Carlet _et al._, [Higher-Order Masking Schemes for S-Boxes](https://link.springer.com/content/pdf/10.1007/978-3-642-34047-5_21.pdf), FSE, 2011.

[72] S. Belaïd _et al._, [Tight Private Circuits: Achieving Probing Security with the Least Refreshing](https://eprint.iacr.org/2018/439.pdf), ASIACRYPT, 2018.

[73] S. Tillich, J. Großschädl, [Power Analysis Resistant AES Implementation with Instruction Set Extensions](https://link.springer.com/content/pdf/10.1007/978-3-540-74735-2_21.pdf), CHES, 2007.

[74] A. G. Bayrak _et al._, [A First Step Towards Automatic Application of Power Analysis Countermeasures](https://dl.acm.org/doi/pdf/10.1145/2024724.2024778), DAC, 2011.

[75] A. G. Bayrak _et al._, [An Architecture-Independent Instruction Shuffler to Protect against Side-Channel Attacks](https://dl.acm.org/doi/pdf/10.1145/2086696.2086699), TACO, 2012.

[76] A. Miss _et al._, [Compiler assisted masking](https://link.springer.com/content/pdf/10.1007/978-3-642-33027-8_4.pdf), CHES, 2012.

[77] M. Barbosa _et al._, A domain-specific type system for cryptographic components, FSEN, 2011.

[78] G. Agosta _et al._, [A Code Morphing Methodology to Automate Power Analysis Countermeasures](https://dl.acm.org/doi/pdf/10.1145/2228360.2228376), DAC, 2012.

[79] A. G. Bayrak _et al._, [Sleuth: Automated verification of software power analysis countermeasures](https://www.iacr.org/archive/ches2013/80860192/80860192.pdf), CHES, 2013.

[80] C. Lattne, V. Adve, [LLVM: A compilation framework for lifelong program analysis & transformation](http://wwwi10.lrr.in.tum.de/~gerndt/home/Teaching/HPCSeminar/llvm_lifelong_program_analysispdf.pdf), CGO, 2004.

[81] C. Cada _et al._, [KLEE: Unassisted and Automatic Generation of High-Coverage Tests for Complex Systems Programs](https://static.usenix.org/events/osdi08/tech/full_papers/cadar/cadar.pdf), OSDI, 2008.

[82] H. Eldib _et al._, [SMT-based verification of software countermeasures against side-channel attacks](https://link.springer.com/content/pdf/10.1007/978-3-642-54862-8_5.pdf), TACAS, 2014.

[83] H. Eldib, C. Wang, [Synthesis of Masking Countermeasures against Side Channel Attacks](https://link.springer.com/content/pdf/10.1007/978-3-319-08867-9_8.pdf), CAV, 2014.

[84] B. Dutertre, L. De Moura, [A fast linear-arithmetic solver for DPLL(T)](https://link.springer.com/content/pdf/10.1007/11817963_11.pdf), CAV, 2006.

[85] G. Barthe _et al._, [Verified Proofs of Higher-Order Masking](https://link.springer.com/content/pdf/10.1007/978-3-662-46800-5_18.pdf), EUROCRYPT, 2015.

[86] G. Barthe _et al._, [Formal Certification of Code-Based Cryptographic Proofs](https://dl.acm.org/doi/pdf/10.1145/1480881.1480894), POPL, 2009.

[87] G. Barthe _et al._, [Strong Non-Interference and Type-Directed Higher-Order Masking](https://dl.acm.org/doi/pdf/10.1145/2976749.2978427), CCS, 2016.

[88] J.-S. Coron, [Formal Verification of Side-channel Countermeasures via Elementary Circuit Transformations](https://eprint.iacr.org/2017/879.pdf), ACNS, 2018.

[89] G. Agosta _et al._, [Compiler-based Side Channel Vulnerability Analysisand Optimized Countermeasures Application](https://dl.acm.org/doi/pdf/10.1145/2463209.2488833), DAC, 2013.

[90] S. Belaïd _et al._, [Tornado: Automatic Generation of Probing-Secure MaskedBitsliced Implementations](https://eprint.iacr.org/2020/506.pdf), EUROCRYPT, 2020.

[91] J.S. Coron _et al._, [Side Channel Cryptanalysis of a Higher Order Masking Scheme](https://link.springer.com/content/pdf/10.1007/978-3-540-74735-2_3.pdf), CHES, 2007.

[92] A. Battistello _et al._, [Horizontal  side-channel attacks and countermeasures on the ISW masking scheme](http://158.64.76.181/bitstream/10993/34592/1/540.pdf), CHES, 2016.
