---
layout: post
title: Tornado, Automatic Generation of Probing-Secure Masked Sliced Implementations
date: "2020-07-02 00:00:00"
description: 
lang: en
locale: en_US
author: Darius Mercadier
excerpt: 
comments: false
hidden: true
---

Given a high-level description of a cryptographic primitive, Tornado
synthesizes a masked implementation using the ISW-based multiplication
and refresh gadgets [1], and sharewise addition gadgets. The key role
of Usuba is to automate the generation of a sliced implementation,
upon which tightPROVE+ is then able to verify either the bit probing
or register probing security, or identify the necessary refreshes. By
integrating both tools, we derive a masked implementation from the
sliced one.

## Tornado's architecture

The overall architecture of Tornado is shown below:

<p align="center" style="margin-top:30px;margin-bottom:30px">
<img src="{{ site.baseurl }}/assets/images/blog/tornado-pipeline-final-small.png">
</p>

After normalization and optimization, the Usuba0 program is sent to
tightPROVE<sup>+</sup>, which adds refreshes if necessary. The output
of tightPROVE<sup>+</sup> is translated back to Usuba0, which Usubac
then masks: variables are replaced with arrays of shares, linear
operators and non-linear operators involving constants are applied
share-wise, and other non-linear operators and refreshes are left as
is to be replaced by masked gadgets during C code generation. Before
generating C code, a pass of _loop fusion_ merges share-wise
applications of linear operators when possible.


### Encoding and Decoding Usuba0 for tightPROVE<sup>+</sup>

The input language of tightPROVE+ consists of unrolled inlined
register-based circuits, whereas Usuba0 includes loops, nodes and node
calls. While Usubac can easily inline nodes and unroll loops, Tornado
targets low-end embedded devices with drastic memory constraint, on
which fully inlining and unrolled ciphers would not fit.

Usubac thus fully unrolls and inlines the Usuba0 code before
generating tightPROVE<sup>+</sup>'s input, but the refreshes inserted
by tightPROVE<sup>+</sup> are propagated back into the Usuba0 program
with loops, nodes and node calls.

To do so, when inlining and unrolling, we keep track of the origin of
each instruction: which node they come from, and which instruction in
that node. For each refresh inserted by TightPROVE<sup>+</sup>'s, we
therefore know where the refreshed variable comes from, and are
therefore able to insert the refresh directly in the right node.

<!--

```python
def refresh_prog(ua_source):
   ua_expanded  = inline_and_unroll(ua_source)
   tp_source    = usuba_to_tightprove(ua_expanded)
   tp_refreshed = call_tightprove(tp_source)
   ua_refreshed = tightprove_to_usuba(tp_refreshed, ua_expanded)
   return propagate_refreshes(ua_refreshed, ua_source)
```
-->


### Masking

To mask an Usuba0 program, Usubac replaces each variable with an array
of shares, and each operator with a masked gadget. The gadget to mask
a linear operator (`xor`) is simply a loop applying the operator on
each share, written directly in Usuba. To mask a negation, we only
negate the first share (since `~(r0 ^ r1 ^ ... ^ rk) == ~r0 ^ r1 ^
... ^ rk`), still in Usuba. To mask non-linear operators (`and` and
`or`), however, we introduce the operators `m&` and `m|` into Usuba,
which are transformed into calls to masked C gadgets when generating
the C code. In particular, for the multiplication (`and`), we use the
so-called ISW gadget gadget introduced in [1]:


```c
static void isw_mult(uint32_t *res,
                     const uint32_t *op1,
                     const uint32_t *op2) {
    for (int i = 0; i <= MASKING_ORDER; i++)
        res[i] = 0;
     
    for (int i = 0; i <= MASKING_ORDER; i++) {
        res[i] ^= op1[i] & op2[i];
        
        for (int j = i+1; j <= MASKING_ORDER; j++) {
            uint32_t rnd = get_random();
            res[i] ^= rnd;
            res[j] ^= (rnd ^ (op1[i] & op2[j])) ^ (op1[j] & op2[i]);
        }
    }
}
```

while the `or`s are transformed into `not` and `and`, since `a | b ==
~(~a & ~b)`. Similarly, refreshes, either inserted manually by the
developper or automatically by tightPROVE<sup>+</sup>, are compiled
into calls to the ISW refresh routine when generating C code:


```c
static void isw_refresh(uint32_t *res,
                        const uint32_t *in) {
    for (int i=0; i<=MASKING_ORDER; i++)
        res[i] = in[i];

    for (int i=0; i<=MASKING_ORDER; i++) {
        for (int j=i+1; j<=MASKING_ORDER; j++) {
            uint32_t rnd = get_random();
            res[i] ^= rnd;
            res[j] ^= rnd;
        }
    }
}
```


#### Constants

Constants are not secret values and thus do not need to be
shared. Furthermore, when multiplying a constant with a secret value,
there is no need to use the ISW mutliplication gadgets: we can simply
multiply each share of the secret value with the constant. The cost of
masking a multiplication by a constant is thus linear in the number of
shares, rather than quadratic as the ISW gadget is. Our benchmarks
(see section "Evaluation" below) show that indeed, the more masked
multiplication a cipher has, the slower it is. Avoiding unnecessary
masked multiplications is thus essential.

For instance, Pyjamask's linear layer contains a matrix
multiplication, implemented by calling 4 times the following Usuba
node, which multiplies two 32-bit vectors `a` and `b`:

<div class="language-lustre highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">node</span> <span class="nf">col_mult</span> <span class="p">(</span><span class="n">a</span><span class="o">:</span><span class="n">b32</span><span class="o">,</span><span class="n">b</span><span class="o">:</span><span class="n">b32</span><span class="p">)</span> <span class="k">returns</span> <span class="p">(</span><span class="n">r</span><span class="o">:</span><span class="n">b1</span><span class="p">)</span>
<span class="k">vars</span> <span class="n">acc</span><span class="o">:</span><span class="n">b32</span>
<span class="k">let</span>
    <span class="n">acc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&amp;</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
    <span class="k">forall</span> <span class="n">i</span> <span class="k">in</span> <span class="p">[</span><span class="mi">1</span><span class="o">,</span><span class="mi">31</span><span class="p">]</span> <span class="p">{</span>
        <span class="n">acc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">acc</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">^</span> <span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&amp;</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="p">}</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">acc</span><span class="p">[</span><span class="mi">31</span><span class="p">]</span>
<span class="k">tel</span>
</code></pre></div></div>

When this node is called in Pyjamask, `b` is always constant, and the
multiplication (`a[i] & b[i]`) therefore does not need to be
masked. Usubac uses a simple inference algorithm to track which
variables are constant and which are not, and is thus able to identify
that `b` does not need to be shared, and that the multiplication `a[i]
& b[i]` does not need to be masked.  This optimization both reduces
stack usage (since constant variables are kept as a single share
rather than an array of share) and increases performances (since
multiplying by a constant becomes linear rather than quadratic).


### Loop Fusion

Since each linear operation is replaced with a loop applying the
operation on each share, the masked code contains a lot of loops. The
overhead of those loops becomes quickly detrimental to
performances. Consider for instance the following Usuba0 snippet:

```lustre
x = a ^ b;
y = c ^ d;
z = x ^ y;
```

After masking, it becomes:


<div class="language-lustre highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">forall</span> <span class="n">i</span> <span class="k">in</span> <span class="p">[</span><span class="mi">0</span><span class="o">,</span> <span class="n">MASKING_ORDER</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">{</span>
    <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">^</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>
<span class="k">forall</span> <span class="n">i</span> <span class="k">in</span> <span class="p">[</span><span class="mi">0</span><span class="o">,</span> <span class="n">MASKING_ORDER</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">{</span>
    <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">^</span> <span class="n">d</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>
<span class="k">forall</span> <span class="n">i</span> <span class="k">in</span> <span class="p">[</span><span class="mi">0</span><span class="o">,</span> <span class="n">MASKING_ORDER</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">{</span>
    <span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">^</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>
</code></pre></div></div>


In order to reduce the overhead of looping over each share for linear
operations, we aggressively perform loop fusion (also called _loop
jamming_) in Usubac, which consists in replacing multiple loops with a
single one. The above snippet is thus optimized to:


<div class="language-lustre highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">forall</span> <span class="n">i</span> <span class="k">in</span> <span class="p">[</span><span class="mi">0</span><span class="o">,</span> <span class="n">MASKING_ORDER</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">{</span>
    <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">^</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">^</span> <span class="n">d</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">^</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>
</code></pre></div></div>


Loop fusion is also able to reduce the amount of stack used by
allowing Usubac to replace temporary arrays with temporary
variables. In the example above, Usubac would thus convert `x` and `y`
into scalars rather than arrays and produce the following code:


<div class="language-lustre highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">forall</span> <span class="n">i</span> <span class="k">in</span> <span class="p">[</span><span class="mi">0</span><span class="o">,</span> <span class="n">MASKING_ORDER</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">{</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">^</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">^</span> <span class="n">d</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span> <span class="o">^</span> <span class="n">y</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>


On embedded devices (which Tornado targets), this is especially
beneficial since the amount of stack available is very limited (_e.g._
a few dozen of kilobytes).

C compilers also perform loop fusion, but experimentally, they are
less aggressive than Usubac. We thus obtain better performances by
fusing loops directly in Usubac. On the 11 ciphers of the NIST
competition we implemented in Usuba and compiled with Tornado,
performing loop fusion in Usubac allows us to reduce stack usage of
our bitsliced implementations by 11kB on average whereas this saves
us, on average, 3kB of stack for our _n_-sliced implementations
(note that our platform offers a measly 96kB of SRAM). It also
positively impacts performance, with a 16% average speedup for
bitslicing and a 21% average speedup for n-slicing.


## Evaluation

We used Tornado to compare 11 cryptographic primitives from the second
round of the NIST lightweight cryptography competition. The choice of
cryptographic primitives was made on the basis that they were
self-identified as being amenable to masking. We stress that we do not
focus on the full authenticated encryption, message authentication, or
hash protocols but on the underlying primitives, mostly block ciphers
and permutations. The complete list of primitives follows:


<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-9wq8{border-color:inherit;text-align:center;vertical-align:middle}
.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
.tg .tg-uzvj{border-color:inherit;font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-xwyw{border-color:#000000;text-align:center;vertical-align:middle}
.tg .tg-wruy{border-color:#000000;color:#32cb00;text-align:center;vertical-align:middle}
.tg .tg-73t7{border-color:#000000;color:#cb0000;text-align:center;vertical-align:middle}
.tg .tg-y0n7{background-color:#efefef;text-align:center;vertical-align:middle}
</style>
<center>
<table class="tg" style="margin-bottom:25px">
<thead>
  <tr>
    <th class="tg-uzvj">submissions</th>
    <th class="tg-uzvj">primitive</th>
    <th class="tg-uzvj">n-sliceable</th>
    <th class="tg-uzvj">slice size</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-y0n7" colspan="4">block ciphers</td>
  </tr>
  <tr>
    <td class="tg-9wq8">Gift-Cofb [7],<br>Hyena [17],<br>Sundae-Gift [18]</td>
    <td class="tg-9wq8">Gift-128</td>
    <td class="tg-wruy">✔</td>
    <td class="tg-xwyw">32</td>
  </tr>
  <tr>
    <td class="tg-c3ow">Pyjamask [10]</td>
    <td class="tg-9wq8">Pyjamask-128</td>
    <td class="tg-wruy">✔</td>
    <td class="tg-xwyw">32</td>
  </tr>
  <tr>
    <td class="tg-9wq8">Skinny [11],<br>Romulus [19]</td>
    <td class="tg-9wq8">Skinny-128-256</td>
    <td class="tg-73t7">✖</td>
    <td class="tg-xwyw">-</td>
  </tr>
  <tr>
    <td class="tg-9wq8">Spook [6]</td>
    <td class="tg-9wq8">Clyde-128</td>
    <td class="tg-wruy">✔</td>
    <td class="tg-xwyw">32</td>
  </tr>
  <tr>
    <td class="tg-y0n7" colspan="4">permutations</td>
  </tr>
  <tr>
    <td class="tg-9wq8">Ace [4]</td>
    <td class="tg-9wq8">Ace</td>
    <td class="tg-wruy">✔</td>
    <td class="tg-xwyw">32</td>
  </tr>
  <tr>
    <td class="tg-9wq8">Ascon [5]</td>
    <td class="tg-9wq8"><i>p<sup>12</sup></i></td>
    <td class="tg-wruy">✔</td>
    <td class="tg-xwyw">64</td>
  </tr>
  <tr>
    <td class="tg-9wq8">Elephant [13]</td>
    <td class="tg-9wq8">Spongent-π[160]</td>
    <td class="tg-73t7">✖</td>
    <td class="tg-xwyw">-</td>
  </tr>
  <tr>
    <td class="tg-9wq8">Gimli [8]</td>
    <td class="tg-9wq8">Gimli-36</td>
    <td class="tg-wruy">✔</td>
    <td class="tg-xwyw">32</td>
  </tr>
  <tr>
    <td class="tg-9wq8">Orange [20],<br>Photon-Beetle [9]</td>
    <td class="tg-9wq8">Photon-256</td>
    <td class="tg-73t7">✖</td>
    <td class="tg-xwyw">-</td>
  </tr>
  <tr>
    <td class="tg-9wq8">Xoodyak [15,16]</td>
    <td class="tg-9wq8">Xoodoo</td>
    <td class="tg-wruy">✔</td>
    <td class="tg-xwyw">32</td>
  </tr>
  <tr>
    <td class="tg-y0n7" colspan="4">others</td>
  </tr>
  <tr>
    <td class="tg-c3ow">Subterranean [14]</td>
    <td class="tg-9wq8">blank(8)</td>
    <td class="tg-73t7">✖</td>
    <td class="tg-xwyw">-</td>
  </tr>
</tbody>
</table>
</center>


Whenever possible, we generate both a bitsliced and an _n_-sliced
implementation for each primitive, which allows us to exercise the
bit-probing and the register-probing models of tightPROVE+. However, 4
primitives do not admit a straightforward n-sliced implementation. The
Subterranean permutation involves a significant amount of
bit-twiddling across its 257-bit state, which makes it a resolutely
bitsliced primitive (as confirmed by its reference
implementation). Photon, Skinny, Spongent rely on lookup tables that
would be too expansive to emulate in n-sliced mode. In bitslicing,
these tables are simply implemented by their Boolean circuit, either
provided by the authors (Photon, Skinny) or generated through SAT [2]
with the objective of minimizing multiplicative complexity (Spongent,
with 4 ANDs and 28 XORs).


Note that the _n_-sliced implementations, when they exist, are either
32-sliced or 64-sliced.  This means in particular that, unlike
bitslicing that processes multiple blocks in parallel, these
implementations process a single block at once on our 32-bit Cortex
M4. Note also that in practice, all _n_-sliced implementation are
vsliced, since the Cortex M4 we consider does not provide SIMD
extensions, which are required for hslicing.


Running tightPROVE<sup>+</sup> on our Usuba implementations showed
that all of them were _t_-probing secure in the bit-probing model, but
3 were not secure in the register-probing model. ACE required 384
additional refreshes, Clyde-128 required 6 refreshes, and Gimli
required 120. In the case of ACE and Clyde, the number of refreshes
inserted by tightPROVE<sup>+</sup> is known minimal, while for Gimli,
it is only an upper bound [3].


### Baseline Performance Evaluation

In the following, we benchmark our implementations –in Usuba and
compiled with Tornado– of the NIST submissions against the reference
implementation provided by the contestants. This allows us to
establish a performance baseline (without masking), thus providing a
common frame of reference for the performance of these primitives
based on their implementation synthesized from Usuba. In doing so, we
have to bear in mind that the reference implementations provided by
the NIST contestants are of varying quality: some appear to have been
finely tuned for performance while others focus on simplicity, acting
as an executable specification.

In an effort to level the playing field, we ran our benchmark on an
Intel i5-6500 @ 3.20GHz, running Linux 4.15.0-54. The implementations
were compiled with Clang 7.0.0 with flags `-O3 -fno-slp-vectorize
-fno-vectorize`. These flags prevent Clang from trying to produce
vectorized code, which would artificially advantage some
implementations at the expense of others because of brittle,
hard-to-predict vectorization heuristics. Besides, vectorized
instructions remain an exception in the setting of embedded devices
(_e.g._, Cortex M). At the exception of Subterranean (which is
bitsliced), the reference implementations follow a n-sliced
implementation pattern, representing the state of the primitive
through a matrix of 32-bit values, or 64-bit in the case of Ascon. To
evaluate bitsliced implementations, we simulate a 32-bit architecture,
meaning that the throughput we report corresponds to the parallel
encryption of 32 independent blocks. The cost of transposing data into
a bitslice format (around 9 cycles/bytes to transpose a 32x32 matrix)
is excluded. The results are shown in the following table:

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-wa1i{font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-0lax{text-align:left;vertical-align:top}
</style>
<center>
<table class="tg" style="margin-bottom:25px;margin-top:25px">
<thead>
  <tr>
    <th class="tg-wa1i" rowspan="2">Primitive</th>
    <th class="tg-wa1i" colspan="3">Performances (cycles/bytes)<br><span style="font-style:italic">(lower is better)</span></th>
  </tr>
  <tr>
    <td class="tg-wa1i">Usuba n-slice</td>
    <td class="tg-wa1i">Usuba bitslice</td>
    <td class="tg-wa1i">reference</td>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-0lax">Ace</td>
    <td class="tg-0lax">34.25</td>
    <td class="tg-0lax">55.89</td>
    <td class="tg-0lax">273.53</td>
  </tr>
  <tr>
    <td class="tg-0lax">Ascon</td>
    <td class="tg-0lax">9.84</td>
    <td class="tg-0lax">4.94</td>
    <td class="tg-0lax">5.18</td>
  </tr>
  <tr>
    <td class="tg-0lax">Clyde</td>
    <td class="tg-0lax">33.72</td>
    <td class="tg-0lax">21.99</td>
    <td class="tg-0lax">37.69</td>
  </tr>
  <tr>
    <td class="tg-0lax">Gimli</td>
    <td class="tg-0lax">15.77</td>
    <td class="tg-0lax">5.80</td>
    <td class="tg-0lax">44.35</td>
  </tr>
  <tr>
    <td class="tg-0lax">Gift</td>
    <td class="tg-0lax">565.30</td>
    <td class="tg-0lax">45.51</td>
    <td class="tg-0lax">517.27</td>
  </tr>
  <tr>
    <td class="tg-0lax">Photon</td>
    <td class="tg-0lax">-</td>
    <td class="tg-0lax">44.88</td>
    <td class="tg-0lax">214.47</td>
  </tr>
  <tr>
    <td class="tg-0lax">Pyjamask</td>
    <td class="tg-0lax">246.72</td>
    <td class="tg-0lax">131.33</td>
    <td class="tg-0lax">267.35</td>
  </tr>
  <tr>
    <td class="tg-0lax">Skinny</td>
    <td class="tg-0lax">-</td>
    <td class="tg-0lax">46.87</td>
    <td class="tg-0lax">207.82</td>
  </tr>
  <tr>
    <td class="tg-0lax">Spongent</td>
    <td class="tg-0lax">-</td>
    <td class="tg-0lax">146.93</td>
    <td class="tg-0lax">4824.97</td>
  </tr>
  <tr>
    <td class="tg-0lax">Subterranean</td>
    <td class="tg-0lax">-</td>
    <td class="tg-0lax">17.64</td>
    <td class="tg-0lax">355.38</td>
  </tr>
  <tr>
    <td class="tg-0lax">Xoodoo</td>
    <td class="tg-0lax">14.93</td>
    <td class="tg-0lax">6.47</td>
    <td class="tg-0lax">10.14</td>
  </tr>
</tbody>
</table>
</center>

We notice that Usuba often delivers performance that is on par or
better than the reference implementations. Note that this does not
come at the expense of intelligibility: our Usuba implementations are
written in a high-level language, which is amenable to formal
reasoning thanks to its straightforward semantic model (unlike any
implementation in C). The reference implementations of Skinny and
Photon use lookup tables, which do not admit a straightforward
implementation in terms of constant-time, combinational operations. As
a result, we are unable to implement a constant-time n-sliced version
in Usuba and to mask such an implementation.

We now turn our attention specifically to a few implementations that
exhibit interesting performance with the following observations:

 - The reference implementation of Subterranean is an order of
   magnitude slower than in Usuba because its implementation is
   bit-oriented (each bit is stored in a distinct 8-bit variable) but
   only a single block is encrypted at a time. Switching to 32-bit
   variables and encrypting 32 blocks in parallel, as Usuba does,
   significantly improves performance.
   
 - The reference implementation of Spongent is slowed down by a
   prohibitively expensive bitpermutation over 160 bits, which is
   spread across 20 8-bit variables. Thanks to bitslicing, Usuba turns
   this permutation into a purely static renaming of variable, which
   occurs purely at compile-time.
   
 - On Ascon, our n-sliced implementation is twice slower than the
   reference implementation. Unlike the reference implementation, we
   have refrained from performing aggressive function inlining and
   loop unrolling to keep code size in check, since we target embedded
   systems.  However, if we instruct the Usuba compiler to perform
   these optimizations, the performance of our n-sliced implementation
   is on par with the reference one.
   
 - Ace reference implementation suffers from significant performance
   issues, relying on an excessive number of temporary variables to
   store intermediate results.
   
 - Gimli offers two reference implementations, one being a
   high-performance SSE implementation with the other serving as an
   executable specification on general-purpose registers.  We chose
   the general-purpose one here (which had not been subjected to the
   same level of optimizations) because our target architecture
   (Cortex M) does not provide a vectorized instruction set.
   
 - Finally, Gift's n-slice implementation suffers from sever
   performance issues because of its expensive linear layer. Using a
   the recent _fixslicing_ technique [21] improves the performance of
   Usuba's _n_-slice Gift implementation down to 42 cycles/byte.


### Masking benchmarks

We ran our benchmarks on a Nucleo STM32F401RE offering an Arm
Cortex-M4 with 512 Kbytes of Flash memory and 96 Kbytes of SRAM. We
used the GNU C compiler arm-none-eabi-gcc version 9.2.0 at
optimization level -O3.  We considered two modes regarding the Random
Number Generator (RNG):


 - Pooling mode: The RNG generates random numbers at a rate of 32 bits
   every 64 clock cycles.  Fetching a random number can thus take up
   to 65 clock cycles.

 - Fast mode: The RNG only takes a few clock cycles to generate a
   32-bit random word. The RNG routine thus can simply read a register
   containing this 32-bit random word without checking for its
   availability.


Those two modes were chosen because they are the ones used in the
submission of Pyjamask, which is the only submission detailing the
question of how to get random numbers for a masked implementation.


#### Scaling




Since masking a multiplication has a quadratic cost in the number of
shares, we expect performance at high orders to be mostly proportional
with the number of multiplications used by the primitives. We thus
report the number of multiplications involved in our implementation
(bitsliced and nsliced) in the following table:

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-wa1i{font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-uzvj{border-color:inherit;font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
.tg .tg-0lax{text-align:left;vertical-align:top}
</style>
<center>
<table class="tg">
<thead>
  <tr>
    <th class="tg-uzvj" rowspan="2">primitive</th>
    <th class="tg-wa1i" rowspan="2">state size<br>(bits)</th>
    <th class="tg-uzvj" colspan="2">multiplications</th>
    <th class="tg-uzvj" colspan="2">multiplications/bits</th>
  </tr>
  <tr>
    <td class="tg-wa1i">n-slice</td>
    <td class="tg-wa1i">bitslice</td>
    <td class="tg-wa1i">n-slice</td>
    <td class="tg-wa1i">bitslice</td>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-0pky">ACE</td>
    <td class="tg-0lax">320<br></td>
    <td class="tg-0pky">384</td>
    <td class="tg-0lax">12288</td>
    <td class="tg-0pky">1.2</td>
    <td class="tg-0lax">38</td>
  </tr>
  <tr>
    <td class="tg-0pky">ASCON</td>
    <td class="tg-0lax">320</td>
    <td class="tg-0pky">60</td>
    <td class="tg-0lax">3840</td>
    <td class="tg-0pky">0.19</td>
    <td class="tg-0lax">12</td>
  </tr>
  <tr>
    <td class="tg-0pky">Clyde</td>
    <td class="tg-0lax">128</td>
    <td class="tg-0pky">48</td>
    <td class="tg-0lax">1536</td>
    <td class="tg-0pky">0.37</td>
    <td class="tg-0lax">12</td>
  </tr>
  <tr>
    <td class="tg-0pky">GIFT</td>
    <td class="tg-0lax">128</td>
    <td class="tg-0pky">160</td>
    <td class="tg-0lax">5120</td>
    <td class="tg-0pky">1.25</td>
    <td class="tg-0lax">40</td>
  </tr>
  <tr>
    <td class="tg-0pky">Gimli</td>
    <td class="tg-0lax">384</td>
    <td class="tg-0pky">288</td>
    <td class="tg-0lax">9216</td>
    <td class="tg-0pky">0.75</td>
    <td class="tg-0lax">24</td>
  </tr>
  <tr>
    <td class="tg-0pky">PHOTON</td>
    <td class="tg-0lax">256</td>
    <td class="tg-0pky">-</td>
    <td class="tg-0lax">3072</td>
    <td class="tg-0pky">-</td>
    <td class="tg-0lax">12</td>
  </tr>
  <tr>
    <td class="tg-0pky">Pyjamask</td>
    <td class="tg-0lax">128</td>
    <td class="tg-0pky">56</td>
    <td class="tg-0lax">1792</td>
    <td class="tg-0pky">0.44</td>
    <td class="tg-0lax">14</td>
  </tr>
  <tr>
    <td class="tg-0pky">SKINNY</td>
    <td class="tg-0lax">128</td>
    <td class="tg-0pky">-</td>
    <td class="tg-0lax">6144</td>
    <td class="tg-0pky">-</td>
    <td class="tg-0lax">48</td>
  </tr>
  <tr>
    <td class="tg-0pky">SPONGENT</td>
    <td class="tg-0lax">160</td>
    <td class="tg-0pky">-</td>
    <td class="tg-0lax">12800</td>
    <td class="tg-0pky">-</td>
    <td class="tg-0lax">80</td>
  </tr>
  <tr>
    <td class="tg-0pky">Subterranean</td>
    <td class="tg-0lax">257</td>
    <td class="tg-0pky">-</td>
    <td class="tg-0lax">2056</td>
    <td class="tg-0pky">-</td>
    <td class="tg-0lax">8</td>
  </tr>
  <tr>
    <td class="tg-0pky">Xoodoo</td>
    <td class="tg-0lax">384</td>
    <td class="tg-0pky">144</td>
    <td class="tg-0lax">4608</td>
    <td class="tg-0pky">0.37</td>
    <td class="tg-0lax">12</td>
  </tr>
</tbody>
</table>
</center>


Our results confirm that ciphers with a low number of multiplications
scale better at high masking order.

<p align="center" style="margin-top:30px;margin-bottom:30px;">
<img style="height:auto;width:auto;max-width:100%" src="{{ site.baseurl }}/assets/images/blog/n-slice-masking-scaling-bloc-pooling.png">
</p>

<p align="center" style="margin-top:30px;margin-bottom:30px">
<img style="height:auto;width:auto;max-width:100%" src="{{ site.baseurl }}/assets/images/blog/n-slice-masking-scaling-bloc-fast.png">
</p>

<p align="center" style="margin-top:30px;margin-bottom:30px;">
<img style="height:auto;width:auto;max-width:100%" src="{{ site.baseurl }}/assets/images/blog/n-slice-masking-scaling-byte-pooling.png">
</p>

<p align="center" style="margin-top:30px;margin-bottom:30px">
<img style="height:auto;width:auto;max-width:100%" src="{{ site.baseurl }}/assets/images/blog/n-slice-masking-scaling-byte-fast.png">
</p>




### Usuba vs reference


Of these 11 NIST submissions, only Pyjamask provides a masked
implementation. Our implementation is consistently (at every order,
and with both the pooling and fast RNGs) 1.8 times slower than their
masked implementation. The reason is twofold. First, their reference
implementation has been heavily optimized to take advantage of the
barrel shifter on the Cortex M4, which we do not exploit. Second, our
implementation uses the generic ISW multiplication (Figure 7) whereas
the reference implementation employs a specialized, hand-tuned
implementation in assembly.



---
## References

[1] Y. Ishai _et al._, [Private Circuits: Securing Hardware against Probing Attacks](https://people.eecs.berkeley.edu/~daw/papers/privcirc-crypto03.pdf), CRYPTO, 2003.

[2] K. Stoffelen, [Efficient cryptography on the RISC-V architecture](https://eprint.iacr.org/2019/794.pdf), LATINCRYPT, 2019.

[3] S. Belaïd _et al._, [Tornado: Automatic Generation of Probing-Secure Masked Bitsliced Implementations](https://eprint.iacr.org/2020/506.pdf), EUROCRYPT, 2020.

[4] M. Aagaard _et al._, [ACE: An Authenticated Encryption and Hash Algorithm](https://csrc.nist.gov/CSRC/media/Projects/Lightweight-Cryptography/documents/round-1/spec-doc/ace-spec.pdf), 2019.

[5] C. Dobraunig _et al._, [ASCON](https://csrc.nist.gov/CSRC/media/Projects/lightweight-cryptography/documents/round-2/spec-doc-rnd2/ascon-spec-round2.pdf), 2019.

[6] D. Bellizia _et al._, [Spook: Sponge-Based Leakage-Resilient Authenticated Encryption with a Masked Tweakable Block Cipher](https://csrc.nist.gov/CSRC/media/Projects/Lightweight-Cryptography/documents/round-1/spec-doc/Spook-spec.pdf), 2019.

[7] S. Banik _et al._, [GIFT-COFB](https://csrc.nist.gov/CSRC/media/Projects/Lightweight-Cryptography/documents/round-1/spec-doc/GIFT-COFB-spec.pdf), 2019.

[8] D. J. Bernstein _et al._, [Gimli : A cross-platform permutation](https://eprint.iacr.org/2017/630.pdf), CHES, 2017.

[9] Z. Bao _et al._, [PHOTON-Beetle Authenticated Encryption and Hash Family](https://csrc.nist.gov/CSRC/media/Projects/Lightweight-Cryptography/documents/round-1/spec-doc/PHOTON-Beetle-spec.pdf), 2019.

[10] D. Goudarzi _et al._, [Pyjamask](https://csrc.nist.gov/CSRC/media/Projects/lightweight-cryptography/documents/round-2/spec-doc-rnd2/pyjamask-spec-round2.pdf), 2019.

[11] C. Beierle _et al._, [SKINNY-AES and SKINNY-Hash](https://csrc.nist.gov/CSRC/media/Projects/Lightweight-Cryptography/documents/round-1/spec-doc/SKINNY-spec.pdf), 2019.

[12] A. Bogdanov _et al._, [SPONGENT: A lightweight hash function](https://eprint.iacr.org/2011/697.pdf), CHES, 2011.

[13] T. Byene _et al._, [Elephant v1](https://csrc.nist.gov/CSRC/media/Projects/Lightweight-Cryptography/documents/round-1/spec-doc/elephant-spec.pdf), 2019.

[14] J. Daemen _et al._, [The Subterranean 2.0 cipher suite](https://cs.ru.nl/~joan/Subterranean/subterranean_ToSC_preprint.pdf), 2019.

[15] J. Daemen _et al._, [Xoodoo cookbook](https://eprint.iacr.org/2018/767.pdf), 2018.

[16] J. Daemen _et al._, [Xoodyak, a lightweight cryptographic scheme](https://pdfs.semanticscholar.org/7be0/c4cd872f3acb816b1737975f17d8ede942b0.pdf), 2019.

[17] A. Chakraborti _et al._, [Security Analysis of HYENA Authenticated Encryption Mode](https://csrc.nist.gov/CSRC/media/Events/lightweight-cryptography-workshop-2019/documents/papers/security-analysis-of-hyena-lwc2019.pdf), 2019.

[18] S. Banik _et al._, [SUNDAE-GIFT](https://csrc.nist.gov/CSRC/media/Projects/Lightweight-Cryptography/documents/round-1/spec-doc/SUNDAE-GIFT-spec.pdf), 2019.

[19] T. Iwata _et al._, [Romulus](https://csrc.nist.gov/CSRC/media/Projects/Lightweight-Cryptography/documents/round-1/spec-doc/Romulus-spec.pdf), 2019.

[20] B. Chakraborty, M. Nandi, [ORANGE](https://csrc.nist.gov/CSRC/media/Projects/Lightweight-Cryptography/documents/round-1/spec-doc/orange-spec.pdf), 2019.

[21] A. Adomnicai _et al._, [Fixslicing: A New GIFT Representation](https://eprint.iacr.org/2020/412.pdf), TCHES, 2020.
