---
layout: post
title: Evaluation of Usuba generated ciphers on Intel CPUs
date: "2020-08-09 00:00:00"
description: 
lang: en
locale: en_US
author: Darius Mercadier
excerpt: 
comments: false
hidden: true
---

## Usuba vs Human

## Scalability

<p align="center" style="margin-top:30px;margin-bottom:30px;">
<img style="height:auto;width:auto;max-width:100%" src="{{ site.baseurl }}/assets/images/blog/eval-scaling-speedup.png">
</p>

Figure 3 shows the scaling of our implementations on the main SIMD
available on Intel: SSE (SSE4.2), AVX, AVX2 and AVX512. Those
benchmarks were compiled using ICC 18.0.1, and executed on a Intel(R)
Xeon(R) Gold 6126 CPU @ 2.60GHz running a Scientific Linux 7.5
(Nitrogen).

We omitted the cost of transposition in this benchmark to focus solely
on the cryptographic primitives. The cost of transposition depends on
the data layout and the target instruction set. For example, the
transposition of u V 16 × 4 costs 0.09 cycles/byte on AVX512 while the
transposition of u H 16 × 4 costs up to 10.76 cycles/byte on SSE.


One could expect the speedup to be linear in the size of registers,
but the reality is more complex. Spilling wider reg- isters puts more
pressure on the L1 data-cache, leading to more frequent misses. To
stay within thermal design power (TDP) envelope of the CPU, wider SIMD
execution units (from AVX to AVX512) are throttled, meaning that the
processor must perform time-consuming frequency reduction steps. AVX
and AVX512 registers need tens of thousands warm-up cycles before
being used, since they are not pow- ered when no instruction uses
them. SSE instructions take two operands and overwrite one to store
the result, while AVX offer 3-operand non destructive instructions,
thus reducing register spilling. Also, successive generations of SIMD
instructions expand the number of registers (from 8 with SSE, 16 with
AVX and 32 with AVX512), further reducing the need for spilling. The
latency and throughput of most instructions differ from one
micro-architecture to another and from one SIMD to another. For
instance, up to 4 gen- eral purpose bitwise operations can be computed
per cycle, and only 3 SSE/AVX. Finally, newer SIMD extensions tend to
have more powerful instructions than older ones. For in- stance,
AVX512 offers, among many useful features, a bitwise ternary logic
instruction (vpternlogq) that computes any three-operand binary
function at once. We distinguish AVX from AVX2 because the latter
introduced shifts, n-bit integer arithmetic, and byte-shuffle on 256
bits, thus making it more suitable for slicing on 256 bits.

Bitslice Rectangle and DES both scale nicely. As any bitsliced
algorithm, they both suffer from a lot of spilling, and therefore
benefit a lot from having more registers available: using AVX
instructions instead of SSE allows to use non-destructive 3-operand
instructions, therefore yielding a 10 to 15% speedup, without using
wider registers. When doubling the word size by using 256-bit AVX2
registers instead of 128-bit, the speedup is unsurprisingly
doubled. AVX512 benefits are twofold. First, they provide twice more
registers than AVX2, thus reducing the spilling. Second, they offer a
bitwise ternary logic instruction, which is exploited by ICC to fuse
nested logical gates. Overall, this allows Rectangle and DES to run
almost 5 times faster on AVX512 than on SSE.  Bitslice AES, on the
other hand, does not benefit from having wider registers, because it
contains many more spilling and memory operations: about 6 times more
than Rectangle and DES. Consequently, increasing the register size
puts more pressure on the caches: while AES suffers from less than 1%
misses in the L1 data cache when using general purpose 64-bit
registers, that number grows to 6% on SSE, 14% on AVX2, and up to 50%
on AVX512.

Overall, m-sliced programs are similar excepted when it comes to
shuffle and m-bit arithmetic. As a result, they exhibit similar
scaling behavior. They tend to use only a handful of variables, and do
not suffer from spilling as much as bitsliced implementations, which
explains why using AVX instructions yields only a marginal –if any–
improvement in throughput. As in bitslicing, AVX2 registers allows the
throughput to be doubled. AVX512 is particularly beneficial because of
the aforementioned vpternlogq instruction. This translates into a good
speedup on Rectangle and AES while the effect is reduced on Chacha20,
which involves few Boolean operations.


## Monomorphization

As explained in the [post describing the Usuba language]({{
site.baseurl }}{% post_url 2020-02-24-usuba %}), we can specialize our
polymorphic implementation of Rectangle to all types of slicing and
SIMD instruction set: for instance, on AVX2, the vsliced C
implementation of Rectangle generated from the Usuba code will have
the type

```c
void Rectangle (__m256i plain[4], __m256i key[26][4], __m256i cipher[4])
```

while the bitsliced SSE implementation has type


```c
void Rectangle (__m128i plain[64], __m128i key[26][64], __m128i cipher[64])
```


- Few ciphers h-sliceable: only `u16` or less

Rectangle

AES


- bitslice + vslice (some examples)

Ascon

Serpent


---
## References
